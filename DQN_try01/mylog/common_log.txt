mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False  True]
greedy_action q_values = tensor([   -inf,  0.9792, -1.5320,  1.0246,    -inf, -0.4305, -2.6842, -1.8775,
        -3.8334,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False False False  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True False  True  True]
greedy_action q_values = tensor([   -inf,  1.1076,    -inf,    -inf,    -inf, -1.0934,    -inf, -1.7045,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 0: Reward=-286.21, route=[0, 9, 4, 3, 2, 8, 6, 1, 5, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5497,  0.9888,    -inf, -0.3966, -2.6587, -1.8706,
        -3.8192,  0.3577], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5417, -1.7418,
        -3.2795,  0.1614], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.9790, -1.5383,
        -3.6482,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6313,    -inf,
        -2.8568,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 1: Reward=-289.55, route=[0, 1, 4, 3, 5, 2, 9, 7, 6, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.2984,    -inf,  0.9199,    -inf, -2.3972, -1.6198,
           -inf, -0.1666], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9175,    -inf,    -inf,    -inf, -2.9633, -1.5466,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6149,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 2: Reward=-285.46, route=[0, 1, 3, 8, 5, 4, 9, 2, 7, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True False False False False]
greedy_action q_values = tensor([   -inf,  0.9806, -1.5564,  1.0159,    -inf,    -inf, -2.6683, -1.8529,
        -3.8347,  0.3666], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True False False False False]
greedy_action q_values = tensor([   -inf,  1.1135, -1.1854,    -inf,    -inf,    -inf, -2.8272, -1.8002,
        -3.6653,  0.1375], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1456,    -inf,    -inf,    -inf, -2.7806, -1.7842,
        -3.3249, -0.0528], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 3: Reward=-262.03, route=[0, 5, 4, 3, 1, 9, 8, 6, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3048,  0.4371,  0.5558,    -inf,    -inf, -1.7568,
        -2.9044, -0.1189], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5409,  0.9849,    -inf,    -inf,    -inf, -1.8907,
        -3.8290,  0.3648], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.0349,    -inf,    -inf,    -inf,    -inf,    -inf,
        -2.8426,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
        -3.2825,    -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 4: Reward=-264.02, route=[0, 1, 5, 6, 4, 3, 9, 7, 2, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9109,  0.2771, -0.3850, -0.3196, -2.9777, -1.6048,
        -3.6190,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  0.5556, -1.0584,    -inf, -1.7471,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 5: Reward=-257.32, route=[0, 1, 9, 3, 2, 8, 6, 4, 7, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
greedy_action q_values = tensor([   -inf,  1.2090, -1.0499,  0.0930,  0.7738,    -inf,    -inf,    -inf,
        -2.8565,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.0875,  0.3228,  0.0291,    -inf,    -inf,    -inf,
        -3.3288,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1307,    -inf, -0.3845,    -inf,    -inf,    -inf,
        -3.6677,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.4973,    -inf,    -inf,    -inf,    -inf,    -inf,
        -3.8327,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
        -3.2825,    -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 6: Reward=-276.78, route=[0, 5, 9, 6, 7, 1, 3, 4, 2, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True False  True False False]
greedy_action q_values = tensor([   -inf,  1.2453,    -inf,    -inf,  0.7693,    -inf, -2.6331,    -inf,
        -2.8817, -0.2020], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 7: Reward=-294.51, route=[0, 5, 2, 3, 7, 1, 9, 8, 4, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1620,    -inf,  1.0763, -1.5047, -2.5230, -1.6967,
           -inf, -0.1992], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -1.2396,    -inf,    -inf,
           -inf, -0.1630], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 8: Reward=-289.63, route=[0, 1, 3, 8, 4, 2, 6, 7, 9, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([   -inf,  1.3311, -0.9192,  0.3005, -0.3869, -0.3426, -3.0020, -1.5939,
        -3.6264,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1007,  0.3483,  0.0296, -0.6904, -2.7888, -1.8603,
        -3.3250,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5185,    -inf,    -inf, -0.3845, -2.6580, -1.8980,
        -3.8322,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5405,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 9: Reward=-233.95, route=[0, 9, 1, 3, 4, 5, 2, 7, 8, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False False  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.3621, -2.8082,    -inf,
        -3.6551,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 10: Reward=-283.75, route=[0, 1, 7, 2, 9, 4, 3, 5, 6, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9170,    -inf, -0.3600, -0.2866,    -inf, -1.6590,
        -3.6324,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  0.2288,    -inf,    -inf, -1.8217,
        -3.3053,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 11: Reward=-282.22, route=[0, 3, 1, 6, 9, 5, 2, 4, 8, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1007,  0.3483,  0.0296, -0.6904, -2.7888, -1.8603,
        -3.3250,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1520,    -inf, -0.3918, -0.3436, -2.8117, -1.8959,
        -3.6691,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 12: Reward=-241.87, route=[0, 9, 1, 3, 5, 2, 4, 6, 7, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([   -inf,  1.1424, -1.3102,  0.4264,  0.5521, -1.1438,    -inf,    -inf,
        -2.9128, -0.1219], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.7450,    -inf, -0.7655,    -inf,    -inf,
        -3.2685,  0.1424], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -1.5034,    -inf,    -inf,
           -inf, -0.2142], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 13: Reward=-317.27, route=[0, 7, 6, 1, 4, 2, 3, 8, 9, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.2867,    -inf,  0.9292,    -inf, -2.4177, -1.6320,
        -2.6820, -0.1910], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -1.7729,
        -3.2819,  0.1689], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 14: Reward=-290.71, route=[0, 1, 3, 5, 4, 6, 2, 9, 8, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([   -inf,  1.2633, -1.0816,  0.0869,  0.7601, -1.3288, -2.6522,    -inf,
        -2.8514, -0.1957], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.7582, -2.5400,    -inf,
        -3.2725,  0.1430], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.3194, -2.9806,    -inf,
        -3.6212,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
        -2.9059,    -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 15: Reward=-287.37, route=[0, 7, 1, 4, 3, 2, 9, 5, 6, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1777,    -inf, -0.4022, -0.3326, -2.8038, -1.8741,
        -3.6632,  0.1078], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  0.2164, -0.7455, -2.5493, -1.7952,
        -3.3000,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.3772, -2.6586, -1.8804,
        -3.8517,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 16: Reward=-211.6, route=[0, 1, 3, 9, 2, 4, 5, 8, 7, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1663,  0.0870,  1.0556, -1.5283, -2.5226, -1.6878,
           -inf, -0.1992], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3246,  0.4534,    -inf, -1.0835,    -inf, -1.7186,
           -inf, -0.0667], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9238,    -inf,    -inf, -0.2802,    -inf, -1.6018,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 17: Reward=-302.37, route=[0, 1, 8, 4, 6, 3, 9, 5, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.7448,  0.1977, -0.7686, -2.5398, -1.7614,
        -3.2881,  0.1388], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf, -0.4151, -0.3312, -2.8050, -1.8483,
        -3.6784,  0.1112], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 18: Reward=-265.76, route=[0, 1, 2, 3, 9, 4, 5, 7, 6, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1663,  0.0870,  1.0556, -1.5283, -2.5226, -1.6878,
           -inf, -0.1992], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1717,    -inf,    -inf, -0.3266,    -inf,    -inf,
           -inf,  0.1312], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.7259,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 19: Reward=-304.49, route=[0, 1, 8, 4, 7, 6, 3, 9, 2, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False  True]
greedy_action q_values = tensor([   -inf,  1.2429,    -inf,  0.0912,  0.7592, -1.3159,    -inf,    -inf,
        -2.8642,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  1.0869, -1.4986,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 20: Reward=-304.42, route=[0, 6, 2, 9, 7, 1, 3, 8, 4, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1564,  0.0650,  1.0539, -1.5419, -2.5193,    -inf,
           -inf, -0.2251], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  0.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.4241,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 21: Reward=-233.44, route=[0, 1, 7, 8, 4, 9, 3, 2, 5, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 22: Reward=-250.91, route=[0, 1, 3, 2, 6, 8, 7, 9, 4, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2746,  0.3044,  0.9138,    -inf, -2.4179, -1.6246,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5237,  0.9930,    -inf,    -inf, -2.6351, -1.8517,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 23: Reward=-318.55, route=[0, 1, 8, 9, 5, 4, 3, 6, 2, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9102,  0.2757, -0.3714, -0.3103,    -inf, -1.6366,
        -3.6179,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  1.0886, -1.4850,    -inf, -1.7110,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 24: Reward=-301.57, route=[0, 1, 6, 9, 3, 2, 8, 4, 5, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1777,    -inf, -0.4022, -0.3326, -2.8038, -1.8741,
        -3.6632,  0.1078], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2548,    -inf,    -inf,    -inf, -2.4503,    -inf,
        -2.6626,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5470,    -inf,
        -3.2802,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 25: Reward=-254.87, route=[0, 1, 3, 9, 7, 4, 5, 2, 6, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False False False  True  True]
greedy_action q_values = tensor([   -inf,  0.9801,    -inf,    -inf,    -inf, -0.7542, -2.5660, -1.7510,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -1.2544, -2.6200,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 26: Reward=-254.0, route=[0, 9, 3, 4, 8, 2, 1, 7, 5, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1141, -1.1838,    -inf, -0.4032, -0.3555, -2.8261, -1.8652,
        -3.6732,  0.1189], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.0603,    -inf,  0.7760, -1.2720, -2.6217,    -inf,
        -2.8527, -0.2034], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1572,    -inf,    -inf, -1.5187, -2.5329,    -inf,
           -inf, -0.2142], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -1.0780,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 27: Reward=-297.12, route=[0, 3, 1, 7, 4, 8, 9, 2, 6, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([   -inf,  1.1299, -1.3170,  0.4506,  0.5612, -1.1328,    -inf, -1.7647,
        -2.9155, -0.0965], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.0629,  0.0584,  0.7635, -1.2844,    -inf,    -inf,
        -2.8428, -0.1989], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5314,  0.9714,    -inf, -0.4024,    -inf,    -inf,
        -3.8117,  0.3455], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1770,    -inf,    -inf, -0.3466,    -inf,    -inf,
        -3.6348,  0.0959], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1447,    -inf,    -inf, -1.4944,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.7259,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 28: Reward=-271.78, route=[0, 6, 1, 7, 4, 3, 9, 8, 2, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1224,  0.3322,  0.0097, -0.6955, -2.7690,    -inf,
        -3.3111, -0.0811], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1334,    -inf,    -inf,    -inf, -2.5455,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5268,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 29: Reward=-230.61, route=[0, 7, 1, 3, 9, 4, 5, 8, 2, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([   -inf,  1.0011, -1.5593,  1.0204,    -inf, -0.4226, -2.6788, -1.8647,
        -3.8268,  0.3666], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False  True False]
greedy_action q_values = tensor([   -inf,  1.2809, -1.1817,    -inf,    -inf, -1.5390, -2.5606, -1.6545,
           -inf, -0.1758], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9244,    -inf,    -inf, -0.2882, -2.9704, -1.5699,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2765,    -inf,    -inf,    -inf, -2.4338, -1.5954,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 30: Reward=-286.32, route=[0, 4, 3, 8, 1, 9, 5, 2, 7, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([   -inf,  1.2774, -1.1802,  0.1132,  1.0581, -1.5631, -2.5469, -1.6844,
           -inf, -0.1865], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5539,  0.9933,    -inf, -0.3700, -2.6402, -1.8508,
           -inf,  0.3956], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5368, -1.7446,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 31: Reward=-323.22, route=[0, 8, 1, 4, 3, 5, 9, 2, 7, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1777,    -inf, -0.4022, -0.3326, -2.8038, -1.8741,
        -3.6632,  0.1078], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False  True False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1406,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 32: Reward=-248.04, route=[0, 1, 3, 9, 7, 5, 6, 4, 8, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1224,  0.3322,  0.0097, -0.6955, -2.7690,    -inf,
        -3.3111, -0.0811], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 33: Reward=-322.18, route=[0, 7, 1, 3, 6, 2, 9, 5, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1777,    -inf, -0.4022, -0.3326, -2.8038, -1.8741,
        -3.6632,  0.1078], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9177,    -inf, -0.3736, -0.2959, -2.9750, -1.6272,
        -3.6335,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.0380,    -inf,    -inf,    -inf, -2.6372,    -inf,
        -2.8429,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5470,    -inf,
        -3.2802,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 34: Reward=-280.87, route=[0, 1, 3, 9, 5, 4, 7, 2, 6, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([   -inf,  1.2163, -1.2976,  0.3252,  0.9160,    -inf, -2.4352, -1.6156,
        -2.6834, -0.1809], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1315,  0.3295,  0.0182,    -inf, -2.7722, -1.8076,
        -3.3299, -0.0653], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3079,    -inf,  0.5689,    -inf,    -inf, -1.7706,
        -2.9124, -0.1183], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5370,    -inf,    -inf,    -inf,    -inf, -1.9053,
        -3.8354,  0.3750], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.0496,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 35: Reward=-287.1, route=[0, 5, 1, 3, 6, 4, 9, 8, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1355,    -inf,  1.0936,    -inf,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5022,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 36: Reward=-226.37, route=[0, 1, 3, 9, 5, 6, 7, 8, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1777,    -inf, -0.4022, -0.3326, -2.8038, -1.8741,
        -3.6632,  0.1078], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9177,    -inf, -0.3736, -0.2959, -2.9750, -1.6272,
        -3.6335,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2578,    -inf,  0.9436,    -inf, -2.4367, -1.6468,
        -2.6860,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2907,    -inf,    -inf,    -inf,    -inf, -1.7498,
        -2.8996,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -1.7883,
        -3.2871,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
        -2.8566,    -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 37: Reward=-258.75, route=[0, 1, 3, 9, 5, 4, 6, 2, 7, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True False False False False]
greedy_action q_values = tensor([   -inf,  1.2018, -1.2971,    -inf,  0.9319,    -inf, -2.4384, -1.6277,
        -2.6897, -0.1796], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1326,    -inf,  0.0324,    -inf, -2.7721, -1.8246,
        -3.3395, -0.0651], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5430,    -inf,    -inf,    -inf, -2.6421, -1.8734,
        -3.8335,  0.3678], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9207,    -inf,    -inf,    -inf, -2.9752, -1.5659,
        -3.6347,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5540, -1.7572,
        -3.2847,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 38: Reward=-319.87, route=[0, 3, 5, 1, 4, 9, 2, 7, 6, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1679,    -inf,  1.0857, -1.4847,    -inf, -1.7300,
           -inf, -0.2035], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 39: Reward=-329.84, route=[0, 1, 3, 6, 8, 4, 5, 9, 2, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.0382,  0.0717,  0.7611, -1.2998, -2.6398,    -inf,
        -2.8420,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1361,  0.1116,    -inf,    -inf, -2.5449,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1391,    -inf,    -inf,    -inf, -2.7885,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 40: Reward=-277.73, route=[0, 1, 9, 7, 4, 5, 8, 3, 2, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1663,  0.0870,  1.0556, -1.5283, -2.5226, -1.6878,
           -inf, -0.1992], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.7672,    -inf, -0.7490, -2.5345, -1.7154,
           -inf,  0.1932], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf, -0.1027], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 41: Reward=-310.37, route=[0, 1, 8, 4, 2, 3, 5, 7, 6, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([   -inf,  1.2633, -1.0816,  0.0869,  0.7601, -1.3288, -2.6522,    -inf,
        -2.8514, -0.1957], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf, -0.2212], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 42: Reward=-318.74, route=[0, 7, 1, 5, 3, 6, 4, 2, 8, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([   -inf,  1.0011, -1.5593,  1.0204,    -inf, -0.4226, -2.6788, -1.8647,
        -3.8268,  0.3666], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
greedy_action q_values = tensor([   -inf,  1.1328, -1.1954,    -inf,    -inf, -0.3580, -2.8311, -1.8229,
        -3.6557,  0.1318], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1445,    -inf,    -inf, -0.6629, -2.7871, -1.8123,
        -3.3147, -0.0488], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9276,    -inf,    -inf, -0.3045, -2.9823, -1.5891,
        -3.6195,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 43: Reward=-255.75, route=[0, 4, 3, 1, 9, 5, 6, 8, 2, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9177,    -inf, -0.3736, -0.2959, -2.9750, -1.6272,
        -3.6335,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2578,    -inf,  0.9436,    -inf, -2.4367, -1.6468,
        -2.6860,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5156,    -inf,    -inf,    -inf, -2.6475, -1.8862,
        -3.8401,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5438, -1.6178,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6149,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 44: Reward=-236.32, route=[0, 1, 3, 9, 5, 4, 2, 8, 7, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
greedy_action q_values = tensor([   -inf,  1.1626,    -inf,  0.4730,    -inf, -1.1366,    -inf, -1.6917,
        -2.9107, -0.0792], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 45: Reward=-258.92, route=[0, 4, 2, 6, 1, 9, 7, 3, 5, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False  True False]
greedy_action q_values = tensor([   -inf,  1.2495, -1.1723,  0.1193,  1.0602,    -inf, -2.5365, -1.6631,
           -inf, -0.1922], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1423,  0.3358,  0.0080,    -inf, -2.7483, -1.7861,
           -inf, -0.0379], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5472,    -inf,    -inf,    -inf, -2.6236, -1.8536,
           -inf,  0.4058], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9175,    -inf,    -inf,    -inf, -2.9633, -1.5466,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6149,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 46: Reward=-261.15, route=[0, 5, 8, 1, 3, 4, 9, 2, 7, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3178,  0.4292,    -inf, -1.0945,    -inf,    -inf,
           -inf, -0.0921], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1717,    -inf,    -inf, -0.3266,    -inf,    -inf,
           -inf,  0.1312], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9188,    -inf,    -inf, -0.2956,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2680,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 47: Reward=-271.19, route=[0, 1, 4, 8, 7, 6, 3, 9, 5, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5459,    -inf,    -inf, -0.3766, -2.6526, -1.8852,
        -3.8255,  0.3679], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1430,    -inf,    -inf,    -inf, -2.5487, -1.6608,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 48: Reward=-253.02, route=[0, 1, 3, 4, 9, 5, 8, 2, 6, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([   -inf,  1.2774, -1.1802,  0.1132,  1.0581, -1.5631, -2.5469, -1.6844,
           -inf, -0.1865], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9126,    -inf,    -inf,    -inf, -2.9573,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5268,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 49: Reward=-305.44, route=[0, 8, 1, 7, 3, 4, 5, 9, 2, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5468,  0.9842,    -inf,    -inf, -2.6482, -1.8588,
        -3.8271,  0.3576], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 50: Reward=-288.93, route=[0, 1, 5, 4, 3, 7, 8, 6, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False  True False]
greedy_action q_values = tensor([   -inf,  1.2495, -1.1723,  0.1193,  1.0602,    -inf, -2.5365, -1.6631,
           -inf, -0.1922], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf, -0.1703], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 51: Reward=-265.36, route=[0, 5, 8, 1, 3, 6, 2, 4, 7, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3114,    -inf,    -inf,    -inf,    -inf,    -inf,
        -2.8927, -0.1280], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 52: Reward=-314.24, route=[0, 1, 5, 4, 3, 7, 6, 9, 8, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([   -inf,  1.3311, -0.9192,  0.3005, -0.3869, -0.3426, -3.0020, -1.5939,
        -3.6264,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1007,  0.3483,  0.0296, -0.6904, -2.7888, -1.8603,
        -3.3250,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1485,    -inf,    -inf, -1.5008, -2.5588, -1.6814,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.7259, -2.5439, -1.7493,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 53: Reward=-251.67, route=[0, 9, 1, 3, 4, 8, 2, 5, 6, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1777,    -inf, -0.4022, -0.3326, -2.8038, -1.8741,
        -3.6632,  0.1078], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9177,    -inf, -0.3736, -0.2959, -2.9750, -1.6272,
        -3.6335,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2578,    -inf,  0.9436,    -inf, -2.4367, -1.6468,
        -2.6860,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5156,    -inf,    -inf,    -inf, -2.6475, -1.8862,
        -3.8401,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5540, -1.7572,
        -3.2847,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 54: Reward=-235.73, route=[0, 1, 3, 9, 5, 4, 2, 7, 8, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5459,    -inf,    -inf, -0.3766, -2.6526, -1.8852,
        -3.8255,  0.3679], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9276,    -inf,    -inf, -0.3045, -2.9823, -1.5891,
        -3.6195,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.0509,    -inf,    -inf,    -inf, -2.6223,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5268,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 55: Reward=-234.76, route=[0, 1, 3, 4, 9, 5, 8, 7, 2, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([   -inf,  1.2163, -1.2976,  0.3252,  0.9160,    -inf, -2.4352, -1.6156,
        -2.6834, -0.1809], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5114,  0.9748,    -inf,    -inf, -2.6257,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 56: Reward=-265.94, route=[0, 5, 1, 8, 7, 9, 4, 3, 6, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.0603,    -inf,  0.7760, -1.2720, -2.6217,    -inf,
        -2.8527, -0.2034], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.7460,    -inf,    -inf,
        -3.2789,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 57: Reward=-296.75, route=[0, 1, 3, 7, 4, 6, 9, 2, 5, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.0118,    -inf,  0.7722,  0.2029, -0.7969, -2.5619, -1.7631,
        -3.2985,  0.1483], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.4271,    -inf, -1.1216,    -inf,    -inf,
        -2.8962, -0.1131], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.3104,    -inf,    -inf,
        -3.6198,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 58: Reward=-288.19, route=[0, 2, 1, 4, 7, 6, 3, 9, 5, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.2865,  0.2994,  0.9138,    -inf, -2.4142, -1.6204,
        -2.6758, -0.1929], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.0676,  0.0792,    -inf,    -inf, -2.6290,    -inf,
        -2.8344, -0.1977], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1523,    -inf,    -inf,    -inf, -2.5229,    -inf,
           -inf, -0.2209], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9126,    -inf,    -inf,    -inf, -2.9573,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5268,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 59: Reward=-338.27, route=[0, 1, 5, 4, 7, 3, 8, 9, 2, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1141, -1.1838,    -inf, -0.4032, -0.3555, -2.8261, -1.8652,
        -3.6732,  0.1189], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.0603,    -inf,  0.7760, -1.2720, -2.6217,    -inf,
        -2.8527, -0.2034], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5335,    -inf,    -inf, -0.3860, -2.6432,    -inf,
        -3.8162,  0.3485], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1387,    -inf,    -inf, -1.5144, -2.5555,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 60: Reward=-275.23, route=[0, 3, 1, 7, 4, 9, 8, 2, 6, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1777,    -inf, -0.4022, -0.3326, -2.8038, -1.8741,
        -3.6632,  0.1078], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5185,    -inf,    -inf, -0.3845, -2.6580, -1.8980,
        -3.8322,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.0496,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 61: Reward=-222.33, route=[0, 1, 3, 9, 4, 5, 6, 8, 7, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([   -inf,  1.3311, -0.9192,  0.3005, -0.3869, -0.3426, -3.0020, -1.5939,
        -3.6264,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2592,  0.3062,  0.9266,    -inf, -2.4348, -1.6357,
        -2.6801,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5195,  0.9884,    -inf,    -inf, -2.6536, -1.8716,
        -3.8338,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1430,    -inf,    -inf,    -inf, -2.5487, -1.6608,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 62: Reward=-287.6, route=[0, 9, 1, 5, 4, 3, 8, 2, 6, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
greedy_action q_values = tensor([   -inf,  1.1328, -1.1954,    -inf,    -inf, -0.3580, -2.8311, -1.8229,
        -3.6557,  0.1318], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3210,    -inf,    -inf,    -inf,    -inf, -1.7359,
        -2.8976, -0.1048], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1504,    -inf,    -inf,    -inf,    -inf, -1.6945,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 63: Reward=-290.82, route=[0, 4, 3, 1, 5, 6, 9, 8, 2, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1777,    -inf, -0.4022, -0.3326, -2.8038, -1.8741,
        -3.6632,  0.1078], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5185,    -inf,    -inf, -0.3845, -2.6580, -1.8980,
        -3.8322,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5438, -1.6178,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6149,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 64: Reward=-229.95, route=[0, 1, 3, 9, 4, 5, 2, 8, 7, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1406,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf, -0.0461], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 65: Reward=-327.61, route=[0, 7, 6, 3, 8, 4, 5, 1, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([   -inf,  1.3311, -0.9192,  0.3005, -0.3869, -0.3426, -3.0020, -1.5939,
        -3.6264,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2646,  0.3354,    -inf,    -inf, -2.4509, -1.5960,
        -2.6605,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 66: Reward=-295.86, route=[0, 9, 1, 4, 5, 3, 7, 6, 8, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.2769,    -inf,  0.9245,    -inf, -2.4135,    -inf,
        -2.6777, -0.2156], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3114,    -inf,    -inf,    -inf,    -inf,    -inf,
        -2.8927, -0.1280], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9130,    -inf,    -inf,    -inf,    -inf,    -inf,
        -3.6196,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
        -3.2825,    -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 67: Reward=-310.78, route=[0, 1, 3, 7, 5, 4, 6, 9, 2, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([   -inf,  1.2633, -1.0816,  0.0869,  0.7601, -1.3288, -2.6522,    -inf,
        -2.8514, -0.1957], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1224,  0.3322,  0.0097, -0.6955, -2.7690,    -inf,
        -3.3111, -0.0811], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True  True False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.7395, -2.5217,    -inf,
           -inf,  0.1803], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.4241,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 68: Reward=-291.21, route=[0, 7, 1, 3, 8, 4, 2, 9, 5, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  0.2095, -0.7457, -2.5370, -1.7798,
        -3.2947,  0.1469], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -1.0855,    -inf, -1.7087,
        -2.9096, -0.0895], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.2955,    -inf, -1.5935,
        -3.6323,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 69: Reward=-267.54, route=[0, 1, 3, 2, 4, 6, 9, 5, 7, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.0118,    -inf,  0.7722,  0.2029, -0.7969, -2.5619, -1.7631,
        -3.2985,  0.1483], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.3410,  0.0080, -0.6841, -2.7734, -1.8067,
        -3.3331, -0.0583], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  0.7699, -1.2418,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.3563,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 70: Reward=-310.96, route=[0, 2, 1, 3, 6, 8, 9, 7, 4, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([   -inf,  1.2774, -1.1802,  0.1132,  1.0581, -1.5631, -2.5469, -1.6844,
           -inf, -0.1865], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1406,  0.3497,  0.0106, -0.6649, -2.7548, -1.8155,
           -inf, -0.0339], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1749,    -inf, -0.4125, -0.3120, -2.7890, -1.8547,
           -inf,  0.1374], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  0.2113, -0.7270, -2.5322, -1.7830,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.4280, -1.5545,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 71: Reward=-248.67, route=[0, 8, 1, 3, 9, 2, 4, 5, 7, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1141, -1.1838,    -inf, -0.4032, -0.3555, -2.8261, -1.8652,
        -3.6732,  0.1189], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1315,    -inf,  0.0353, -0.6597, -2.7785, -1.8527,
        -3.3292, -0.0612], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -1.1010,    -inf,    -inf,
        -2.9037, -0.1126], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 72: Reward=-278.82, route=[0, 3, 1, 4, 2, 7, 6, 9, 5, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([   -inf,  1.2163, -1.2976,  0.3252,  0.9160,    -inf, -2.4352, -1.6156,
        -2.6834, -0.1809], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True False False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  1.0787,    -inf, -2.5306, -1.6571,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 73: Reward=-321.27, route=[0, 5, 1, 2, 9, 3, 8, 4, 7, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5185,    -inf,    -inf, -0.3845, -2.6580, -1.8980,
        -3.8322,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.0380,    -inf,    -inf,    -inf, -2.6372,    -inf,
        -2.8429,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5405,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 74: Reward=-249.99, route=[0, 1, 3, 9, 4, 5, 7, 2, 8, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([   -inf,  0.9898, -1.5533,  1.0211,    -inf, -0.4190,    -inf, -1.8966,
        -3.8287,  0.3739], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False  True False]
greedy_action q_values = tensor([   -inf,  1.2697, -1.1877,    -inf,    -inf, -1.5190,    -inf, -1.6877,
           -inf, -0.1801], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1469,    -inf,    -inf, -0.6371,    -inf, -1.8297,
           -inf, -0.0224], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9238,    -inf,    -inf, -0.2802,    -inf, -1.6018,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2779,    -inf,    -inf,    -inf,    -inf, -1.6245,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 75: Reward=-293.54, route=[0, 6, 4, 3, 8, 1, 9, 5, 2, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([   -inf,  1.2633, -1.0816,  0.0869,  0.7601, -1.3288, -2.6522,    -inf,
        -2.8514, -0.1957], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1224,  0.3322,  0.0097, -0.6955, -2.7690,    -inf,
        -3.3111, -0.0811], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 76: Reward=-305.2, route=[0, 7, 1, 3, 5, 6, 4, 8, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True False  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True False  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2918,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 77: Reward=-284.53, route=[0, 3, 4, 5, 7, 9, 8, 1, 6, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5370,    -inf,    -inf,    -inf,    -inf, -1.9053,
        -3.8354,  0.3750], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 78: Reward=-276.69, route=[0, 1, 3, 6, 5, 4, 9, 2, 7, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1723,  0.0851,  1.0650, -1.5083,    -inf, -1.7211,
           -inf, -0.2036], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5480,  0.9940,    -inf, -0.3664,    -inf, -1.8827,
           -inf,  0.4029], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3069,    -inf,    -inf,    -inf,    -inf, -1.6096,
           -inf, -0.1460], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9169,    -inf,    -inf,    -inf,    -inf, -1.5785,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -1.7759,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 79: Reward=-333.06, route=[0, 1, 6, 8, 4, 3, 5, 9, 2, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3063,  0.4252,  0.5584, -1.1008,    -inf, -1.7702,
        -2.9083, -0.1088], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 80: Reward=-309.08, route=[0, 1, 6, 4, 2, 9, 8, 3, 7, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1663,  0.0870,  1.0556, -1.5283, -2.5226, -1.6878,
           -inf, -0.1992], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2808,  0.3312,    -inf,    -inf,    -inf, -1.6138,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 81: Reward=-353.72, route=[0, 1, 8, 4, 6, 9, 5, 3, 7, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([   -inf,  1.2633, -1.0816,  0.0869,  0.7601, -1.3288, -2.6522,    -inf,
        -2.8514, -0.1957], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9059,  0.2689, -0.3925, -0.3342, -2.9727,    -inf,
        -3.6068,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1336,    -inf,  1.0873, -1.5140, -2.5423,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2910,    -inf,    -inf, -1.0710,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2680,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 82: Reward=-254.1, route=[0, 7, 1, 9, 3, 8, 4, 6, 5, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([   -inf,  1.2774, -1.1802,  0.1132,  1.0581, -1.5631, -2.5469, -1.6844,
           -inf, -0.1865], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1406,  0.3497,  0.0106, -0.6649, -2.7548, -1.8155,
           -inf, -0.0339], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1749,    -inf, -0.4125, -0.3120, -2.7890, -1.8547,
           -inf,  0.1374], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  0.2236,    -inf,    -inf, -1.8109,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -1.8806,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 83: Reward=-251.2, route=[0, 8, 1, 3, 9, 6, 5, 2, 4, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.7292,  0.1917, -0.7476,    -inf,    -inf,
           -inf,  0.1616], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.3485,    -inf,    -inf,
           -inf,  0.4048], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 84: Reward=-278.99, route=[0, 1, 6, 7, 8, 2, 3, 4, 9, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9177,    -inf, -0.3736, -0.2959, -2.9750, -1.6272,
        -3.6335,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 85: Reward=-271.85, route=[0, 1, 3, 9, 5, 7, 4, 6, 2, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([   -inf,  1.2774, -1.1802,  0.1132,  1.0581, -1.5631, -2.5469, -1.6844,
           -inf, -0.1865], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1406,  0.3497,  0.0106, -0.6649, -2.7548, -1.8155,
           -inf, -0.0339], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf, -0.3931, -0.2802, -2.9663, -1.5804,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  0.9175,    -inf, -2.4104, -1.5937,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6297, -1.8488,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6149,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 86: Reward=-323.34, route=[0, 8, 1, 3, 2, 9, 5, 4, 7, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([   -inf,  1.2774, -1.1802,  0.1132,  1.0581, -1.5631, -2.5469, -1.6844,
           -inf, -0.1865], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1406,  0.3497,  0.0106, -0.6649, -2.7548, -1.8155,
           -inf, -0.0339], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.2984,    -inf,  0.9199,    -inf, -2.3972, -1.6198,
           -inf, -0.1666], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5472,    -inf,    -inf,    -inf, -2.6236, -1.8536,
           -inf,  0.4058], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9175,    -inf,    -inf,    -inf, -2.9633, -1.5466,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 87: Reward=-311.8, route=[0, 8, 1, 3, 5, 4, 9, 2, 7, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.7448,  0.1977, -0.7686, -2.5398, -1.7614,
        -3.2881,  0.1388], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf, -0.4151, -0.3312, -2.8050, -1.8483,
        -3.6784,  0.1112], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 88: Reward=-271.55, route=[0, 1, 2, 3, 9, 6, 4, 5, 7, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([   -inf,  1.2774, -1.1802,  0.1132,  1.0581, -1.5631, -2.5469, -1.6844,
           -inf, -0.1865], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True False False  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.4664,    -inf,    -inf,    -inf, -1.6873,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -1.8325,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 89: Reward=-293.59, route=[0, 8, 1, 9, 5, 4, 2, 6, 3, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9109,  0.2771, -0.3850, -0.3196, -2.9777, -1.6048,
        -3.6190,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1520,    -inf, -0.3918, -0.3436, -2.8117, -1.8959,
        -3.6691,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2578,    -inf,  0.9436,    -inf, -2.4367, -1.6468,
        -2.6860,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
        -2.9059,    -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 90: Reward=-276.83, route=[0, 1, 9, 3, 5, 4, 7, 2, 6, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.7448,  0.1977, -0.7686, -2.5398, -1.7614,
        -3.2881,  0.1388], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf, -0.4151, -0.3312, -2.8050, -1.8483,
        -3.6784,  0.1112], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.3772, -2.6586, -1.8804,
        -3.8517,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.4491, -1.5681,
        -2.6751,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6313,    -inf,
        -2.8568,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
        -2.9059,    -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 91: Reward=-265.76, route=[0, 1, 2, 3, 9, 4, 5, 7, 6, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False  True False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  0.1986,    -inf, -2.5199,    -inf,
        -3.2936,  0.1232], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6327,    -inf,
        -3.8435,  0.3596], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5405,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 92: Reward=-268.73, route=[0, 1, 3, 5, 7, 2, 4, 9, 8, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([   -inf,  1.0011, -1.5593,  1.0204,    -inf, -0.4226, -2.6788, -1.8647,
        -3.8268,  0.3666], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True  True  True]
greedy_action q_values = tensor([   -inf,  1.2297, -1.0717,    -inf,    -inf, -1.2749,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 93: Reward=-288.8, route=[0, 4, 3, 8, 6, 9, 7, 1, 5, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([   -inf,  1.2163, -1.2976,  0.3252,  0.9160,    -inf, -2.4352, -1.6156,
        -2.6834, -0.1809], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1598,  0.0930,  1.0559,    -inf, -2.5124, -1.6669,
           -inf, -0.2054], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5510,  0.9888,    -inf,    -inf, -2.6297, -1.8390,
           -inf,  0.3956], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1751,    -inf,    -inf,    -inf, -2.7893, -1.7919,
           -inf,  0.1591], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9175,    -inf,    -inf,    -inf, -2.9633, -1.5466,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6149,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 94: Reward=-290.4, route=[0, 5, 1, 8, 4, 3, 9, 2, 7, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3063,  0.4252,  0.5584, -1.1008,    -inf, -1.7702,
        -2.9083, -0.1088], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.5438,  0.9895,    -inf, -0.3930,    -inf, -1.9025,
        -3.8211,  0.3649], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1859,    -inf,    -inf, -0.3300,    -inf, -1.8677,
        -3.6469,  0.1214], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9269,    -inf,    -inf, -0.2955,    -inf, -1.6210,
        -3.6185,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -1.6518,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 95: Reward=-255.04, route=[0, 1, 6, 4, 3, 9, 5, 2, 8, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([   -inf,  1.0011, -1.5593,  1.0204,    -inf, -0.4226, -2.6788, -1.8647,
        -3.8268,  0.3666], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
greedy_action q_values = tensor([   -inf,  1.1328, -1.1954,    -inf,    -inf, -0.3580, -2.8311, -1.8229,
        -3.6557,  0.1318], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1406,    -inf,    -inf,    -inf,    -inf,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 96: Reward=-265.95, route=[0, 4, 3, 1, 5, 6, 7, 9, 8, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([   -inf,  1.1299, -1.3170,  0.4506,  0.5612, -1.1328,    -inf, -1.7647,
        -2.9155, -0.0965], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5012,  0.9710,    -inf,    -inf,    -inf,    -inf,
        -3.8263,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1399,    -inf,    -inf,    -inf,    -inf,    -inf,
        -3.6504,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 97: Reward=-292.27, route=[0, 6, 1, 9, 5, 7, 4, 3, 2, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([   -inf,  1.3311, -0.9192,  0.3005, -0.3869, -0.3426, -3.0020, -1.5939,
        -3.6264,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1007,  0.3483,  0.0296, -0.6904, -2.7888, -1.8603,
        -3.3250,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1520,    -inf, -0.3918, -0.3436, -2.8117, -1.8959,
        -3.6691,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,  0.2176,    -inf, -2.5421, -1.7906,
        -3.3028,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6313,    -inf,
        -2.8568,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
        -2.9059,    -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 98: Reward=-263.99, route=[0, 9, 1, 3, 5, 2, 4, 7, 6, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.2736, -0.3955, -0.3196, -2.9811, -1.5773,
        -3.6329,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf, -0.4048, -0.3424, -2.8124, -1.8715,
        -3.6845,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -1.8806,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 99: Reward=-300.63, route=[0, 1, 2, 9, 3, 5, 6, 8, 4, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1777,    -inf, -0.4022, -0.3326, -2.8038, -1.8741,
        -3.6632,  0.1078], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9177,    -inf, -0.3736, -0.2959, -2.9750, -1.6272,
        -3.6335,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.0380,    -inf,    -inf,    -inf, -2.6372,    -inf,
        -2.8429,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5405,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 100: Reward=-285.47, route=[0, 1, 3, 9, 5, 4, 7, 2, 8, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1898,    -inf,    -inf, -0.3351, -2.8089, -1.8312,
        -3.6456,  0.1197], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.0407,    -inf,    -inf, -1.2739, -2.6429,    -inf,
        -2.8364,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.7607, -2.5583,    -inf,
        -3.2766,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 101: Reward=-228.9, route=[0, 1, 4, 3, 9, 7, 2, 5, 8, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.2882,    -inf,  0.9412,    -inf,    -inf, -1.6610,
        -2.6857, -0.1880], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1689,    -inf,    -inf,    -inf,    -inf, -1.6707,
           -inf, -0.1996], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 102: Reward=-303.85, route=[0, 1, 3, 6, 5, 4, 8, 9, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3063,  0.4252,  0.5584, -1.1008,    -inf, -1.7702,
        -2.9083, -0.1088], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.7947,    -inf,    -inf,    -inf, -1.7581,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 103: Reward=-335.17, route=[0, 1, 6, 4, 8, 9, 5, 2, 3, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1663,  0.0870,  1.0556, -1.5283, -2.5226, -1.6878,
           -inf, -0.1992], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.3055,    -inf,    -inf,    -inf, -2.4148, -1.5806,
           -inf, -0.1491], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 104: Reward=-332.36, route=[0, 1, 8, 4, 3, 5, 9, 6, 7, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9102,  0.2757, -0.3714, -0.3103,    -inf, -1.6366,
        -3.6179,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1492,    -inf, -0.3747, -0.3382,    -inf, -1.9309,
        -3.6703,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.1453,    -inf,  1.0953,    -inf,    -inf, -1.7337,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5139,    -inf,    -inf,    -inf,    -inf, -1.8982,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -1.7759,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 105: Reward=-282.37, route=[0, 1, 6, 9, 3, 5, 8, 4, 2, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False  True False  True]
greedy_action q_values = tensor([   -inf,  1.2188, -1.0511,  0.0952,  0.7678,    -inf, -2.6581,    -inf,
        -2.8569,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,  0.7497,  0.1937,    -inf, -2.5349,    -inf,
        -3.2922,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.6387,    -inf,
        -3.8503,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,
        -2.9059,    -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 106: Reward=-297.73, route=[0, 5, 9, 7, 1, 2, 3, 4, 6, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.0118,    -inf,  0.7722,  0.2029, -0.7969, -2.5619, -1.7631,
        -3.2985,  0.1483], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf, -0.2792,    -inf, -1.5742,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 107: Reward=-326.58, route=[0, 2, 1, 3, 8, 4, 6, 9, 5, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1299,  0.3433,  0.0208, -0.6820, -2.7787, -1.8370,
        -3.3192, -0.0613], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2578,    -inf,  0.9436,    -inf, -2.4367, -1.6468,
        -2.6860,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -1.7127,
        -2.9117,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 108: Reward=-231.72, route=[0, 1, 3, 9, 5, 4, 2, 6, 7, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf,  1.1223, -1.2803,  0.4525,  0.2395, -0.8910, -2.6638, -1.8482,
        -3.1807, -0.0725], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1749,    -inf, -0.4125, -0.3120, -2.7890, -1.8547,
           -inf,  0.1374], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.0492,    -inf,  0.7744, -1.2570, -2.6215,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.5104,    -inf,    -inf, -0.3672, -2.6301,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -1.2666,    -inf,    -inf,    -inf, -2.4296,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.5268,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 109: Reward=-282.02, route=[0, 1, 8, 3, 9, 7, 4, 5, 2, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([   -inf,  1.2633, -1.0816,  0.0869,  0.7601, -1.3288, -2.6522,    -inf,
        -2.8514, -0.1957], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -1.1224,  0.3322,  0.0097, -0.6955, -2.7690,    -inf,
        -3.3111, -0.0811], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -0.9127,    -inf, -0.3811, -0.3105, -2.9700,    -inf,
        -3.6213,    -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([  -inf,   -inf,   -inf,   -inf, 0.2116,   -inf,   -inf,   -inf,   -inf,
          -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 110: Reward=-217.2, route=[0, 7, 1, 3, 9, 5, 8, 6, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True  True False]
greedy_action q_values = tensor([   -inf,    -inf, -2.8978, -1.3194, -1.2500, -3.3479, -3.1179,    -inf,
           -inf, -1.2588], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False  True  True False]
greedy_action q_values = tensor([   -inf,    -inf, -3.0938, -1.1693,    -inf,    -inf, -2.8612,    -inf,
           -inf, -1.1879], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True False]
greedy_action q_values = tensor([   -inf,    -inf, -2.9283,    -inf,    -inf,    -inf, -3.1196,    -inf,
           -inf, -0.9354], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -2.9624,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 111: Reward=-279.07, route=[0, 1, 8, 7, 4, 5, 3, 9, 2, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([   -inf,  0.0249, -2.9373,    -inf, -2.4227, -2.8415, -3.1743, -3.4619,
        -4.3340, -0.9596], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -2.8244,    -inf, -1.9242, -2.9501, -3.2510, -3.4742,
        -4.0409, -1.1459], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -2.7849,    -inf, -2.3799, -2.8586, -3.4374, -3.2325,
        -4.2492,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 112: Reward=-259.38, route=[0, 3, 1, 9, 4, 8, 2, 7, 5, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf, -2.8872, -1.3285, -1.2409, -3.3685, -3.1227,    -inf,
        -3.7093, -1.2815], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False False  True False False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf, -1.6167,    -inf, -4.9067, -3.5325,    -inf,
        -5.2779, -1.6656], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -3.5681,    -inf,
           -inf, -2.2779], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -3.9010,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 113: Reward=-295.35, route=[0, 1, 7, 4, 2, 3, 5, 8, 9, 6] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf, -1.0509, -4.7691, -1.9470, -3.6779, -5.1010, -3.6882, -4.5742,
        -5.1134, -1.9418], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -4.6818, -2.0729, -3.9874, -5.2367, -3.7931, -4.5250,
        -4.9851, -2.0843], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -4.7590,    -inf, -4.4312, -5.1154, -3.7194, -4.5670,
        -5.2415, -1.8843], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -4.6862,    -inf, -4.4724, -5.2923, -3.9342, -4.4362,
        -5.0743,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -4.7803,    -inf, -3.0047,    -inf,    -inf, -4.4854,
        -4.9086,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -4.8622,    -inf,    -inf,    -inf,    -inf, -4.5089,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 114: Reward=-255.44, route=[0, 1, 3, 9, 6, 5, 4, 8, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf, -1.0509, -4.7691, -1.9470, -3.6779, -5.1010, -3.6882, -4.5742,
        -5.1134, -1.9418], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -4.6818, -2.0729, -3.9874, -5.2367, -3.7931, -4.5250,
        -4.9851, -2.0843], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False  True False]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf, -3.6314,    -inf, -3.5094, -4.5824,
           -inf, -1.6217], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf, -6.2009,    -inf, -4.6461, -5.7183,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 115: Reward=-311.29, route=[0, 1, 3, 5, 8, 2, 9, 6, 4, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True  True False]
greedy_action q_values = tensor([   -inf, -2.0909, -6.2494, -3.4219, -4.8406, -7.3413, -4.4590,    -inf,
           -inf, -2.8061], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  0.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf, -6.1585, -3.0516,    -inf, -7.4963, -4.6615,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 116: Reward=-233.8, route=[0, 8, 7, 1, 4, 9, 3, 5, 6, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([   -inf, -2.3322, -6.2465,    -inf, -6.0404, -7.2595, -4.5239, -5.8810,
        -6.4648, -2.5394], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False False]
greedy_action q_values = tensor([   -inf,    -inf, -6.1511,    -inf, -4.5967,    -inf, -4.1214, -5.6375,
        -6.2686, -2.6672], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -6.1678,    -inf, -6.1691,    -inf, -4.6579, -5.7473,
        -6.2797,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf, -5.1383,    -inf,    -inf, -5.8807,
        -6.6230,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 117: Reward=-282.13, route=[0, 3, 1, 5, 9, 6, 2, 4, 8, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([   -inf, -3.2814, -7.5874, -4.0456, -6.8946, -9.1386, -5.1141, -7.0705,
        -7.9137, -3.2510], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([   -inf, -3.6735, -7.6580, -4.1512, -7.9019, -9.6380, -5.5556, -7.1898,
        -7.9026,    -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -7.4797, -4.1419, -6.1631,    -inf, -4.9208, -6.8606,
        -7.7944,    -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -7.6830,    -inf, -7.7393,    -inf, -5.3291, -7.3142,
        -8.1136,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([   -inf,    -inf, -7.5253,    -inf, -6.4696,    -inf,    -inf, -7.0201,
        -7.8854,    -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([   -inf,    -inf, -7.6413,    -inf,    -inf,    -inf,    -inf,    -inf,
        -7.5414,    -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 118: Reward=-302.28, route=[0, 9, 1, 5, 3, 6, 4, 7, 8, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True False False False False]
greedy_action q_values = tensor([   -inf, -3.0934,    -inf, -4.1290, -6.1818,    -inf, -4.9218, -6.8330,
        -7.8091, -3.2107], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -5.4940, -7.1333,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -6.9787,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 119: Reward=-308.45, route=[0, 2, 5, 1, 3, 8, 4, 9, 6, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,  -9.0864,  -5.6940,  -8.1682, -11.1943,     -inf,
            -inf,  -9.1171,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,  -9.2150,     -inf,  -9.4437, -11.5291,     -inf,
            -inf,  -9.6667,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 120: Reward=-278.36, route=[0, 9, 1, 6, 7, 3, 2, 5, 8, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,  -4.8724,  -8.3274, -10.9363,  -5.7817,
         -8.4759,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,  -9.5066, -11.5535,  -6.2684,
         -8.7580,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,  -8.1327, -10.9373,     -inf,
         -8.3670,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 121: Reward=-324.97, route=[0, 1, 8, 9, 2, 3, 6, 4, 5, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,  -6.4713, -10.7896,     -inf, -11.3008, -13.8999,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -10.5673,     -inf,     -inf, -13.4941,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 122: Reward=-262.35, route=[0, 6, 8, 9, 7, 3, 1, 4, 2, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf,  -6.0058, -10.5701,  -6.4907, -10.3941, -13.3815,  -7.1385,
         -9.9546, -11.0820,  -4.6961], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False  True]
greedy_action q_values = tensor([    -inf,  -6.0809,     -inf,  -5.9238,     -inf, -13.5705,     -inf,
        -10.3193, -11.4395,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,  -6.4875,     -inf,     -inf,     -inf, -13.9478,     -inf,
        -10.3238, -11.3246,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -13.7525,     -inf,
        -10.0647, -11.0636,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 123: Reward=-218.4, route=[0, 9, 6, 2, 4, 3, 1, 7, 8, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf,  -6.5511, -10.7562,  -6.7849, -11.5946, -14.2275,  -7.5838,
        -10.2669, -11.2573,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -10.7221,  -6.7493, -10.8587, -13.7586,  -7.3505,
        -10.0557, -11.0472,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -10.7831,     -inf, -11.3182, -13.9027,  -7.3564,
        -10.3226, -11.3108,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -10.5157,     -inf,  -9.8851, -13.0439,     -inf,
         -9.8500, -10.9516,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -11.3601,     -inf,     -inf,
            -inf, -12.4168,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 124: Reward=-296.66, route=[0, 9, 1, 3, 6, 7, 2, 5, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf,  -7.4345, -12.2441,  -7.7624, -12.2505, -15.6179,  -8.4238,
        -11.6555, -12.7641,  -5.7980], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,  -7.6012, -12.2571,  -7.1758,     -inf,     -inf,     -inf,
        -12.0819, -13.1546,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,  -7.0993, -12.2224,     -inf,     -inf,     -inf,     -inf,
        -11.1704,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -12.3687,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 125: Reward=-300.53, route=[0, 9, 5, 6, 4, 3, 8, 1, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf,  -7.4345, -12.2441,  -7.7624, -12.2505, -15.6179,  -8.4238,
        -11.6555, -12.7641,  -5.7980], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf,  -8.1788, -12.5789,  -8.2128, -13.5344, -16.6769,  -8.9109,
        -12.0551, -13.1013,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -12.3227,  -8.1751, -11.8383, -15.5736,  -8.5143,
            -inf, -12.4120,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([   -inf,    -inf,    -inf,    -inf,    -inf,    -inf, -9.5246,    -inf,
           -inf,    -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 126: Reward=-267.04, route=[0, 9, 1, 7, 3, 8, 4, 2, 5, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf,  -8.7507, -13.9263,  -9.0001, -13.8322, -17.4295,     -inf,
        -13.2667, -14.2530,  -7.3041], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf,  -9.5815,     -inf,     -inf, -15.3389, -18.7887,     -inf,
        -14.0097,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 127: Reward=-310.67, route=[0, 6, 9, 8, 2, 3, 1, 5, 7, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf,  -9.5478, -14.3654,     -inf, -15.3138, -18.7566, -10.3176,
        -13.9731, -14.9133,  -7.1121], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False  True  True  True]
greedy_action q_values = tensor([    -inf,  -8.9675,     -inf,     -inf, -14.0109, -17.8292,  -9.9130,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -14.8619, -18.4499, -10.1660,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -13.8534, -17.4350,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 128: Reward=-272.39, route=[0, 3, 9, 2, 8, 7, 1, 6, 4, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -10.8794, -15.9813, -10.0537,     -inf, -20.7236, -11.7371,
        -15.7495, -16.8335,  -8.6727], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False  True]
greedy_action q_values = tensor([    -inf, -11.5569, -16.6962, -11.2008,     -inf, -21.8351, -12.3102,
        -15.9168, -17.0063,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False  True]
greedy_action q_values = tensor([    -inf, -11.3193, -16.3928,     -inf,     -inf, -21.3940, -12.0976,
        -15.8448, -16.8818,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -16.3650,     -inf,     -inf, -20.9847, -11.8958,
        -15.4940, -16.5267,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -15.9487,     -inf,     -inf, -19.8098,     -inf,
        -15.0820, -16.1238,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -19.8689,     -inf,
            -inf, -16.3596,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 129: Reward=-246.88, route=[0, 4, 9, 3, 1, 6, 7, 2, 8, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True  True False]
greedy_action q_values = tensor([    -inf, -10.5717, -16.3178, -10.9583, -16.2213, -20.1997, -11.5015,
            -inf,     -inf,  -9.0871], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -16.0073, -10.1019,     -inf, -20.7329, -11.7213,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -16.4032,     -inf,     -inf, -21.3728, -12.0632,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 130: Reward=-244.27, route=[0, 8, 7, 9, 1, 4, 3, 6, 2, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -13.5040,     -inf, -13.0663, -20.6406,     -inf,     -inf,
        -18.0880, -19.2909,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -13.2596,     -inf,     -inf, -20.2720,     -inf,     -inf,
        -17.9827, -19.1342,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -19.6694,     -inf,     -inf,
        -17.6367, -18.7630,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 131: Reward=-232.61, route=[0, 2, 5, 6, 9, 3, 1, 7, 8, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -12.3998, -18.5075, -12.6085, -18.6322, -22.8089, -13.3479,
            -inf, -18.0980, -10.8609], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -18.5952, -12.7041, -19.6585, -23.7087, -13.8260,
            -inf, -18.6736,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -18.5916,     -inf, -20.2424, -24.1776, -14.0514,
            -inf, -19.0634,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -18.1280,     -inf, -18.4633, -22.3687,     -inf,
            -inf, -18.1756,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 132: Reward=-253.24, route=[0, 7, 9, 1, 3, 6, 2, 5, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -12.5726, -18.2460, -12.2690, -19.0864, -22.9948, -13.3972,
        -17.3350, -18.4759, -10.7319], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -13.4824, -18.9561, -13.0551, -20.6316, -24.6949, -14.3396,
        -18.0673, -19.2404,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -13.2409, -18.6000,     -inf, -20.2580, -24.1989, -14.0801,
        -17.9654, -19.0838,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -21.0408,     -inf, -21.2765, -25.6184, -15.3678,
            -inf, -20.4642,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -20.6600,     -inf, -21.0408, -25.1093,     -inf,
            -inf, -20.4477,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -20.7542,     -inf, -20.6434, -24.9839,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -20.7725,     -inf,     -inf, -26.2901,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 133: Reward=-238.29, route=[0, 9, 3, 1, 7, 6, 8, 4, 2, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -14.5771, -20.8192, -14.2160, -21.7048, -25.7955, -15.4381,
        -19.5925, -20.7903, -12.6915], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True False False False  True]
greedy_action q_values = tensor([    -inf, -14.2994,     -inf, -13.6350, -21.3666,     -inf, -15.1024,
        -19.5212, -20.7669,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True False False False  True]
greedy_action q_values = tensor([    -inf, -15.3615,     -inf,     -inf, -23.0338,     -inf, -16.2137,
        -20.3296, -21.5702,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf, -15.6800,
        -20.1381, -21.4439,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 134: Reward=-271.93, route=[0, 9, 5, 2, 3, 1, 4, 6, 8, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -14.2246, -20.6752, -14.0132, -21.0606, -25.1233,     -inf,
        -19.2772,     -inf, -12.6185], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -15.6375, -21.6696, -15.0947, -23.4094, -27.7048,     -inf,
        -20.4721,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -15.3470, -21.2944,     -inf, -22.9829, -27.1377,     -inf,
        -20.3393,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -23.8973,     -inf, -24.1424, -28.6510,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -24.1341, -28.1901,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 135: Reward=-257.43, route=[0, 8, 6, 9, 3, 1, 7, 2, 4, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -16.7929, -23.6655, -16.3835, -24.5483, -28.8340, -17.6749,
        -22.1130, -23.3409, -14.8903], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True  True]
greedy_action q_values = tensor([    -inf, -16.2147, -23.5509, -16.3747, -23.5050, -27.9848, -17.1769,
        -21.4101,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -23.9044, -16.7322, -24.1807, -28.6825, -17.5821,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -23.4585,     -inf, -23.8746, -28.1215,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -24.1341, -28.1901,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 136: Reward=-300.09, route=[0, 9, 8, 1, 7, 3, 6, 2, 4, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -16.7929, -23.6655, -16.3835, -24.5483, -28.8340, -17.6749,
        -22.1130, -23.3409, -14.8903], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -16.9469, -25.3310, -29.7692, -18.2309,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -25.9885, -30.3533, -18.5315,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 137: Reward=-296.64, route=[0, 9, 7, 2, 8, 1, 3, 6, 5, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -27.3123, -19.2563, -28.3862, -33.0672, -20.7707,
        -25.3720, -26.5703, -17.6807], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -26.5675, -18.6644, -26.5279, -31.1732, -19.6155,
        -24.1820,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -27.4783,     -inf, -29.1568, -33.7822, -21.1441,
        -25.9347,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -26.5008,     -inf, -26.9147, -31.3775,     -inf,
        -24.5966,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -26.9834,     -inf, -27.2279, -31.9403,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -27.1582, -31.4437,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 138: Reward=-298.66, route=[0, 1, 9, 8, 3, 6, 7, 2, 4, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -28.4351,     -inf, -20.7734,
        -25.4055, -26.6620, -17.7170], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -29.6929,     -inf, -21.5330,
        -26.1427, -27.4492,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -26.9506,     -inf,     -inf,
        -24.6117, -25.8452,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -26.9415,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 139: Reward=-302.86, route=[0, 2, 5, 3, 1, 9, 6, 7, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -19.2287, -26.7520, -18.6907, -27.6171, -32.1371, -20.1945,
        -24.9579, -26.1782, -17.3750], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False  True]
greedy_action q_values = tensor([    -inf, -21.4960,     -inf, -20.5842, -30.4955, -34.9777, -22.5811,
        -27.8663, -29.0967,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False False False False  True]
greedy_action q_values = tensor([    -inf, -22.3550,     -inf,     -inf,     -inf, -36.4489, -23.3941,
        -28.8120, -30.0998,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -36.8068, -23.7050,
        -28.5962, -29.8227,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -35.5495,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 140: Reward=-269.18, route=[0, 9, 2, 3, 4, 1, 6, 8, 7, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -31.8481, -36.7163,     -inf,
            -inf, -29.7721, -20.4829], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -33.1917, -38.2090,     -inf,
            -inf, -30.6703,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -29.7202,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 141: Reward=-259.81, route=[0, 6, 2, 7, 3, 1, 9, 8, 5, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -21.9101, -30.1838, -21.2714, -31.0077, -35.6913, -23.0126,
        -28.0284, -29.2599, -20.0878], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -22.9985, -31.0115,     -inf, -32.6316, -37.4829, -24.0760,
        -29.1664, -30.3758,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -33.5330,     -inf, -33.3348, -38.3867, -25.4649,
        -30.4812,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -33.2268,     -inf, -33.1319,     -inf,     -inf,
        -30.5125,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -34.1200,     -inf, -34.2468,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 142: Reward=-225.09, route=[0, 9, 3, 1, 8, 6, 5, 7, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -24.8864, -33.8912, -24.1028, -34.5844, -39.5980, -26.1731,
        -31.3691, -32.6238, -23.0972], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -26.5526, -35.5089, -25.5335, -36.9673, -42.3454, -27.8551,
        -32.8945, -34.1634,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True False False  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -35.6407,     -inf, -26.9558,
        -32.0505,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -33.8185,     -inf,     -inf,
        -30.9711,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -34.2974,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 143: Reward=-288.84, route=[0, 9, 3, 5, 8, 2, 1, 6, 7, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -24.8864, -33.8912, -24.1028, -34.5844, -39.5980, -26.1731,
        -31.3691, -32.6238, -23.0972], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False  True]
greedy_action q_values = tensor([    -inf, -25.3704, -34.0080, -23.8212,     -inf, -40.3951, -26.5988,
        -32.1776, -33.4492,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False False False False  True]
greedy_action q_values = tensor([    -inf, -24.4184,     -inf,     -inf,     -inf, -38.8162, -25.7080,
        -31.1959, -32.4393,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf, -28.5556,
        -34.1335, -35.3076,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -34.6478, -35.8299,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 144: Reward=-265.26, route=[0, 9, 4, 3, 2, 1, 5, 6, 7, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -28.1204, -37.8494, -27.1757, -38.4115, -43.7167, -29.5309,
        -35.1123, -36.2846, -26.4305], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False  True]
greedy_action q_values = tensor([    -inf, -27.8685, -38.0175, -27.5059, -38.0486, -43.4631, -29.3592,
            -inf, -35.8216,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False  True False  True]
greedy_action q_values = tensor([    -inf, -29.4554, -38.9671,     -inf, -40.3230, -45.8469, -30.8636,
            -inf, -37.6661,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -38.6882,     -inf, -39.4569, -44.9720, -30.3678,
            -inf, -36.9637,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -37.3487,     -inf, -37.4743, -42.7368,     -inf,
            -inf, -35.7169,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -37.0471,     -inf, -36.8276,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 145: Reward=-256.4, route=[0, 9, 7, 3, 1, 6, 8, 5, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False  True]
greedy_action q_values = tensor([    -inf, -27.8685, -38.0175, -27.5059, -38.0486, -43.4631, -29.3592,
            -inf, -35.8216,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False  True False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -39.5099, -45.0279, -30.3917,
            -inf, -37.0146,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -37.5287, -42.7949,     -inf,
            -inf, -35.7738,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 146: Reward=-295.59, route=[0, 9, 7, 3, 2, 1, 6, 8, 5, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -31.0170,     -inf, -29.6771, -41.8420, -47.2100, -32.5800,
        -38.8208, -39.7838, -29.6176], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False  True]
greedy_action q_values = tensor([    -inf, -33.7083,     -inf, -32.3467, -45.5054, -51.4646, -35.3738,
        -41.1866, -42.1373,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -30.6974,     -inf,     -inf, -41.2801,     -inf,     -inf,
        -38.1293,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -40.2751,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 147: Reward=-268.98, route=[0, 2, 9, 3, 6, 5, 8, 1, 4, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -31.0721,     -inf,     -inf, -41.8711,     -inf,     -inf,
            -inf,     -inf, -29.6601], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -33.7575,     -inf,     -inf, -45.5317,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 148: Reward=-272.54, route=[0, 7, 3, 6, 5, 8, 2, 9, 1, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -34.3386, -46.2081, -33.6890, -45.6969, -51.3183, -36.2367,
        -42.1698,     -inf, -33.3321], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True  True]
greedy_action q_values = tensor([    -inf, -37.7712, -49.2413, -36.1216, -50.3497, -56.4803, -39.6903,
        -45.7756,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False False  True  True]
greedy_action q_values = tensor([    -inf, -34.8993,     -inf,     -inf, -46.4637, -51.9935, -36.6686,
        -43.2189,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -45.5317,     -inf, -36.0852,
        -42.2896,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -46.3167,     -inf,     -inf,
        -42.9480,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 149: Reward=-290.24, route=[0, 8, 9, 3, 2, 1, 5, 6, 7, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -35.4783, -46.8932, -34.0992, -47.2329, -52.9159, -37.3337,
        -43.5545, -44.3296, -33.9254], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -37.7380, -49.1977, -36.0953, -50.3098, -56.4437, -39.6731,
        -45.7553, -46.5072,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -37.1304, -48.3481,     -inf, -49.4931, -55.4457, -39.0102,
        -45.3464, -46.0644,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -47.9485,     -inf, -48.5090, -54.4227, -38.3828,
        -44.4977, -45.2242,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -46.2783,     -inf, -46.1759, -51.7781,     -inf,
        -42.8732, -43.6232,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -47.0526,     -inf, -46.8337, -52.6013,     -inf,
            -inf, -43.8407,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -45.8684,     -inf, -45.4414,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 150: Reward=-212.62, route=[0, 9, 3, 1, 6, 7, 8, 5, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -35.4783, -46.8932, -34.0992, -47.2329, -52.9159, -37.3337,
        -43.5545, -44.3296, -33.9254], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -37.7380, -49.1977, -36.0953, -50.3098, -56.4437, -39.6731,
        -45.7553, -46.5072,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -41.4874, -53.5706,     -inf, -54.6738, -60.6780, -43.6869,
        -50.1679, -50.7429,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -52.3048,     -inf,     -inf, -59.0385, -42.4990,
        -49.3435, -49.9788,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -51.2742,     -inf,     -inf, -56.7357,     -inf,
        -47.4208, -48.0309,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -52.1074,     -inf,     -inf, -57.6294,     -inf,
            -inf, -48.2971,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 151: Reward=-214.01, route=[0, 9, 3, 1, 4, 6, 7, 8, 5, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -39.6689, -51.9281, -38.0635, -52.2260, -57.9401, -41.8164,
        -48.1811, -48.8157, -38.1857], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
greedy_action q_values = tensor([    -inf, -40.3256, -52.2319,     -inf,     -inf, -58.9496, -42.4478,
        -49.2592, -49.9049, -38.4668], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False  True  True]
greedy_action q_values = tensor([    -inf, -38.5138, -51.2096,     -inf,     -inf, -56.3077, -40.6578,
        -46.7441,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -53.1814,     -inf,     -inf, -59.6463, -43.0192,
        -49.2603,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -51.3195,     -inf,     -inf, -56.7804,     -inf,
        -47.4428,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -52.1582,     -inf,     -inf, -57.6744,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 152: Reward=-293.21, route=[0, 3, 4, 9, 8, 1, 6, 7, 2, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -39.6689, -51.9281, -38.0635, -52.2260, -57.9401, -41.8164,
        -48.1811, -48.8157, -38.1857], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True False False False  True]
greedy_action q_values = tensor([    -inf, -45.0320, -57.6814,     -inf,     -inf,     -inf, -47.3212,
        -54.5436, -54.9836,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -58.5929,     -inf,     -inf,     -inf, -47.8586,
        -54.4842, -54.8625,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -56.5447,     -inf,     -inf,     -inf,     -inf,
        -52.4542, -52.8708,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -56.4570,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 153: Reward=-272.53, route=[0, 3, 9, 5, 4, 1, 6, 7, 8, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -44.1976, -57.2371, -42.2171, -57.4386, -63.0691, -46.5335,
        -53.2733, -53.6873, -42.8722], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -56.3352,     -inf, -55.6826, -61.2026, -45.1846,
        -51.6376,     -inf, -42.1049], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -55.4879,     -inf, -44.9866,
        -51.6889,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -56.3762,     -inf,     -inf,
        -52.5280,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -57.1846,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 154: Reward=-289.59, route=[0, 3, 1, 8, 9, 2, 5, 6, 7, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -44.1976, -57.2371, -42.2171, -57.4386, -63.0691, -46.5335,
        -53.2733, -53.6873, -42.8722], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -46.1235, -59.0208,     -inf, -60.0145, -65.9324, -48.5454,
        -55.3951, -55.7557, -44.2084], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -46.9467, -60.0700,     -inf, -61.0574, -67.1676, -49.4228,
        -56.0461, -56.4167,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -58.5289,     -inf, -58.9708, -64.8388, -47.8253,
        -54.4537, -54.8021,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -57.6924,     -inf,     -inf, -64.2441,     -inf,
        -54.5591, -54.9494,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -62.8650,     -inf,     -inf, -67.6409,     -inf,
            -inf, -58.2066,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 155: Reward=-250.47, route=[0, 3, 9, 1, 6, 4, 7, 8, 2, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -64.0543, -47.8735, -64.4934, -69.8027, -52.7178,
        -59.6810, -59.9191, -48.8344], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -64.7104,     -inf, -65.6879, -71.0668, -53.5900,
        -60.8417, -61.0883, -49.3898], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf, -52.3339,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 156: Reward=-251.73, route=[0, 1, 3, 9, 2, 8, 5, 7, 4, 6] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -47.8484, -61.7641, -45.8075, -61.4823, -66.4652,     -inf,
        -57.4102, -57.6848, -47.1055], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -47.4329, -61.6677,     -inf, -60.9824, -65.9802,     -inf,
            -inf,     -inf, -46.9289], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -47.2543, -61.2639,     -inf, -60.6812,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -67.5480,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 157: Reward=-300.37, route=[0, 6, 3, 7, 8, 9, 5, 1, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
greedy_action q_values = tensor([    -inf, -54.6489, -68.7199,     -inf,     -inf, -74.0142, -57.1802,
        -65.2125, -65.0888, -53.6229], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False False False False  True]
greedy_action q_values = tensor([    -inf, -52.9196,     -inf,     -inf,     -inf, -71.5549, -55.3551,
        -63.2391, -63.1401,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -74.9459, -57.9322,
        -65.3978, -65.2240,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -71.4444,     -inf,
        -62.9254, -62.8193,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -70.9345,     -inf,
        -62.1686,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -72.6131,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 158: Reward=-265.47, route=[0, 3, 4, 9, 2, 1, 6, 8, 7, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -53.7965, -68.2340, -51.4055, -68.5827, -72.7940, -56.3128,
        -63.8759, -63.7526, -53.1185], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -56.0920, -70.4183,     -inf, -71.5634, -76.0469, -58.7335,
        -66.4272, -66.2377, -54.8572], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -57.0811, -71.6283,     -inf, -72.7987, -77.4510, -59.7843,
        -67.2399, -67.0408,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.2928,     -inf, -54.4545,
            -inf, -61.9193,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -67.3268,     -inf,     -inf,
            -inf, -62.8622,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 159: Reward=-249.97, route=[0, 3, 9, 1, 2, 7, 5, 6, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -53.7965, -68.2340, -51.4055, -68.5827, -72.7940, -56.3128,
        -63.8759, -63.7526, -53.1185], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -61.1545, -76.3066,     -inf, -77.5196, -80.8836, -63.8385,
        -71.9906, -71.4377, -60.7163], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -57.6971,     -inf,     -inf, -73.0809, -76.0901, -60.1602,
        -68.5007, -68.0526,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False  True False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -79.0067,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 160: Reward=-291.21, route=[0, 3, 9, 2, 1, 7, 6, 8, 4, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -58.6641, -73.9019, -56.5504, -74.3200, -77.4403, -61.2160,
        -69.2259, -68.7513, -58.7594], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -61.1545, -76.3066,     -inf, -77.5196, -80.8836, -63.8385,
        -71.9906, -71.4377, -60.7163], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.1706, -76.1736, -60.2110,
        -68.5678,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.0117, -76.0718,     -inf,
        -68.2306,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.0713, -77.2527,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -79.0067,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 161: Reward=-267.77, route=[0, 3, 9, 1, 8, 2, 6, 7, 4, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False  True]
greedy_action q_values = tensor([    -inf, -64.4620,     -inf, -62.1775,     -inf, -83.0733,     -inf,
        -76.1882, -75.2198,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf, -61.2763,     -inf,     -inf,     -inf,     -inf,     -inf,
        -72.3243, -71.5060,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -76.4073, -75.4112,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 162: Reward=-275.98, route=[0, 9, 6, 2, 4, 3, 5, 1, 8, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -83.1197, -65.4104, -84.9692, -86.7800, -69.7676,
        -78.4984,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.8793,     -inf,     -inf, -83.0640, -66.8477,
        -76.1951,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.0132,     -inf,     -inf, -80.0684,     -inf,
        -73.3882,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 163: Reward=-230.34, route=[0, 8, 1, 9, 3, 4, 6, 7, 5, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.3099, -79.0354, -61.7819, -80.0559, -81.5572, -65.6989,
        -74.5199, -73.5927, -64.7615], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -65.9948, -81.6716,     -inf, -83.4546, -85.1384, -68.5068,
        -77.4887, -76.4535, -66.9708], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.8273,     -inf, -82.0555, -83.6833, -67.3994,
        -76.1293, -75.1095, -66.2014], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.7504, -80.1603, -64.5836,
        -73.7456, -72.8496,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.2195, -83.7521,     -inf,
        -78.1636, -76.9327,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -77.1039,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 164: Reward=-272.0, route=[0, 3, 1, 9, 2, 6, 8, 4, 5, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -87.7836, -70.8999, -90.9096, -90.6712, -74.2122,
        -83.5590, -82.1194,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -86.4540,     -inf, -89.4947, -89.1623, -73.0222,
        -82.6608, -81.2461,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -82.2889,     -inf, -84.1079, -83.6434,     -inf,
        -78.0812, -76.8255,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -82.0812,     -inf, -83.5013, -83.0695,     -inf,
        -77.2148,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -83.6372,     -inf, -85.4208, -85.0218,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.4437, -83.9293,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 165: Reward=-239.97, route=[0, 1, 9, 3, 6, 8, 7, 2, 5, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.7124, -83.5028, -67.0197, -85.7611, -85.3036, -69.9327,
        -79.3561, -78.0796, -70.7742], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -85.4071,     -inf, -87.9002, -87.5284, -71.7412,
        -81.0843, -79.7092, -72.3571], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -82.2027,     -inf, -84.0113, -83.5326,     -inf,
        -77.9716, -76.7280, -69.6674], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -83.0114,     -inf,     -inf,
        -77.0347, -75.8806,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -89.2666,     -inf,     -inf,
        -81.4769,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 166: Reward=-272.7, route=[0, 3, 1, 6, 9, 2, 5, 8, 7, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.8687, -87.4416, -72.3475, -91.4558, -88.5042, -74.2094,
        -83.5825, -82.1027, -76.6849], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -89.4156, -74.1881, -93.7147, -90.8051, -76.1122,
        -85.3673, -83.7825, -78.3779], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -90.4672,     -inf, -95.3186, -92.3962, -77.3928,
        -86.9562, -85.3458, -79.4160], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -86.0728,     -inf, -89.6082, -86.6739,     -inf,
        -82.1203, -80.6764, -75.4744], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -91.9994,     -inf, -96.9346, -94.0868,     -inf,
        -88.1219, -86.4574,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -85.3097,     -inf, -88.5191,     -inf,     -inf,
        -81.1025,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 167: Reward=-269.88, route=[0, 1, 3, 6, 9, 8, 5, 7, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False  True False False]
greedy_action q_values = tensor([    -inf, -72.9680, -88.1947, -72.7510,     -inf, -89.8991, -75.3400,
            -inf, -83.6301, -77.5315], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False  True False False]
greedy_action q_values = tensor([    -inf, -74.9234, -90.4862,     -inf,     -inf, -92.4200, -77.4125,
            -inf, -85.3220, -79.4034], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -86.1313,     -inf,     -inf, -86.7268,     -inf,
            -inf, -80.6905, -75.5082], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -85.3682,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 168: Reward=-278.02, route=[0, 7, 4, 3, 1, 6, 9, 8, 5, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.5173, -90.1781, -77.3672, -96.3116, -90.7391, -77.3494,
        -86.6308, -85.5040, -82.0114], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -87.7416, -75.1175, -93.0290,     -inf, -74.6729,
        -83.7868, -82.7781, -79.7164], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.0240,     -inf,     -inf,     -inf,
        -88.5018, -87.3647, -83.1557], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -84.3545,     -inf, -80.4970], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 169: Reward=-269.82, route=[0, 1, 5, 6, 2, 4, 3, 8, 9, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -73.3640, -88.4365, -75.8668, -93.6743, -88.2076, -75.2062,
        -84.0549,     -inf, -80.1959], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -92.3054, -79.3913, -98.7774, -93.1789, -79.3903,
        -88.5485,     -inf, -83.8787], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -90.1968, -77.5268, -95.8431, -90.3301,     -inf,
            -inf,     -inf, -81.8047], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -87.8804,     -inf, -93.1433,     -inf,     -inf,
            -inf,     -inf, -79.8266], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -91.2693,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 170: Reward=-309.58, route=[0, 8, 1, 6, 7, 3, 5, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True False False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True False False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf, -82.7919,
        -92.3614, -91.9714,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -87.1935, -86.8768,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 171: Reward=-298.25, route=[0, 1, 2, 9, 5, 4, 3, 6, 8, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([     -inf,  -78.5335,  -91.5570,  -81.4755, -100.0922,  -92.0931,
         -79.1141,  -88.4626,  -88.0900,  -86.8287], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -90.1779, -80.1073, -98.1914, -90.3016,     -inf,
            -inf, -86.5907,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([     -inf,      -inf,  -94.8455,      -inf, -104.4464,  -96.3426,
             -inf,      -inf,  -91.7634,      -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -89.3086,     -inf, -96.9238,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -98.6391,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 172: Reward=-251.64, route=[0, 1, 9, 7, 6, 3, 8, 5, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([     -inf,  -78.5335,  -91.5570,  -81.4755, -100.0922,  -92.0931,
         -79.1141,  -88.4626,  -88.0900,  -86.8287], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([     -inf,      -inf,  -93.6258,  -83.5259, -102.5795,  -94.5263,
         -81.1568,  -90.3777,  -89.9433,  -88.7501], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -90.0775, -80.0049, -98.0672, -90.1743,     -inf,
        -86.8513, -86.4878, -85.3985], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
greedy_action q_values = tensor([     -inf,      -inf,  -90.0674,      -inf, -100.2461,  -89.6355,
             -inf,  -86.7659,      -inf,      -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -89.3933,     -inf, -99.6112,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([     -inf,      -inf,      -inf,      -inf, -101.3792,      -inf,
             -inf,      -inf,      -inf,      -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 173: Reward=-238.62, route=[0, 1, 6, 3, 9, 8, 7, 5, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -90.2277, -83.0498,     -inf, -90.1719,     -inf,
            -inf, -87.6110, -89.4014], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -94.8906,     -inf,     -inf, -96.2822,     -inf,
            -inf, -92.9076, -94.2054], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -90.0348,     -inf,     -inf, -89.5735,     -inf,
            -inf,     -inf, -88.9730], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 174: Reward=-317.39, route=[0, 4, 1, 7, 6, 3, 8, 9, 5, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False  True False False]
greedy_action q_values = tensor([     -inf,  -84.0831,      -inf,      -inf, -107.3447,  -96.3109,
         -83.2583,      -inf,  -92.9363,  -94.1900], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True  True  True  True]
greedy_action q_values = tensor([     -inf,  -86.7571,      -inf,      -inf, -111.1195,  -97.1555,
             -inf,      -inf,      -inf,      -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -92.9398,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 175: Reward=-302.95, route=[0, 2, 7, 3, 6, 8, 9, 1, 4, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([     -inf,  -86.5670,  -95.4465,  -91.6562, -110.8800,  -96.9557,
         -84.3388,  -93.3217,  -94.2182,      -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([     -inf,  -80.0469,  -89.3497,  -85.1961, -102.5190,  -89.1829,
             -inf,  -86.9946,  -87.7968,      -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -95.5805,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 176: Reward=-331.94, route=[0, 9, 6, 1, 8, 2, 4, 7, 3, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True  True]
greedy_action q_values = tensor([     -inf,  -79.3827,  -89.1057,  -85.0833, -101.7867,  -88.5476,
         -77.3862,  -86.0625,      -inf,      -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
greedy_action q_values = tensor([     -inf,  -80.1250,  -89.4316,  -85.2666, -102.6160,  -89.2599,
             -inf,  -87.0493,      -inf,      -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True  True]
greedy_action q_values = tensor([     -inf,      -inf,  -92.9828,  -89.0601, -107.4283,  -93.7261,
             -inf,  -90.6845,      -inf,      -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
greedy_action q_values = tensor([     -inf,      -inf,  -94.0998,      -inf, -109.2810,  -95.4206,
             -inf,  -92.4000,      -inf,      -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
greedy_action q_values = tensor([     -inf,      -inf,  -90.9397,      -inf, -104.2249,  -90.7399,
             -inf,      -inf,      -inf,      -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -89.8758,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 177: Reward=-274.79, route=[0, 9, 8, 6, 1, 3, 7, 5, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([     -inf,  -81.5476,  -88.8050,  -87.6554, -105.0364,  -89.0603,
         -78.3135,  -87.0154,  -88.7534,  -96.3266], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -82.8698, -89.5748, -88.2710,     -inf, -90.5667,     -inf,
        -88.7116, -90.4636, -97.4826], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -90.9112, -89.8885,     -inf, -91.5336,     -inf,
        -88.9228, -90.6747, -98.5471], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -86.0616,     -inf,     -inf,     -inf,
            -inf,     -inf, -95.0438], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 178: Reward=-227.44, route=[0, 6, 4, 1, 7, 8, 5, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([     -inf,  -79.1559,  -87.1590,  -85.9234, -102.0330,  -86.4011,
         -76.2348,  -84.4770,      -inf,  -94.1483], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([     -inf,  -79.8951,  -87.4448,  -86.1044, -102.8776,  -87.1269,
             -inf,  -85.4682,      -inf,  -94.7388], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
greedy_action q_values = tensor([     -inf,      -inf,  -90.9383,  -89.9387, -107.7898,  -91.5600,
             -inf,  -88.9559,      -inf,  -98.5682], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -89.6993, -88.4095,     -inf, -90.6720,     -inf,
            -inf,     -inf, -97.6040], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -92.1043,     -inf,     -inf, -93.2852,     -inf,
            -inf,     -inf, -99.9866], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -95.1374,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 179: Reward=-315.51, route=[0, 8, 6, 1, 7, 4, 3, 2, 9, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([     -inf,  -81.5476,  -88.8050,  -87.6554, -105.0364,  -89.0603,
         -78.3135,  -87.0154,  -88.7534,  -96.3266], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([     -inf,  -78.7281,  -84.7386,  -86.0008, -101.2910,  -84.2037,
             -inf,  -83.1212,  -85.4589,  -95.5362], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([     -inf,      -inf,  -88.1549,  -89.8479, -106.1741,  -88.5478,
             -inf,  -86.5041,  -89.0159,  -99.4217], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True  True]
greedy_action q_values = tensor([     -inf,      -inf,  -84.7243,  -86.0716, -100.7102,  -83.7126,
             -inf,      -inf,      -inf,      -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 180: Reward=-263.74, route=[0, 6, 1, 7, 9, 8, 5, 2, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([     -inf,  -78.9373,      -inf,  -85.8086, -101.5963,  -84.4578,
         -75.2408,  -83.5906,  -85.9809,  -95.6440], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([     -inf,      -inf,      -inf,      -inf, -108.3923,      -inf,
             -inf,      -inf,  -90.9752,      -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 181: Reward=-286.46, route=[0, 2, 6, 1, 7, 5, 9, 3, 8, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([     -inf,  -83.9860,  -89.1734,      -inf, -108.0409,  -90.1662,
         -79.9369,  -88.0600,  -90.6315, -100.7325], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([     -inf,  -78.7518,  -84.7704,      -inf, -101.3129,  -84.2107,
             -inf,  -83.1727,  -85.5135,  -95.5757], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([     -inf,      -inf,  -85.0365,      -inf, -103.5949,  -85.0012,
             -inf,  -83.6237,  -86.6360,  -99.2346], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
greedy_action q_values = tensor([     -inf,      -inf,  -83.1977,      -inf, -100.3347,  -82.1103,
             -inf,      -inf,  -83.9545,  -96.7264], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -86.6564, -98.4372], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 182: Reward=-297.11, route=[0, 3, 6, 1, 7, 5, 2, 4, 8, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -76.7465, -81.7486, -85.0708, -98.8696, -80.8431,     -inf,
            -inf,     -inf, -95.3613], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -84.9650,     -inf, -81.1613,     -inf,
            -inf,     -inf, -95.5926], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([     -inf,      -inf,      -inf,      -inf,      -inf,      -inf,
             -inf,      -inf,      -inf, -100.8648], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 183: Reward=-244.12, route=[0, 7, 8, 6, 1, 4, 2, 5, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([     -inf,  -78.3687,  -83.0130,  -86.6076, -100.9607,  -82.6827,
         -74.2431,  -81.8069,  -84.7428,  -96.9732], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.4141,     -inf,     -inf, -78.1692,     -inf,
            -inf, -81.4858, -95.5815], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1666,     -inf,     -inf,     -inf,     -inf,
            -inf, -79.5305, -93.1341], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -87.0061,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 184: Reward=-287.92, route=[0, 6, 1, 3, 4, 7, 5, 2, 9, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.8260, -77.8626, -83.1286, -95.3467, -76.8529,     -inf,
        -76.8048, -80.6208, -94.1321], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([     -inf,      -inf,  -81.1116,  -86.8963, -100.0375,  -80.9283,
             -inf,  -79.9667,  -84.0430,  -98.0005], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.3500, -84.8391, -96.8486, -78.1312,     -inf,
            -inf, -81.4229, -95.5134], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.0747, -85.5781,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 185: Reward=-256.69, route=[0, 6, 1, 7, 5, 8, 9, 4, 2, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.4653, -79.1597, -84.7163, -97.4810, -78.6976, -71.3319,
        -78.2702, -82.2446, -95.7936], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.8260, -77.8626, -83.1286, -95.3467, -76.8529,     -inf,
        -76.8048, -80.6208, -94.1321], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -98.3806, -78.8211,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -90.6700,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 186: Reward=-281.86, route=[0, 6, 1, 9, 7, 8, 2, 3, 5, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.3565, -92.1534, -73.4653, -66.8333,
        -73.8680,     -inf, -92.5662], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.6398, -91.9589, -73.3103,     -inf,
        -73.4644,     -inf, -92.5491], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.7936,     -inf,     -inf,     -inf,
        -76.4542,     -inf, -95.4142], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.3200,     -inf,     -inf,     -inf,
            -inf,     -inf, -93.9576], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 187: Reward=-286.48, route=[0, 8, 1, 2, 6, 5, 4, 7, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf, -75.6083, -78.0782,     -inf, -98.0587, -78.5650,     -inf,
            -inf, -83.0416, -97.4527], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.2168,     -inf, -96.3136, -77.0777,     -inf,
            -inf, -81.5634, -96.1762], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.3600,     -inf, -90.3782,     -inf,     -inf,
            -inf, -77.0998, -91.3204], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -81.5903, -95.3929], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 188: Reward=-288.65, route=[0, 6, 7, 3, 1, 5, 2, 4, 8, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.8943,     -inf, -77.2806, -88.1595, -69.8575,     -inf,
        -70.3078, -75.9155, -90.0891], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.1040, -92.3813, -73.4987,     -inf,
        -72.7651, -78.7352, -93.7633], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.7502, -86.6428,     -inf,     -inf,
            -inf, -74.3968, -89.0289], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.6595, -87.3859,     -inf,     -inf,
            -inf,     -inf, -89.7522], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -94.2497,     -inf,     -inf,
            -inf,     -inf, -95.2114], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 189: Reward=-257.77, route=[0, 6, 2, 1, 7, 5, 8, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.2148, -71.5980, -78.9785, -89.9034, -71.3508, -65.0895,
        -71.1745, -76.9634, -91.5657], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.4222, -88.2892, -69.9666,     -inf,
            -inf, -76.0241,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -94.2717,     -inf,     -inf,
            -inf, -80.3899,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 190: Reward=-305.71, route=[0, 6, 7, 9, 1, 2, 5, 3, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.2148, -71.5980, -78.9785, -89.9034, -71.3508, -65.0895,
        -71.1745, -76.9634, -91.5657], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.6656, -70.3720, -77.4813, -87.8672, -69.6245,     -inf,
        -69.8242, -75.4255, -89.9675], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -66.3738, -73.7473, -82.8580,     -inf,     -inf,
        -65.6561, -71.4146, -86.4462], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4477, -76.1032, -85.5063,     -inf,     -inf,
            -inf, -73.3095, -88.8191], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.4054, -84.5125,     -inf,     -inf,
            -inf, -73.0232, -87.6568], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.6699, -83.6300,     -inf,     -inf,
            -inf,     -inf, -87.2706], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -90.3594], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 191: Reward=-303.22, route=[0, 6, 1, 5, 7, 2, 8, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2131, -68.1794, -75.9747, -86.1185, -68.2935, -62.2550,
        -67.9226, -73.9639, -88.9933], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -63.7914, -66.4145, -73.7806, -82.9202,     -inf,     -inf,
        -65.7292, -71.4817,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.9791, -78.0619, -88.5569,     -inf,     -inf,
        -69.5085, -75.7371,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.5129, -76.1880, -85.5971,     -inf,     -inf,
            -inf, -73.3991,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.4887, -84.6066,     -inf,     -inf,
            -inf, -73.1120,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.7547, -83.7208,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -90.3975,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 192: Reward=-324.2, route=[0, 6, 9, 5, 1, 7, 2, 8, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2131, -68.1794, -75.9747, -86.1185, -68.2935, -62.2550,
        -67.9226, -73.9639, -88.9933], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -64.7181, -67.0173, -74.5337, -84.1531, -66.6167,     -inf,
        -66.6288, -72.4747, -87.4416], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -69.8771, -77.9414, -88.4082, -70.2957,     -inf,
        -69.3749, -75.5755, -91.0344], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4089, -76.0651, -85.4498, -67.7430,     -inf,
            -inf, -73.2383, -88.7538], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -67.7426,     -inf, -86.5158,     -inf,     -inf,
            -inf, -74.2935, -89.6129], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.0848,     -inf,     -inf,
            -inf, -70.4001, -85.0417], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.1777,     -inf,     -inf,
            -inf,     -inf, -84.7227], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -87.6344], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 193: Reward=-313.41, route=[0, 6, 1, 7, 5, 3, 2, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -66.9266, -74.7712, -84.8422, -67.6136, -61.3696,
        -66.0780, -72.8479, -88.2969], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -64.2374, -71.5420, -80.7439, -64.0344,     -inf,
        -63.5217, -69.8834, -84.8846], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.3857, -81.0923, -64.3252,     -inf,
            -inf,     -inf, -85.0005], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -70.8608, -79.5966,     -inf,     -inf,
            -inf,     -inf, -84.0145], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -86.6744,     -inf,     -inf,
            -inf,     -inf, -89.7477], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 194: Reward=-272.55, route=[0, 1, 6, 7, 8, 2, 5, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.4257, -65.2883, -72.8869, -82.6276, -65.6685, -59.8030,
        -64.7109, -71.2915, -86.3279], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -61.9905, -64.2102, -71.4938, -80.7143, -64.0180,     -inf,
        -63.5002, -69.8620, -84.8386], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -67.7507,     -inf,     -inf, -69.1240,     -inf,
        -67.4217, -74.2560, -89.5861], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 195: Reward=-319.62, route=[0, 6, 1, 4, 3, 7, 2, 8, 9, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -61.0348, -62.8755, -69.9412, -79.2723, -63.6154, -57.4609,
        -61.9452, -69.0547, -83.7101], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf, -62.3260, -63.2465,     -inf,     -inf, -65.0171,     -inf,
        -63.3185, -70.4150, -84.7285], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -61.3281,     -inf,     -inf,     -inf,     -inf,
        -59.9492, -66.7189, -81.4002], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -63.2666,     -inf,     -inf,     -inf,     -inf,
            -inf, -68.5397, -83.6437], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -68.1755, -82.4694], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.1922], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 196: Reward=-307.18, route=[0, 6, 3, 4, 1, 5, 7, 2, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -61.0348, -62.8755, -69.9412, -79.2723, -63.6154, -57.4609,
        -61.9452, -69.0547, -83.7101], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -59.6431, -61.8427, -68.6053, -77.4235, -61.9956,     -inf,
        -60.7825, -67.6603, -82.2703], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -64.4760, -71.7585, -81.3943, -65.5231,     -inf,
        -63.2742, -70.5618, -85.6308], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -65.2177,     -inf, -83.0656, -67.0748,     -inf,
            -inf,     -inf, -86.8524], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.8105, -62.3094,     -inf,
            -inf,     -inf, -82.4299], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.3412,     -inf,     -inf,
            -inf,     -inf, -81.4922], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 197: Reward=-285.8, route=[0, 6, 1, 7, 8, 3, 2, 5, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -56.8404, -59.5823, -65.3001, -73.2905,     -inf, -53.8317,
        -57.7229, -64.9083, -79.1765], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -57.8264, -60.1815, -66.0716, -74.5468,     -inf,     -inf,
        -58.6466, -65.9681, -80.1830], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.5144, -66.1524, -73.9609,     -inf,     -inf,
        -58.1478,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.6223, -67.5394, -75.8003,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -66.0390, -74.9942,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.1734,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 198: Reward=-254.23, route=[0, 5, 6, 1, 9, 8, 7, 2, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -57.8298, -60.2082, -66.0920, -74.5625, -60.6611,     -inf,
        -58.6449,     -inf, -80.1692], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -61.5297, -67.4338, -75.6706, -61.7066,     -inf,
            -inf,     -inf, -81.3995], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.5444, -81.5160, -67.0781,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -65.5348, -73.5162,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.1734,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 199: Reward=-318.35, route=[0, 8, 6, 1, 7, 2, 9, 5, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True  True]
greedy_action q_values = tensor([    -inf, -55.9333, -59.0858, -63.8265, -71.3163, -59.2062, -52.9697,
        -56.4137,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -56.4337, -58.8889, -63.9039, -72.0323, -59.8566,     -inf,
        -57.0571,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.1535, -65.6299,     -inf, -62.9192,     -inf,
        -59.4358,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.2289, -65.2078,     -inf, -60.9191,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -63.7547,     -inf, -60.1825,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 200: Reward=-328.29, route=[0, 9, 8, 6, 1, 4, 7, 2, 5, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -57.6626, -59.7676, -65.0381, -73.6366, -61.3554, -54.5175,
        -58.0470, -65.8317, -79.4447], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -56.2973, -58.7729, -63.7858, -71.8941, -59.7340,     -inf,
        -56.9435, -64.4968, -78.0838], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -61.3141, -66.7436, -75.6305, -63.2451,     -inf,
        -59.2883, -67.2639, -81.2641], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -60.0772, -65.0848, -72.9620, -60.7716,     -inf,
            -inf, -65.2247, -79.2837], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.7961,     -inf,     -inf,
            -inf, -63.6316, -77.3040], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.3645,     -inf,     -inf,
            -inf,     -inf, -77.9899], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.5893], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 201: Reward=-306.9, route=[0, 6, 1, 7, 2, 3, 5, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False  True False False]
greedy_action q_values = tensor([    -inf, -58.1921,     -inf, -63.5494,     -inf, -62.4448, -54.7163,
            -inf, -66.0172, -78.6808], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf, -59.8606,     -inf,     -inf,     -inf, -64.3884,     -inf,
            -inf, -67.4335, -80.6456], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -58.7499,     -inf,
            -inf,     -inf, -76.2832], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -75.7053], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 202: Reward=-307.59, route=[0, 2, 7, 4, 6, 3, 1, 8, 5, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False False False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -61.3840,     -inf,     -inf, -51.8392,
        -55.1424,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -59.4850,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 203: Reward=-250.37, route=[0, 2, 4, 1, 9, 8, 5, 6, 3, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -56.9144, -59.0557, -63.0709, -71.4548, -60.9150, -53.6701,
        -56.9038, -64.6999, -77.7297], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -55.5429, -58.0630, -61.8517, -69.7542, -59.2793,     -inf,
        -55.8150, -63.3873, -76.4022], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -57.5477, -61.2023, -68.6066,     -inf,     -inf,
        -54.9966, -62.4484, -75.5608], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -62.1309, -65.3711, -74.4717,     -inf,     -inf,
            -inf, -67.6152,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.2418,     -inf,     -inf,
            -inf, -66.8487,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 204: Reward=-327.65, route=[0, 6, 1, 5, 7, 9, 2, 3, 8, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.2232,     -inf,     -inf,
            -inf,     -inf, -79.1494], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -77.2832], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 205: Reward=-293.4, route=[0, 7, 5, 1, 6, 2, 8, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False  True]
greedy_action q_values = tensor([    -inf, -57.8330, -58.9641, -62.0463,     -inf, -62.5351, -54.1483,
        -57.3762, -65.3357,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf, -59.4695, -60.8936,     -inf,     -inf, -64.4801,     -inf,
            -inf, -66.7037,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.3002,     -inf,     -inf, -62.9779,     -inf,
            -inf, -65.4600,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 206: Reward=-277.34, route=[0, 9, 4, 6, 7, 3, 1, 2, 8, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -56.3058, -58.7075, -60.3510, -68.4547, -61.4434, -52.8522,
        -55.6270, -63.6259, -74.9329], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -54.0840,     -inf,     -inf, -65.7843,     -inf,     -inf,
        -53.7870, -61.4645, -72.9112], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.4345,     -inf,     -inf,
            -inf, -65.1476, -76.7659], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 207: Reward=-291.03, route=[0, 6, 2, 3, 5, 7, 1, 8, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True False False False False]
greedy_action q_values = tensor([    -inf, -54.0369, -57.2162, -58.5354,     -inf,     -inf, -50.8789,
        -53.7135, -61.3756, -72.8347], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -55.2626,     -inf, -59.0281,     -inf,     -inf,     -inf,
        -55.0138, -62.7945, -73.7911], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -55.8870,     -inf, -60.4537,     -inf,     -inf,     -inf,
            -inf, -63.1309, -74.8927], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 208: Reward=-283.22, route=[0, 4, 5, 6, 2, 7, 1, 9, 8, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -56.5251, -59.1659, -59.4859, -67.6885, -62.4304, -53.0425,
        -55.5830, -63.6895, -74.0714], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -55.1216, -58.1488, -58.3344, -66.0659, -60.7141,     -inf,
        -54.5088, -62.3947, -72.8248], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -55.9850, -59.4626, -59.5144, -67.0646, -61.7525,     -inf,
            -inf, -63.0283, -73.8895], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -59.4127, -59.8794,     -inf, -63.9352,     -inf,
            -inf, -64.9806, -74.9458], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -58.1870,     -inf, -61.0907,     -inf,
            -inf, -62.7879, -72.9182], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 209: Reward=-303.42, route=[0, 6, 7, 1, 4, 2, 3, 8, 9, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -55.0993, -58.1365, -58.3302, -66.0560, -60.7064,     -inf,
            -inf, -62.3672, -72.8097], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.4824,     -inf,     -inf, -66.0666,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -61.2082,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 210: Reward=-282.66, route=[0, 7, 6, 1, 8, 4, 9, 3, 2, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -59.4162, -61.3234,     -inf, -70.9521, -65.9372, -55.5597,
        -57.9000, -66.3704, -76.7305], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -55.7009, -58.8761,     -inf, -65.7271, -61.9305,     -inf,
        -54.8877, -62.9733, -72.2567], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -61.1463, -63.4187,     -inf, -71.9106, -68.6472,     -inf,
            -inf, -67.9048,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.2537,     -inf, -65.2413, -61.3439,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.1086, -62.4092,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -64.8705,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 211: Reward=-288.45, route=[0, 3, 6, 7, 9, 1, 8, 2, 5, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -57.1088, -59.9010, -59.0974, -67.3371, -63.6867, -53.3088,
        -55.9406, -64.2558, -73.4679], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -55.2446, -59.1843, -57.9904, -65.1612, -61.2658,     -inf,
        -54.2004,     -inf, -71.9980], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -58.5293,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -74.4697], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 212: Reward=-229.14, route=[0, 6, 8, 7, 5, 2, 3, 4, 1, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -56.5523, -60.2010, -59.1361, -66.7560, -62.9916, -52.8886,
            -inf, -63.5609, -73.2757], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -62.5421, -72.1155, -70.0917,     -inf,
            -inf, -68.8510,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 213: Reward=-255.78, route=[0, 7, 6, 2, 1, 9, 3, 5, 8, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf, -57.4607, -61.1302, -59.0186,     -inf, -64.3381,     -inf,
            -inf, -64.4358,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -62.4032, -60.5065,     -inf, -67.0873,     -inf,
            -inf, -66.5751,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 214: Reward=-286.01, route=[0, 6, 9, 4, 7, 1, 3, 5, 8, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -62.0308, -64.2887, -62.4480, -72.0544, -70.0327, -57.3475,
        -59.6985, -68.7892,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 215: Reward=-352.88, route=[0, 9, 6, 5, 3, 8, 4, 7, 2, 1] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -56.6419, -60.2354, -57.4209, -65.2542,     -inf,     -inf,
        -55.7225, -63.5645, -70.7961], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.8764,     -inf,     -inf,
            -inf, -67.5977, -74.5683], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 216: Reward=-288.8, route=[0, 6, 5, 7, 3, 2, 1, 8, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False  True False  True]
greedy_action q_values = tensor([    -inf, -63.2026, -65.4883,     -inf,     -inf, -71.6833, -58.1419,
            -inf, -69.7828,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf, -57.6603, -60.8598,     -inf,     -inf, -64.7465,     -inf,
            -inf, -64.7032,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -63.5368,     -inf,     -inf, -68.6538,     -inf,
            -inf, -67.5537,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -65.1219,     -inf,
            -inf, -65.1676,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 217: Reward=-285.61, route=[0, 4, 3, 7, 9, 6, 1, 2, 5, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -57.8758, -61.3595, -57.9197, -65.9920,     -inf, -53.2674,
        -56.9333, -64.5274, -70.8331], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -58.4002, -62.2703,     -inf, -66.5563,     -inf,     -inf,
        -57.1862,     -inf, -71.4784], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -67.3405,     -inf,     -inf,
            -inf,     -inf, -71.8184], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 218: Reward=-267.23, route=[0, 5, 6, 3, 8, 7, 1, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -61.6004, -63.2510, -60.0692,     -inf, -69.8367,     -inf,
        -60.3586, -68.3860, -73.6715], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf, -63.3545, -65.3343,     -inf,     -inf, -72.0271,     -inf,
        -61.5069, -69.8603, -75.4570], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -58.4393,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -71.5535], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -74.6671], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 219: Reward=-258.59, route=[0, 6, 4, 3, 7, 2, 5, 8, 1, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -61.1022, -64.7064, -60.5630, -69.3528, -69.2443, -56.1299,
            -inf, -67.2812, -72.9481], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -60.1854, -63.2717, -59.3255, -68.2336, -68.1054,     -inf,
            -inf, -66.6634, -71.9329], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -64.6647,     -inf,     -inf, -71.6913,     -inf,
            -inf, -69.5401, -74.0121], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -68.5395,     -inf,
            -inf, -67.2038, -72.0544], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -67.4691,     -inf,
            -inf,     -inf, -71.8425], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -71.3160], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 220: Reward=-274.37, route=[0, 7, 6, 3, 1, 4, 2, 8, 5, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -60.4935,     -inf, -59.1400, -68.4512, -68.5215, -55.5188,
        -59.7954, -67.1671, -71.9731], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -60.2687,     -inf, -59.3916, -68.3127, -68.1906,     -inf,
        -59.3892, -66.7643, -72.0148], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf, -63.0417,     -inf, -60.9760,     -inf, -71.7644,     -inf,
            -inf, -69.5612, -74.0219], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -59.2901,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -65.6901, -71.2408], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -69.8079, -74.9323], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 221: Reward=-312.73, route=[0, 2, 6, 7, 4, 3, 5, 1, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -61.7161, -64.3642, -60.4742, -69.8529, -70.0403, -56.6277,
        -60.5314, -68.1460, -73.1468], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -65.9911, -68.1533, -64.1587, -74.6433, -75.4528,     -inf,
        -63.8148, -72.0322,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -62.7495, -66.3006, -61.4949, -70.6986, -71.0856,     -inf,
            -inf, -68.4776,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -66.4579, -68.3497,     -inf, -74.6330, -75.8508,     -inf,
            -inf, -72.2800,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -65.2066,     -inf,     -inf, -69.2113,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -70.4174,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 222: Reward=-303.2, route=[0, 6, 9, 7, 3, 1, 4, 8, 2, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.2746, -65.8885, -61.3430, -71.1582, -71.8140, -58.2077,
        -62.1906, -69.2676, -73.6522], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -65.1127, -60.2937, -68.9998, -69.1058,     -inf,
        -60.1988,     -inf, -72.2475], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.3214, -61.5121, -70.7035, -71.0604,     -inf,
            -inf,     -inf, -73.5424], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.3644,     -inf, -74.6376, -75.8181,     -inf,
            -inf,     -inf, -76.3119], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.7906, -70.2980,     -inf,
            -inf,     -inf, -72.5718], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -73.6330,     -inf,
            -inf,     -inf, -74.6282], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 223: Reward=-293.04, route=[0, 6, 1, 8, 7, 3, 2, 4, 5, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -66.4755, -68.3521,     -inf, -74.6582, -75.8685, -61.1289,
        -64.8472, -72.3034,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf, -63.5172,     -inf,     -inf,     -inf, -71.6789,     -inf,
        -63.2731, -69.3942,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -62.2627,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -67.8476,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -72.0879,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 224: Reward=-279.29, route=[0, 9, 3, 6, 4, 2, 7, 5, 1, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.6687, -67.2400, -62.3843, -72.4678, -73.1450, -59.5701,
        -63.8986, -70.2691, -74.2863], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -63.1280, -66.1022, -61.1856, -70.7766, -71.1604,     -inf,
        -62.6785, -68.8012, -73.0838], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.8364, -69.6818,     -inf, -75.9062, -77.1711,     -inf,
        -66.5769, -73.2977, -76.9023], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf, -64.0640, -67.5992,     -inf, -71.9341, -72.3135,     -inf,
            -inf, -69.4126, -74.1207], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -68.9973,     -inf, -74.4536, -75.4049,     -inf,
            -inf, -71.8615, -75.9537], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.4573, -78.8626,     -inf,
            -inf, -74.4497,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.4288, -70.5425,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -75.0877,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 225: Reward=-341.57, route=[0, 6, 3, 7, 1, 2, 9, 8, 4, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.6687, -67.2400, -62.3843, -72.4678, -73.1450, -59.5701,
        -63.8986, -70.2691, -74.2863], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -62.6546, -66.4858, -61.3039,     -inf,     -inf,     -inf,
        -61.8763,     -inf, -72.9066], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -67.9666, -69.8200,     -inf,     -inf,     -inf,     -inf,
        -66.6496,     -inf, -77.0121], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -64.1826, -67.7305,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -74.2295], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7076,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -77.0635], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -74.2476], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 226: Reward=-326.37, route=[0, 6, 5, 4, 8, 3, 7, 1, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2082, -68.7658, -63.8189, -74.1637, -74.5294, -60.9035,
        -65.6142, -71.5066, -75.2633], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False  True False]
greedy_action q_values = tensor([    -inf, -64.1130, -67.9597,     -inf,     -inf, -71.7477,     -inf,
        -63.5297,     -inf, -73.8401], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 227: Reward=-298.29, route=[0, 6, 3, 4, 8, 7, 5, 9, 2, 1] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2082, -68.7658, -63.8189, -74.1637, -74.5294, -60.9035,
        -65.6142, -71.5066, -75.2633], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -64.0886, -67.9146, -62.6882, -71.9334, -71.7221,     -inf,
        -63.4859,     -inf, -73.7963], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -65.1162,     -inf,     -inf, -72.8470,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.4569,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 228: Reward=-319.23, route=[0, 6, 8, 3, 7, 5, 9, 2, 1, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False  True False]
greedy_action q_values = tensor([    -inf, -65.1435, -68.4271, -63.5278, -73.1876,     -inf, -59.8750,
        -64.9568,     -inf, -74.1321], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.1664, -72.8359,     -inf, -79.6458,     -inf,     -inf,
        -70.2383,     -inf, -78.9287], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.2400, -70.6614,     -inf, -75.5914,     -inf,     -inf,
            -inf,     -inf, -76.0875], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 229: Reward=-264.89, route=[0, 8, 5, 6, 3, 7, 1, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.0152, -67.0747, -78.0759, -78.0399, -64.0252,
        -68.7671, -74.2537, -77.8435], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -69.0325, -64.2071, -74.2894, -73.6728,     -inf,
        -66.0188, -71.0654, -74.9799], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.7472,     -inf, -79.5566, -79.8557,     -inf,
        -70.1950, -75.8059, -78.8803], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 230: Reward=-327.09, route=[0, 1, 6, 3, 7, 9, 8, 4, 5, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8199, -72.0637, -67.6324,     -inf, -78.5328,     -inf,
        -70.6864, -75.4792, -78.2795], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf, -72.8036, -74.4048,     -inf,     -inf, -80.9721,     -inf,
        -72.0740, -77.1311, -80.1456], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.6838,     -inf,     -inf, -79.1311,     -inf,
            -inf, -75.5748, -79.1631], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -75.1111,     -inf,
            -inf, -72.8229, -76.2770], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -82.7940,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 231: Reward=-311.53, route=[0, 6, 4, 3, 7, 1, 2, 8, 9, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.4009, -71.7645, -67.1322, -78.0277, -76.7241, -63.8860,
        -69.0864, -73.8423, -77.4002], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.7726, -70.5614, -65.8939, -76.2795, -74.6750,     -inf,
        -67.7222, -72.2490, -76.1592], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True False False  True]
greedy_action q_values = tensor([    -inf, -68.1672,     -inf,     -inf, -76.5441, -75.1660,     -inf,
        -68.3845, -72.9127,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.2983, -79.2804,     -inf,
        -70.8172, -75.7644,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -78.7141,     -inf,
            -inf, -75.6736,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 232: Reward=-291.91, route=[0, 6, 3, 9, 2, 1, 7, 4, 8, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False  True False]
greedy_action q_values = tensor([    -inf, -67.2402, -70.8871, -65.9797, -75.8061,     -inf, -61.8687,
        -66.8360,     -inf, -75.9355], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -67.8842, -70.6637, -65.9689, -76.3881,     -inf,     -inf,
        -67.7916,     -inf, -76.2499], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.3487, -73.7970,     -inf,     -inf,     -inf,     -inf,
        -72.4500,     -inf, -79.7135], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.4357,     -inf,     -inf,     -inf,     -inf,
        -72.3610,     -inf, -80.5923], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.9041,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.6931], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -77.6516], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 233: Reward=-281.85, route=[0, 5, 8, 6, 3, 4, 1, 7, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.7347, -73.3549, -68.8998, -79.9928, -77.5414, -65.3268,
        -70.6527, -75.0387, -78.6938], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.0911, -72.1281, -67.6350, -78.2112, -75.4810,     -inf,
        -69.2576, -73.4155, -77.4365], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True  True False False]
greedy_action q_values = tensor([    -inf, -70.1735,     -inf,     -inf, -79.5779, -76.7825,     -inf,
            -inf, -74.1617, -78.6027], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.3526, -83.5976,     -inf,
            -inf, -79.6623,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 234: Reward=-282.47, route=[0, 6, 3, 2, 7, 1, 9, 8, 5, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False  True False  True]
greedy_action q_values = tensor([    -inf, -75.5769, -77.6336,     -inf, -85.2611, -83.5079, -69.7587,
            -inf, -79.5492,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -69.1741, -72.1995,     -inf, -78.2949, -75.5635,     -inf,
            -inf, -73.5147,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 235: Reward=-314.45, route=[0, 3, 7, 9, 6, 1, 5, 2, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.9736, -75.0245, -70.6916, -81.7456, -78.1994, -66.4353,
        -72.0495, -75.9633, -79.9956], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.3457, -75.4002, -70.7854, -81.2438, -77.3736,     -inf,
            -inf, -74.9592, -79.8112], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf, -75.4745, -77.7513,     -inf, -85.4435, -82.4953,     -inf,
            -inf, -79.3730, -82.8004], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.9938,     -inf, -83.9524, -80.6227,     -inf,
            -inf, -77.7509, -81.7928], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.1397, -76.5268,     -inf,
            -inf, -74.9015, -78.8189], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.5053, -75.3782,     -inf,
            -inf,     -inf, -78.5872], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.8885,     -inf,     -inf,
            -inf,     -inf, -78.0289], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 236: Reward=-279.27, route=[0, 6, 7, 3, 1, 2, 8, 5, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.5862,     -inf, -69.2081, -80.1225, -76.5237, -65.1408,
        -71.1429, -74.8596, -78.7410], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -69.7833,     -inf, -69.5123, -79.4751, -75.3696,     -inf,
        -69.7545,     -inf, -78.5314], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.1510,     -inf,     -inf,
            -inf,     -inf, -81.9620], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 237: Reward=-270.27, route=[0, 2, 6, 8, 3, 7, 5, 1, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -70.5991, -75.6047, -71.0505, -80.9050, -75.5093, -65.0881,
        -70.9161,     -inf, -79.7873], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.3879, -77.1369, -72.5229,     -inf,     -inf,     -inf,
            -inf,     -inf, -81.3095], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 238: Reward=-274.57, route=[0, 8, 6, 4, 5, 7, 1, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -70.5991, -75.6047, -71.0505, -80.9050, -75.5093, -65.0881,
        -70.9161,     -inf, -79.7873], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -88.9588,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 239: Reward=-285.78, route=[0, 8, 6, 5, 3, 7, 2, 1, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.8757, -76.6078, -72.3397, -83.2752, -78.4195, -67.2162,
        -73.3378, -76.7067, -81.3726], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -75.0813,     -inf, -74.7644,     -inf, -80.6424,     -inf,
        -76.3639, -79.2116, -83.6927], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True False  True False]
greedy_action q_values = tensor([    -inf, -71.3101,     -inf,     -inf,     -inf, -75.8771,     -inf,
        -72.1855,     -inf, -81.1957], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -79.0337,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 240: Reward=-289.24, route=[0, 6, 2, 4, 3, 8, 1, 5, 9, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.4859, -77.8647, -74.1111, -84.7571, -78.6870, -68.0333,
        -74.5098, -77.3381, -82.6539], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.8219, -76.5731, -72.7688, -82.8984, -76.6179,     -inf,
        -73.0359, -75.6459, -81.3427], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.8673, -72.0331, -81.6651,     -inf,     -inf,
        -71.9051, -74.4041, -80.4984], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.3171,     -inf,     -inf,     -inf,     -inf,
            -inf, -79.2329, -83.7323], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -81.2859], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 241: Reward=-285.61, route=[0, 6, 1, 5, 7, 3, 4, 2, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.4859, -77.8647, -74.1111, -84.7571, -78.6870, -68.0333,
        -74.5098, -77.3381, -82.6539], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.0827,     -inf, -72.5834, -83.0666, -76.9935,     -inf,
        -73.5972, -76.2239, -81.3872], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.7649, -88.3434, -81.2796,     -inf,
        -77.1007, -79.6217, -85.7173], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.9704, -85.5659, -78.0221,     -inf,
            -inf, -76.7608, -83.7060], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -89.9243, -83.1828,     -inf,
            -inf, -81.3302, -86.8362], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -83.6421, -75.9045,     -inf,
            -inf,     -inf, -82.3052], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 242: Reward=-290.49, route=[0, 6, 2, 1, 7, 3, 8, 5, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False  True False False]
greedy_action q_values = tensor([    -inf, -73.2185, -79.3883, -75.8513,     -inf, -77.9612, -68.4874,
            -inf, -76.6562, -83.5866], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.0198,     -inf,     -inf, -75.8631,     -inf,
            -inf,     -inf, -82.2580], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.6777], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 243: Reward=-293.38, route=[0, 4, 7, 6, 1, 3, 8, 5, 2, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.3993,     -inf, -74.2027, -84.2403, -77.0406, -67.6643,
        -74.3735, -76.5624, -82.4646], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.2164,     -inf, -74.4683, -84.1517, -76.7418,     -inf,
        -73.8937, -76.0688, -82.5196], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.7649, -88.3434, -81.2796,     -inf,
        -77.1007, -79.6217, -85.7173], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 244: Reward=-224.99, route=[0, 2, 6, 1, 7, 8, 5, 4, 9, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True  True False]
greedy_action q_values = tensor([    -inf, -71.4524, -78.7703, -75.9761, -84.3192, -75.6842, -67.4075,
            -inf,     -inf, -83.1924], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.1303, -78.5705, -76.0317, -84.9222, -76.5880,     -inf,
            -inf,     -inf, -83.5400], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -81.9806, -79.3864, -89.1430, -81.1187,     -inf,
            -inf,     -inf, -86.7739], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -82.8429,     -inf, -90.7354, -83.0307,     -inf,
            -inf,     -inf, -87.9189], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.1187, -76.9724,     -inf,
            -inf,     -inf, -83.6573], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -92.6440,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 245: Reward=-265.93, route=[0, 7, 8, 6, 1, 3, 2, 5, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -71.4773, -78.7794, -75.9795, -84.3234, -75.6956, -67.4170,
        -73.6113,     -inf, -83.2044], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -72.3981,     -inf, -75.8488, -85.0838, -76.9625,     -inf,
        -75.2330,     -inf, -83.5969], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.4648, -89.2322, -81.2073,     -inf,
        -77.9617,     -inf, -86.8615], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.3315, -83.7558,     -inf,     -inf,
            -inf,     -inf, -82.7495], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -92.9855,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 246: Reward=-259.42, route=[0, 8, 6, 2, 1, 7, 5, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.5333, -80.1809, -78.4883, -87.0636, -78.0976, -69.7859,
        -76.5569, -77.9776, -85.3604], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -82.2864, -80.4777, -89.4089, -80.5592,     -inf,
        -78.3077, -79.8473, -87.2646], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.6328, -78.6276, -86.6236, -77.3310,     -inf,
            -inf, -76.9445, -85.2292], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -84.9844, -83.1966, -92.8380, -84.2498,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.3396,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 247: Reward=-240.44, route=[0, 6, 1, 7, 8, 9, 3, 4, 5, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.5333, -80.1809, -78.4883, -87.0636, -78.0976, -69.7859,
        -76.5569, -77.9776, -85.3604], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -75.1301,     -inf, -79.2156,     -inf, -80.0599,     -inf,
        -78.4821, -79.8997, -86.4391], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.2326,     -inf, -84.3201,     -inf,
        -81.1205, -82.8951,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.7944,     -inf, -77.5293,     -inf,
            -inf, -77.1312,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 248: Reward=-225.43, route=[0, 6, 2, 4, 1, 9, 7, 8, 5, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.9594, -80.3417, -79.5489, -87.2901, -77.4651, -69.9722,
        -76.7315, -77.8619, -85.8562], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -77.9425, -85.0642, -84.2112, -92.9824, -83.5356,     -inf,
        -81.2118, -82.6765,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.0752, -85.6653, -75.8889,     -inf,
        -75.9279, -76.8661,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.5000, -84.3335,     -inf,     -inf,
        -74.2007, -75.0366,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.8814, -87.0805,     -inf,     -inf,
            -inf, -77.0615,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -91.5186,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 249: Reward=-255.69, route=[0, 6, 9, 1, 2, 5, 7, 8, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False  True  True]
greedy_action q_values = tensor([    -inf, -76.6792, -83.4634,     -inf,     -inf, -81.9819, -73.5034,
        -80.2828,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -70.4798,     -inf,     -inf,     -inf,     -inf,     -inf,
        -74.2629,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -78.7846,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 250: Reward=-287.59, route=[0, 8, 9, 4, 3, 6, 2, 5, 1, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.9594, -80.3417, -79.5489, -87.2901, -77.4651, -69.9722,
        -76.7315, -77.8619, -85.8562], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.3544, -79.0373, -78.1369, -85.4102, -75.4345,     -inf,
        -75.2136, -76.1315, -84.5174], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.2434, -84.2927,     -inf,     -inf,
        -74.0137, -74.8581, -83.9727], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.6433, -87.0401,     -inf,     -inf,
            -inf, -76.8823, -86.1099], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -91.4606,     -inf,     -inf,
            -inf,     -inf, -89.3250], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 251: Reward=-250.3, route=[0, 6, 1, 2, 5, 7, 8, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -82.4340, -82.4094, -89.6846, -79.3917, -72.1431,
        -78.3771, -79.6514, -87.9835], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.8188, -80.5357, -86.9091, -76.1946,     -inf,
            -inf, -76.7400, -85.9803], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.4240, -79.0609, -85.0183,     -inf,     -inf,
            -inf,     -inf, -84.5941], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -83.4161,     -inf, -91.3764,     -inf,     -inf,
            -inf,     -inf, -89.2493], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.7410,     -inf,     -inf,
            -inf,     -inf, -84.9625], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -93.2558,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 252: Reward=-287.11, route=[0, 1, 6, 7, 5, 8, 3, 2, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False  True]
greedy_action q_values = tensor([    -inf, -69.6626, -78.3510, -78.1890, -84.2724,     -inf, -67.5531,
        -74.0039, -74.8338,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -70.8405, -79.1549, -79.0862, -85.5841,     -inf,     -inf,
        -75.2809, -76.2150,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -82.4462, -83.1057, -89.8832,     -inf,     -inf,
        -78.1008, -79.8987,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.8268, -81.2123, -87.1234,     -inf,     -inf,
            -inf, -76.9563,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.4003, -79.6988, -85.1888,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.5504, -85.8825,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 253: Reward=-270.56, route=[0, 9, 5, 6, 1, 7, 8, 2, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -73.1057, -80.5758, -81.6191,     -inf, -77.9404, -71.5123,
        -78.0774, -79.7312, -87.1166], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -70.0810, -78.9707, -79.5340,     -inf, -74.0972,     -inf,
        -74.7164, -76.1228, -84.8420], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -83.2187,     -inf,     -inf, -80.4214,     -inf,
        -79.6699, -81.5369, -89.2219], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.7671,     -inf,     -inf, -75.3544,     -inf,
            -inf, -76.8436, -86.0843], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -76.8407, -84.9938], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.7785], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 254: Reward=-292.04, route=[0, 4, 6, 1, 3, 7, 5, 2, 8, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.0781, -78.9448,     -inf, -85.5353, -74.0642,     -inf,
        -74.7332, -76.1452, -84.8388], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -82.3458,     -inf, -89.7604, -78.5023,     -inf,
        -77.9911, -79.7733, -88.0760], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.7203, -73.8142,     -inf,
            -inf, -77.3161,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.4219,     -inf,     -inf,
            -inf, -75.4437,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 255: Reward=-298.91, route=[0, 3, 6, 1, 7, 9, 2, 5, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.3080, -80.0381, -81.6193, -87.3406, -75.3808, -69.9856,
        -75.7311, -78.3115, -86.1322], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.7470, -78.7523, -80.1859, -85.4780, -73.3779,     -inf,
        -74.2270, -76.5564, -84.8141], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -82.1353, -83.6665, -89.6930, -77.7868,     -inf,
        -77.4641, -80.2204, -88.0352], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.0524,     -inf, -73.7559,     -inf,
            -inf, -77.1982, -84.9107], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.3677,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.7602], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 256: Reward=-253.21, route=[0, 6, 1, 7, 4, 2, 5, 8, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -70.7586, -80.4929, -81.7043, -86.9261, -74.6095, -69.4467,
            -inf, -77.2029, -85.9539], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -69.7217, -78.7429, -80.1816, -85.4733, -73.3655,     -inf,
            -inf, -76.5237, -84.8015], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -82.1292, -83.6646, -89.6891, -77.7787,     -inf,
            -inf, -80.1856, -88.0234], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.0402, -79.3757, -84.2453,     -inf,     -inf,
            -inf, -75.2376, -83.9491], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.5269, -82.4513,     -inf,     -inf,     -inf,
            -inf,     -inf, -87.2677], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 257: Reward=-264.98, route=[0, 7, 6, 1, 5, 8, 4, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -70.5957, -80.0954, -81.9079, -86.6293, -73.8499, -69.0339,
            -inf, -77.6323, -86.0249], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -69.5616, -78.3456, -80.3836, -85.1758, -72.6142,     -inf,
            -inf, -76.9499, -84.8730], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -81.7127, -83.8662, -89.3747, -77.0063,     -inf,
            -inf, -80.6467, -88.0863], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.6517, -79.5789, -83.9564,     -inf,     -inf,
            -inf, -75.6523, -84.0244], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.7703, -80.4869, -84.7807,     -inf,     -inf,
            -inf,     -inf, -84.7360], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -86.8057, -92.9290,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 258: Reward=-261.29, route=[0, 7, 6, 1, 5, 8, 2, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.1424, -79.6307, -81.8199, -87.0330, -74.6215, -69.5711,
        -75.2113, -78.7541, -86.1980], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.5871, -78.3552, -80.3882, -85.1807, -72.6270,     -inf,
        -73.7143, -76.9832, -84.8858], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -82.5495,     -inf, -90.9399, -78.8918,     -inf,
        -78.6273, -82.5063, -89.2321], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.1539,     -inf, -86.6615, -73.8661,     -inf,
            -inf, -77.7090, -86.1261], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.6651,     -inf, -83.9667,     -inf,     -inf,
            -inf, -75.6876, -84.0490], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.4496,     -inf,     -inf,
            -inf,     -inf, -85.0768], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -92.9401,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 259: Reward=-268.97, route=[0, 6, 1, 3, 7, 5, 8, 2, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.1424, -79.6307, -81.8199, -87.0330, -74.6215, -69.5711,
        -75.2113, -78.7541, -86.1980], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -70.3960, -79.5412, -81.9777, -86.0003, -73.1076,     -inf,
            -inf, -77.9092, -85.8116], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.1752, -80.5142, -84.1270, -71.0897,     -inf,
            -inf,     -inf, -84.4516], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.3892, -84.8116,     -inf,     -inf,
            -inf,     -inf, -84.8113], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -90.4713,     -inf,     -inf,
            -inf,     -inf, -89.1262], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -92.2676,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 260: Reward=-236.59, route=[0, 6, 7, 1, 8, 5, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.9260, -79.0485, -81.8737, -86.3985, -73.8802, -68.4546,
        -74.5517, -79.0288, -85.9494], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -70.3960, -79.5412, -81.9777, -86.0003, -73.1076,     -inf,
            -inf, -77.9092, -85.8116], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -81.1178, -83.9178, -88.7258, -76.2541,     -inf,
            -inf, -80.9352, -87.8273], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.0944, -79.6394, -83.3503,     -inf,     -inf,
            -inf, -75.9053, -83.7949], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.2134, -80.5481, -84.1740,     -inf,     -inf,
            -inf,     -inf, -84.5052], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -86.8571, -92.2568,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 261: Reward=-247.44, route=[0, 6, 7, 1, 5, 8, 2, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.9260, -79.0485, -81.8737, -86.3985, -73.8802, -68.4546,
        -74.5517, -79.0288, -85.9494], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.3767, -77.7863, -80.4457, -84.5620, -71.8925,     -inf,
        -73.0640, -77.2452, -84.6487], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.3421, -79.6382, -82.5965,     -inf,     -inf,
        -70.9636, -75.8895,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.1445,     -inf, -89.4877,     -inf,     -inf,
            -inf, -82.8120,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -83.9679,     -inf,     -inf,
            -inf, -77.9492,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 262: Reward=-305.81, route=[0, 6, 1, 9, 5, 7, 3, 2, 8, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False  True False]
greedy_action q_values = tensor([    -inf, -69.4375,     -inf, -80.2017, -83.8852, -71.5048, -65.8428,
        -72.6374,     -inf, -84.1326], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.2297,     -inf, -79.6330, -82.6326,     -inf,     -inf,
        -70.9183,     -inf, -83.3274], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.9896, -88.0305,     -inf,     -inf,
        -75.2950,     -inf, -87.4173], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.0961, -85.3568,     -inf,     -inf,
            -inf,     -inf, -85.4588], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -91.3404,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 263: Reward=-257.3, route=[0, 8, 2, 6, 5, 1, 7, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.7328, -78.1816, -81.7743, -85.5231, -73.0957, -67.1510,
        -73.4908, -78.8921, -85.3743], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.2393, -83.8166, -87.8354, -75.4694,     -inf,
        -75.1735, -80.8382, -87.2470], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.2602, -79.5497, -82.5089,     -inf,     -inf,
            -inf, -75.7585, -83.2472], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.2987, -80.1215, -82.1028,     -inf,     -inf,
            -inf,     -inf, -83.1000], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 264: Reward=-259.08, route=[0, 6, 1, 7, 5, 8, 2, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.5546, -77.0692, -81.4254, -84.2575, -72.4437, -65.7677,
        -72.5617, -78.4732, -84.4924], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.0130, -75.8472, -80.0134, -82.4670, -70.4646,     -inf,
        -71.1029, -76.6830, -83.2307], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.1028, -83.4572, -86.5402, -74.8118,     -inf,
        -74.2238, -80.4158, -86.3396], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.6126, -81.5871, -83.9113, -71.6805,     -inf,
            -inf, -77.3564, -84.4169], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.2185], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 265: Reward=-305.67, route=[0, 6, 1, 7, 5, 3, 2, 4, 8, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.2042,     -inf, -79.8042, -82.5703, -70.8122, -64.4519,
        -71.6935, -77.3365, -83.2264], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.6576, -83.9864, -71.7405,     -inf,
            -inf, -77.4277, -84.4853], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.2879, -81.3642,     -inf,     -inf,
            -inf, -75.4089, -82.4705], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.1919, -82.1778,     -inf,     -inf,
            -inf,     -inf, -83.1685], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.1721], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 266: Reward=-256.87, route=[0, 2, 6, 1, 7, 5, 8, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.8695,     -inf, -80.5112,     -inf, -70.7220,     -inf,
            -inf,     -inf, -83.0294], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -85.1051,     -inf, -77.3994,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.3103,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 267: Reward=-255.81, route=[0, 2, 4, 6, 8, 7, 1, 9, 5, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.2753, -75.2889, -80.2579, -82.6432, -71.3767, -63.9189,
        -71.4794, -77.4705, -83.0080], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -69.8375, -75.8889, -80.4559, -82.3614, -70.6781,     -inf,
            -inf, -76.4118,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.7987, -81.0736, -69.8461,     -inf,
            -inf, -76.4481,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -86.5525,     -inf,     -inf,
            -inf, -81.4320,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.6941,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 268: Reward=-330.74, route=[0, 6, 9, 7, 1, 2, 5, 3, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.1064, -73.7984, -79.0323, -81.4126, -70.6561, -62.3791,
        -70.3042, -76.4328, -81.6654], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -69.5798, -74.3475, -79.1590, -81.0668, -69.8692,     -inf,
            -inf, -75.2740, -81.5644], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.6130,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.6319], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 269: Reward=-281.44, route=[0, 6, 7, 1, 8, 4, 5, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False  True False False]
greedy_action q_values = tensor([    -inf, -67.4754, -71.9886, -76.8525, -78.5284,     -inf, -59.9003,
            -inf, -73.2906, -79.6108], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.8362,     -inf,     -inf,     -inf,     -inf,
            -inf, -78.3961, -83.5169], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -75.4396, -80.6132], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.4697], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 270: Reward=-291.32, route=[0, 7, 5, 6, 3, 4, 1, 2, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.1064, -73.7984, -79.0323, -81.4126, -70.6561, -62.3791,
        -70.3042, -76.4328, -81.6654], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.4094, -79.3122, -82.3444, -72.5525,     -inf,
        -71.1197, -77.4245, -82.3427], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.0806, -77.5855, -79.8598, -69.4486,     -inf,
            -inf, -74.3978, -80.5627], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7734, -75.3440, -77.3503,     -inf,     -inf,
            -inf, -72.4535, -78.6728], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.0068, -85.5683,     -inf,     -inf,
            -inf, -80.5402,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.3554, -78.2844,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.0132,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 271: Reward=-292.08, route=[0, 6, 1, 7, 5, 2, 9, 8, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -69.0602, -73.0375, -77.5235, -79.8409, -69.4253, -60.8278,
            -inf, -74.3559, -80.4903], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -68.0502, -71.3513, -76.0712, -78.4571, -68.2386,     -inf,
            -inf, -73.7404, -79.4258], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.1311,     -inf, -72.1405,     -inf,
            -inf, -77.6123, -81.6055], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -79.3602, -83.4827], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 272: Reward=-328.56, route=[0, 7, 6, 1, 2, 4, 5, 3, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.5970, -72.4875, -77.3953, -80.1639, -70.2169, -61.3373,
        -69.5284, -75.5357, -80.6075], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.1354, -73.1216, -77.5900, -79.8987, -69.4747,     -inf,
            -inf,     -inf, -80.5572], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.0234,     -inf, -82.8094, -74.1653,     -inf,
            -inf,     -inf, -82.8708], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.6800, -68.3657,     -inf,
            -inf,     -inf, -79.0811], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -81.2213], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 273: Reward=-250.33, route=[0, 6, 8, 7, 1, 3, 2, 5, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.2349, -71.4089, -75.9783, -79.1966, -69.9310, -60.8062,
        -69.0192, -74.8715, -80.1281], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.7300, -70.3115, -74.6996, -77.5234, -67.9702,     -inf,
        -67.6140, -73.1221, -78.9817], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.7798,     -inf, -76.6893,     -inf, -71.8906,     -inf,
            -inf,     -inf, -81.1065], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.3724], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 274: Reward=-326.15, route=[0, 6, 7, 2, 8, 4, 1, 3, 5, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.2887, -77.8405, -81.3587, -72.2683, -62.5922,
        -70.5663, -76.7357, -81.8169], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.5954, -76.6179,     -inf, -71.8066,     -inf,
        -70.9760, -76.9358, -81.0627], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.9993,     -inf,     -inf,     -inf,     -inf,
            -inf, -71.0177,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -73.0805,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 275: Reward=-304.32, route=[0, 1, 6, 4, 7, 3, 9, 5, 2, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.6111, -70.5219, -74.5562, -78.3871, -69.6794, -60.2146,
        -68.4466, -73.9405, -79.6137], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.1243, -69.4481, -73.3157, -76.7374, -67.7189,     -inf,
        -67.0509, -72.2041, -78.4877], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -68.1022, -71.1231, -74.7268, -78.0864, -68.8844,     -inf,
            -inf, -72.7630, -79.5448], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -73.1412, -76.8165, -68.0801,     -inf,
            -inf, -72.8916, -78.5230], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.9529, -83.6668,     -inf,     -inf,
            -inf, -78.8822,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -73.6132, -76.5791,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 276: Reward=-302.38, route=[0, 6, 7, 1, 2, 5, 9, 8, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.1243, -69.4481, -73.3157, -76.7374, -67.7189,     -inf,
        -67.0509, -72.2041, -78.4877], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -68.1022, -71.1231, -74.7268, -78.0864, -68.8844,     -inf,
            -inf, -72.7630, -79.5448], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.3839, -76.3816, -80.5123, -71.9984,     -inf,
            -inf, -75.7600, -81.2955], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.1193,     -inf, -82.0057,     -inf,     -inf,
            -inf, -77.7527,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -75.7348,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 277: Reward=-296.04, route=[0, 6, 7, 1, 5, 9, 3, 2, 8, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.3087, -75.1991, -79.6198, -71.7027, -61.3267,
        -69.3955, -74.7562, -80.4921], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.9344,     -inf, -80.9722, -73.5714,     -inf,
        -71.0814, -76.6171, -81.4867], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -69.6126,     -inf,     -inf, -71.2354,     -inf,
            -inf, -74.9986, -79.7607], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -67.7885,     -inf,
            -inf, -71.9434, -77.8231], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -77.8652,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 278: Reward=-323.5, route=[0, 1, 6, 3, 7, 4, 2, 5, 9, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -65.9461, -68.9136, -72.3007, -75.5437, -66.5895, -57.6276,
        -65.4052,     -inf, -77.5712], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.3890, -75.2637, -79.6755, -71.7436,     -inf,
        -69.4567,     -inf, -80.5596], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.1832, -73.6978, -77.3036, -68.6275,     -inf,
            -inf,     -inf, -78.8723], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.9574, -71.5944, -74.8768,     -inf,     -inf,
            -inf,     -inf, -77.0582], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.1347,     -inf,     -inf,
            -inf,     -inf, -81.6194], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 279: Reward=-267.86, route=[0, 8, 6, 1, 7, 5, 2, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -65.1640, -67.3253,     -inf,     -inf,     -inf,     -inf,
        -65.3271,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -67.1986,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 280: Reward=-323.72, route=[0, 4, 3, 6, 8, 9, 5, 1, 2, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.4593, -68.7236, -72.4279, -76.7690, -69.5350, -59.3342,
        -67.6918, -72.0752, -78.4244], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.0052, -67.6961, -71.2504, -75.1656, -67.5662,     -inf,
        -66.3064, -70.3624, -77.3422], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -72.8843,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 281: Reward=-268.36, route=[0, 6, 1, 9, 5, 2, 4, 8, 7, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.4593, -68.7236, -72.4279, -76.7690, -69.5350, -59.3342,
        -67.6918, -72.0752, -78.4244], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.0052, -67.6961, -71.2504, -75.1656, -67.5662,     -inf,
        -66.3064, -70.3624, -77.3422], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4914, -72.0976,     -inf, -71.8973,     -inf,
        -69.7302, -73.4470, -78.9089], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.6878,     -inf, -76.0007,     -inf,
        -71.8754, -76.1742,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.9487,     -inf, -69.3338,     -inf,
            -inf, -70.3084,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -75.1603,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 282: Reward=-306.9, route=[0, 6, 1, 4, 2, 9, 7, 5, 3, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True False  True False False]
greedy_action q_values = tensor([    -inf, -65.7533,     -inf, -70.1864, -74.8228,     -inf, -58.1579,
            -inf, -70.3770, -76.9611], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -65.6077,     -inf, -70.4863, -74.8347,     -inf,     -inf,
            -inf, -69.7178, -77.0503], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -73.3698, -78.4952,     -inf,     -inf,
            -inf, -73.2275, -79.7503], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -70.6644, -74.5413,     -inf,     -inf,
            -inf,     -inf, -76.9633], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -79.0606], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 283: Reward=-280.56, route=[0, 7, 5, 2, 6, 1, 8, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -65.0320, -67.8925, -70.5269, -74.4295, -67.1597, -57.4222,
        -65.2341,     -inf, -76.8034], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -71.5998, -72.4701, -75.6225, -81.3958, -75.9457,     -inf,
        -71.8305,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.3442, -73.4130, -78.5332, -72.4706,     -inf,
        -69.3960,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.1008, -71.4743, -75.9573, -69.7420,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.8903, -74.6697, -68.9480,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.5261, -73.6480,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.6537,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 284: Reward=-280.18, route=[0, 8, 6, 9, 1, 7, 2, 5, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2303, -68.2999, -71.0870, -76.0525, -70.4305, -59.3574,
        -67.6761, -70.4580, -77.7865], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -70.8380, -72.3915, -75.1273, -81.1289,     -inf,     -inf,
        -71.8128,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.2696, -72.9453, -78.2834,     -inf,     -inf,
        -69.3741,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.1286, -71.4984, -75.9938,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.9148, -74.7060,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.6537,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 285: Reward=-254.44, route=[0, 6, 8, 5, 9, 1, 7, 2, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2303, -68.2999, -71.0870, -76.0525, -70.4305, -59.3574,
        -67.6761, -70.4580, -77.7865], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -63.9757, -66.9025,     -inf, -73.5732,     -inf,     -inf,
        -65.2898,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.2785,     -inf, -78.2889,     -inf,     -inf,
        -69.4031,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.4585,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 286: Reward=-262.28, route=[0, 6, 9, 3, 8, 5, 1, 7, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.8365, -76.6948, -63.8225,
        -71.9640, -74.5744,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.3967, -68.7849,     -inf,
        -66.6113, -68.3150,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.0950, -67.9122,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 287: Reward=-252.61, route=[0, 1, 2, 3, 9, 6, 7, 8, 5, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -68.7571, -70.3760,     -inf, -79.1238, -74.9342, -62.5110,
        -70.9971, -73.3881, -80.2076], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -64.2343, -67.0654,     -inf, -74.2423, -68.6331,     -inf,
        -66.4577, -68.1526, -76.7462], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -69.8733,     -inf, -77.8499, -73.0247,     -inf,
        -69.3968, -71.6082, -79.3900], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -66.5631,     -inf, -73.2237,     -inf,     -inf,
            -inf, -66.8421, -76.0637], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.3291,     -inf,     -inf,
            -inf, -68.9373, -76.8135], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.7725], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 288: Reward=-304.86, route=[0, 3, 6, 1, 7, 5, 2, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False  True False False]
greedy_action q_values = tensor([    -inf, -64.7591, -68.4417,     -inf, -75.4092, -69.8885, -59.0375,
            -inf, -68.0776, -77.8813], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -62.8790, -66.3086,     -inf,     -inf,     -inf,     -inf,
            -inf, -66.3232, -76.2041], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -69.6296,     -inf,     -inf,     -inf,     -inf,
            -inf, -71.1162, -79.5798], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -74.0838,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 289: Reward=-337.72, route=[0, 3, 7, 6, 4, 5, 1, 2, 9, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.3619, -70.0851,     -inf, -78.9278, -75.0449,     -inf,
        -71.4749, -72.8974, -80.3693], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5834,     -inf, -77.6728, -73.1342,     -inf,
        -69.8274, -71.0967, -79.5297], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.1386, -69.1435,     -inf,
        -67.6075, -68.4331, -76.9366], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -75.4916, -69.9577,     -inf,
            -inf, -68.1702, -78.0161], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.8852, -67.9155,     -inf,
            -inf,     -inf, -76.8888], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.2029,     -inf,     -inf,
            -inf,     -inf, -76.3232], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 290: Reward=-267.47, route=[0, 6, 3, 1, 2, 7, 8, 5, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.2435, -67.7669, -70.4123, -75.6211, -70.7406, -59.5456,
        -68.2373, -69.2997, -77.9000], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -63.8633, -66.7873, -69.3265, -74.0823, -68.7381,     -inf,
        -66.8411, -67.6249, -76.8817], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.3664, -69.0359, -73.8162, -68.2141,     -inf,
        -66.0565,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.5265, -70.2288, -75.4661, -70.2900,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -68.6615, -74.1609, -69.5107,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.0174, -75.4964,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.1900,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 291: Reward=-293.74, route=[0, 6, 1, 9, 8, 7, 2, 3, 5, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.1437, -67.6836, -69.8078, -75.5212, -70.9972, -59.8052,
        -68.4532, -69.0474, -78.0154], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -69.4784, -71.4599, -77.5541, -73.3890,     -inf,
            -inf, -70.7711, -79.6043], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.0174, -75.4964,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 292: Reward=-334.9, route=[0, 6, 7, 1, 2, 9, 8, 3, 5, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.1437, -67.6836, -69.8078, -75.5212, -70.9972, -59.8052,
        -68.4532, -69.0474, -78.0154], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -63.7742, -66.7141, -68.7473, -73.9958, -68.9882,     -inf,
        -67.0521, -67.3728, -77.0088], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4489, -69.6532, -75.3721,     -inf,     -inf,
            -inf, -67.0930, -78.2170], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.3474, -68.5257, -73.7870,     -inf,     -inf,
            -inf,     -inf, -77.1108], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -68.1403, -74.1179,     -inf,     -inf,
            -inf,     -inf, -77.2133], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 293: Reward=-251.52, route=[0, 6, 1, 5, 7, 8, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.0919, -67.6840, -69.3121, -75.5052, -71.0962, -59.7699,
        -68.6446, -68.2790, -78.1137], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -63.7313, -66.7228, -68.2737, -73.9915, -69.0831,     -inf,
        -67.2383, -66.6132, -77.1183], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -69.4908, -70.9506, -77.5420, -73.5173,     -inf,
        -70.2183, -70.0306, -79.7140], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -68.0735, -74.0278, -69.5032,     -inf,
        -67.9953, -67.4091, -77.1457], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.7591, -75.4965,     -inf,     -inf,
            -inf,     -inf, -78.3143], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 294: Reward=-271.56, route=[0, 6, 1, 2, 8, 5, 7, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.0919, -67.6840, -69.3121, -75.5052, -71.0962, -59.7699,
        -68.6446, -68.2790, -78.1137], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -63.2532, -67.3083, -68.4625, -73.7350, -68.1960,     -inf,
        -66.1149,     -inf, -77.0397], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5548, -71.0005, -77.6045, -73.5609,     -inf,
        -70.2482,     -inf, -79.7534], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.7857,     -inf, -73.6884,     -inf,
        -71.1560,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -76.0982,     -inf,
        -72.3607,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -70.8782,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 295: Reward=-284.17, route=[0, 6, 8, 1, 2, 9, 4, 3, 7, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -69.7300, -72.1232, -72.8779, -80.6819, -77.5937, -64.4479,
        -73.0139, -72.5269,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -64.1192, -67.3003, -68.2209, -74.3504, -69.5862,     -inf,
        -67.5570, -66.3134,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.2516, -69.6747,     -inf, -73.5835,     -inf,
        -71.0871, -70.1618,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -68.7757,     -inf,
        -66.5237,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -70.8782,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 296: Reward=-284.6, route=[0, 9, 6, 1, 4, 2, 3, 8, 7, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.3956, -68.2062, -69.1789, -75.7921, -71.5267, -60.0616,
        -68.8760, -67.8971, -78.5614], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -63.0660, -66.7482, -67.5712, -73.2780,     -inf,     -inf,
        -66.2723, -64.9213, -76.8877], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -70.0513, -70.8288, -77.8673,     -inf,     -inf,
        -70.4840, -69.6969, -80.2089], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.0512, -69.5834, -75.7372,     -inf,     -inf,
            -inf,     -inf, -78.7171], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -68.0183, -74.4043,     -inf,     -inf,
            -inf,     -inf, -77.6637], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.3599,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 297: Reward=-247.82, route=[0, 6, 5, 1, 8, 7, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -67.4855, -68.9897, -69.8987,     -inf, -74.0471, -62.1250,
        -71.1917, -69.9968, -80.1277], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -63.8549, -67.6098, -67.9523,     -inf,     -inf,     -inf,
        -66.5095, -64.8437, -77.7211], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.4331,     -inf,     -inf,     -inf,     -inf,
        -72.4826, -71.5294, -81.9304], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -68.5388, -67.0622, -78.4874], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -66.6841,     -inf, -78.5150], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 298: Reward=-264.49, route=[0, 4, 6, 5, 1, 3, 2, 8, 7, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -65.7345, -69.7926, -69.8371, -76.1129, -71.2128,     -inf,
            -inf, -66.5489, -79.4094], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.0243, -73.2862, -81.1895, -78.1662,     -inf,
            -inf, -72.4734,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.7582, -68.8453, -74.6239, -69.2146,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -68.4255, -74.9155, -70.5745,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.9819,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 299: Reward=-298.16, route=[0, 6, 7, 1, 9, 8, 2, 3, 5, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False  True False]
greedy_action q_values = tensor([    -inf, -65.3071,     -inf, -69.3575, -75.4564, -69.7041, -59.7362,
        -67.1715,     -inf, -79.5861], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -65.8639,     -inf, -69.2036, -75.7419, -70.6833,     -inf,
        -68.3957,     -inf, -79.7108], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -70.6260,     -inf, -74.7236,     -inf,
        -71.9819,     -inf, -81.5461], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -77.1625,     -inf,
        -73.1944,     -inf, -83.2448], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -71.8927,     -inf,
            -inf,     -inf, -80.8392], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -79.0953], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 300: Reward=-293.95, route=[0, 2, 8, 6, 1, 4, 3, 7, 5, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.9346,     -inf, -68.8106, -75.6025, -70.9953, -60.5080,
        -69.0474, -67.4871, -79.5402], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -71.5767,     -inf, -73.8668, -82.1077, -78.8165,     -inf,
        -74.0189, -73.1510,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -68.6832, -74.7550,     -inf,     -inf,
            -inf, -65.4725,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.5048, -75.5755,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 301: Reward=-245.24, route=[0, 2, 6, 9, 1, 7, 5, 8, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -71.5051, -74.2317, -73.7862, -82.0435, -78.7542, -66.2162,
        -73.9429, -73.0825,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.6437, -72.7620, -80.3847, -75.8983,     -inf,
        -71.9378, -71.1774,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.4056, -70.3955, -76.6068, -70.4361,     -inf,
        -67.7513,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.6314,     -inf, -75.4861,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 302: Reward=-287.87, route=[0, 9, 6, 1, 8, 7, 2, 4, 3, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -66.2182, -71.2984, -70.2621, -76.5137, -70.3236, -60.8126,
        -67.5957,     -inf, -80.6548], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -72.5762, -75.8392, -74.8322, -83.2686, -79.5406,     -inf,
        -74.5202,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.7121, -72.8146, -80.4506, -75.9442,     -inf,
        -71.9695,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.6107, -71.5415, -78.2571, -72.5985,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 303: Reward=-270.79, route=[0, 8, 6, 9, 1, 7, 3, 4, 5, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.0908, -71.6859, -71.0532, -78.2328, -73.3216, -62.8674,
        -70.2318, -69.3022, -81.7215], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.7169, -70.6962, -70.0470, -76.7242, -71.2676,     -inf,
        -68.7993, -67.6010, -80.7272], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.7966, -74.8290, -83.2291, -79.5123,     -inf,
        -74.5131, -74.1116,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.3803, -70.5480,     -inf,     -inf,     -inf,
        -68.0285,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.7180, -72.4893,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.3074,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 304: Reward=-302.08, route=[0, 6, 1, 9, 8, 4, 5, 7, 3, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.1373, -72.7198, -71.9586, -79.2237, -74.3416, -64.0295,
        -70.5391, -70.2829, -82.6911], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -68.6984, -73.5078, -72.2934, -79.1051, -73.4668,     -inf,
            -inf, -68.9554, -82.7657], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.6368, -73.6137, -81.3259, -76.8458,     -inf,
            -inf, -72.0653, -84.3458], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.3758, -71.2453, -77.5353, -71.3192,     -inf,
            -inf,     -inf, -81.7065], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.7780, -72.7274,     -inf,
            -inf,     -inf, -81.7536], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.8571,     -inf,     -inf,
            -inf,     -inf, -81.1674], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.6960], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 305: Reward=-300.95, route=[0, 6, 7, 1, 8, 3, 2, 5, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -66.7262, -71.1729, -70.3526, -76.6943,     -inf, -61.4631,
        -67.8306, -67.1554, -80.9655], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.4855, -72.6932, -72.3376,     -inf,     -inf,     -inf,
        -72.7403, -72.6365, -83.5318], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.7032, -73.6457,     -inf,     -inf,     -inf,
        -72.1995, -72.1646, -84.4255], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.4422, -71.2773,     -inf,     -inf,     -inf,
        -67.9892,     -inf, -81.7862], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.6609, -72.4255,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.9244], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.0142,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 306: Reward=-254.0, route=[0, 5, 6, 4, 1, 8, 7, 3, 9, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.3111, -73.6745, -73.3246, -80.0437, -75.4213, -64.9963,
        -70.9909, -71.6812, -83.4856], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.1484,     -inf,     -inf, -78.5638, -73.7745,     -inf,
            -inf,     -inf, -82.4992], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.3019, -78.0530,     -inf,
            -inf,     -inf, -85.2800], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.2847,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 307: Reward=-303.22, route=[0, 6, 7, 8, 3, 2, 1, 5, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True False False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.3472, -72.6147, -78.4050,     -inf, -62.9174,
        -68.3736,     -inf, -82.5342], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.3240,     -inf,     -inf,     -inf,
        -75.4334,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -73.9287,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 308: Reward=-274.98, route=[0, 5, 1, 8, 6, 2, 4, 9, 7, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -71.0465, -75.6217, -75.3626, -80.9751, -75.9436, -65.4040,
            -inf, -71.9246, -84.3489], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.3023, -73.4619, -78.5577,     -inf,     -inf,
            -inf, -70.0610, -82.6497], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.6330,     -inf,     -inf,
            -inf,     -inf, -87.0015], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 309: Reward=-280.29, route=[0, 7, 6, 1, 5, 8, 2, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -69.0463, -73.2550, -73.3857, -78.5271,     -inf, -63.3110,
        -68.6952, -70.0588, -82.5693], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.7337, -77.3039,     -inf, -84.4737,     -inf,     -inf,
        -74.8998, -77.3212, -86.8558], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.9496,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 310: Reward=-273.01, route=[0, 5, 6, 3, 1, 7, 9, 8, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.5029, -74.8325, -75.0342, -81.0695, -76.8420, -65.9368,
        -71.4411, -73.3100, -84.2891], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.0977, -73.8182, -74.0059, -79.5513, -74.7209,     -inf,
        -69.9880, -71.5221, -83.3007], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -72.5753, -77.2325, -77.1342, -82.3027, -77.7315,     -inf,
            -inf, -73.7005, -85.1893], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.4105, -78.5158, -84.5468, -81.2587,     -inf,
            -inf, -76.9996, -86.7575], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.0591, -76.0444, -80.7117, -75.4965,     -inf,
            -inf,     -inf, -84.1360], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 311: Reward=-244.98, route=[0, 6, 7, 1, 8, 5, 4, 3, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.7417,     -inf, -75.4141, -80.7936, -76.9057, -66.0298,
        -71.1461, -74.1001, -83.9838], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.6287,     -inf, -75.7899, -80.9174, -76.5325,     -inf,
        -70.4296, -73.3172, -84.1508], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -72.6227,     -inf, -77.1961, -82.3694, -77.7874,     -inf,
            -inf, -73.7591, -85.2521], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -83.3747,     -inf,
            -inf, -79.1737, -87.7197], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -75.5695,     -inf,
            -inf,     -inf, -84.2414], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.5931], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 312: Reward=-274.23, route=[0, 2, 6, 7, 1, 4, 3, 8, 5, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.0031, -76.4040, -76.7701, -82.3784, -78.6312, -67.3419,
        -71.8505, -75.0825, -85.0724], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.5814, -75.3721, -75.7280, -80.8507, -76.4766,     -inf,
        -70.3913, -73.2586, -84.0879], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -72.5753, -77.2325, -77.1342, -82.3027, -77.7315,     -inf,
            -inf, -73.7005, -85.1893], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.8558, -76.3895, -80.5369,     -inf,     -inf,
            -inf, -73.4216, -83.8928], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1155, -77.2984, -81.4465,     -inf,     -inf,
            -inf,     -inf, -84.6422], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.7966, -81.6146,     -inf,     -inf,
            -inf,     -inf, -84.6043], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -86.6759,     -inf,     -inf,
            -inf,     -inf, -88.2252], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 313: Reward=-266.44, route=[0, 6, 7, 1, 5, 8, 2, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.2666, -77.4264, -77.9928, -83.0601, -80.2004, -68.4991,
        -72.3154, -76.8020, -85.5084], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf, -73.8552, -78.2801,     -inf, -83.0074, -79.2861,     -inf,
            -inf, -75.4330, -85.6629], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.4687,     -inf, -85.2487, -82.8674,     -inf,
            -inf, -78.7988, -87.2175], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.0966,     -inf, -81.4161, -77.0191,     -inf,
            -inf,     -inf, -84.6179], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.9414,     -inf, -80.6161,     -inf,     -inf,
            -inf,     -inf, -83.9639], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.6224,     -inf,     -inf,
            -inf,     -inf, -84.6272], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.5038], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 314: Reward=-262.7, route=[0, 6, 3, 7, 1, 8, 5, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.2666, -77.4264, -77.9928, -83.0601, -80.2004, -68.4991,
        -72.3154, -76.8020, -85.5084], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -77.5891,     -inf,     -inf, -86.5389, -84.9990,     -inf,
        -75.8323, -80.9969, -88.0901], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True  True False False]
greedy_action q_values = tensor([    -inf, -73.9035,     -inf,     -inf, -83.0746, -79.3431,     -inf,
            -inf, -75.4927, -85.7262], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.3159, -82.9244,     -inf,
            -inf, -78.8585, -87.2807], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 315: Reward=-278.87, route=[0, 6, 2, 3, 7, 1, 8, 5, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -72.8150, -76.5468, -77.4958, -80.9764,     -inf, -66.4099,
        -69.6634, -75.0919, -83.9837], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.9514, -77.1640, -78.1681, -82.0461,     -inf,     -inf,
        -71.0116, -76.7074, -84.7505], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.2547, -81.0045, -85.7537,     -inf,     -inf,
            -inf, -80.6174, -87.3915], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.9286, -82.0092,     -inf,     -inf,
            -inf, -77.5810, -84.7208], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.5672, -82.0026,     -inf,     -inf,
            -inf,     -inf, -84.8891], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 316: Reward=-265.93, route=[0, 5, 6, 7, 1, 2, 8, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.8057,     -inf, -87.0362, -86.1458,     -inf,
        -76.0621, -82.8851,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 317: Reward=-305.27, route=[0, 9, 6, 1, 3, 7, 5, 2, 8, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.4994, -79.1745,     -inf, -79.7687,     -inf,
        -71.2775, -78.2908,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.4094, -80.6234,     -inf, -81.0648,     -inf,
            -inf, -78.7809,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.9662,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 318: Reward=-257.23, route=[0, 1, 4, 9, 6, 7, 8, 5, 2, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.2252, -78.4173, -80.0963, -83.9706, -81.8545, -69.2906,
        -72.6227, -80.1031, -85.6689], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.7761, -77.3812, -79.0465, -82.4557, -79.6369,     -inf,
        -71.1503, -78.1726, -84.7253], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.4727, -81.8954, -86.1666, -84.5803,     -inf,
            -inf, -82.1630, -87.3412], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.8034, -82.4119, -80.0954,     -inf,
            -inf, -79.0611, -84.6906], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -87.4822, -86.7501,     -inf,
            -inf, -84.4603, -88.2519], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.4333, -78.6820,     -inf,
            -inf,     -inf, -84.9001], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.6146,     -inf,     -inf,
            -inf,     -inf, -84.2395], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 319: Reward=-292.01, route=[0, 6, 7, 1, 2, 3, 8, 5, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -81.6806, -82.9835, -84.8711, -89.8142, -89.0526,     -inf,
        -77.2666,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf, -76.5221, -79.5201, -81.2835, -84.6653, -81.4023,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.6868, -82.6767, -86.8848, -85.0695,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.5801, -83.1158, -80.5662,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -88.1978, -87.2526,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 320: Reward=-321.87, route=[0, 8, 6, 9, 7, 1, 2, 3, 5, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -80.0944, -80.9930,     -inf, -87.9472, -87.0369, -72.5969,
        -76.2670, -85.4317, -88.0270], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.0220,     -inf, -82.1158,     -inf,     -inf,
        -70.1672, -77.6870,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.3359,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 321: Reward=-319.65, route=[0, 3, 6, 9, 1, 5, 7, 4, 8, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.7795, -78.4944, -80.7406, -84.5384, -82.1883, -69.1120,
        -72.7873, -81.0838, -85.6238], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.3301, -77.4671, -79.6967, -83.0268, -79.9624,     -inf,
        -71.3105, -79.1288, -84.6978], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -75.4698,     -inf, -79.7565, -83.2361, -80.4781,     -inf,
            -inf, -80.9409, -84.5146], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.6479,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.1445], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -88.1638], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 322: Reward=-287.01, route=[0, 6, 7, 2, 1, 4, 8, 5, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False  True False]
greedy_action q_values = tensor([    -inf, -74.8301, -77.8544, -80.3450,     -inf, -79.0148, -66.8445,
        -70.1368,     -inf, -84.6518], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf, -80.1367, -80.7492,     -inf,     -inf, -87.1983,     -inf,
            -inf,     -inf, -88.0026], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -80.5702,     -inf,
            -inf,     -inf, -84.6559], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 323: Reward=-304.34, route=[0, 4, 8, 6, 7, 3, 1, 2, 5, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.7512, -78.1421, -81.0963, -84.8283, -82.2618, -69.0195,
        -72.9092, -82.0300, -85.5173], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.3128, -77.1308, -80.0635, -83.3248, -80.0322,     -inf,
        -71.4299, -80.0518, -84.6105], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -76.3501, -79.0498, -81.5227, -84.8312, -81.3306,     -inf,
            -inf, -80.5530, -85.7100], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.1909, -82.9011, -87.0388, -85.0108,     -inf,
            -inf, -84.1520, -87.1675], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.8123, -83.2675, -80.5004,     -inf,
            -inf, -80.9679, -84.5661], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -83.9661,     -inf,
            -inf, -85.1986, -86.3717], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -78.8739, -84.1593], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.9230], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 324: Reward=-280.07, route=[0, 6, 7, 1, 2, 3, 4, 5, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.3964, -77.7477, -81.2888, -84.8129, -81.7097, -68.6775,
        -73.0573, -82.4104, -85.5312], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -81.1835, -82.1055, -85.3362, -90.0022, -88.5291,     -inf,
        -77.5358, -88.1722,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -76.0906, -78.7311, -81.7982, -84.9002, -80.8626,     -inf,
            -inf, -81.0061,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.6204,     -inf,     -inf, -78.5658,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -80.1140,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 325: Reward=-281.67, route=[0, 6, 9, 7, 1, 3, 4, 8, 2, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.3964, -77.7477, -81.2888, -84.8129, -81.7097, -68.6775,
        -73.0573, -82.4104, -85.5312], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.9745, -76.7526, -80.2689, -83.3232, -79.4867,     -inf,
        -71.5736, -80.4180, -84.6407], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -76.0058, -78.6732, -81.7302, -84.8343, -80.7762,     -inf,
            -inf, -80.9177, -85.7398], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.7872, -83.0896, -87.0192, -84.4520,     -inf,
            -inf, -84.5493, -87.1728], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.0134, -83.2580, -79.9589,     -inf,
            -inf, -81.3471, -84.5916], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.7957, -82.4206,     -inf,     -inf,
            -inf, -78.8373, -84.1189], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.7469, -83.3763,     -inf,     -inf,
            -inf,     -inf, -84.8826], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -88.0323,     -inf,     -inf,
            -inf,     -inf, -88.1199], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 326: Reward=-265.22, route=[0, 6, 7, 1, 2, 5, 8, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.6785, -76.8110, -81.1108, -84.4473, -80.5236, -67.5108,
        -73.0812, -82.7107, -85.5314], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -80.3875, -81.1072, -85.1272, -89.6048, -87.2741,     -inf,
            -inf, -88.4727,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.8852, -82.9666, -86.7074, -83.3290,     -inf,
            -inf, -84.9530,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.7132, -82.1482,     -inf,     -inf,
            -inf, -79.1951,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 327: Reward=-251.39, route=[0, 6, 7, 9, 1, 2, 5, 8, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -73.2032, -75.2969, -79.4858, -81.9689,     -inf, -64.8207,
        -70.2334, -79.0314, -83.9822], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.3245, -75.8683, -80.1368, -83.0129,     -inf,     -inf,
        -71.6212, -80.7595, -84.7016], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -75.3433, -77.7814, -81.5937, -84.5223,     -inf,     -inf,
            -inf, -81.2549, -85.7982], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.8576, -82.9279, -86.6804,     -inf,     -inf,
            -inf, -84.9201, -87.2115], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.8772, -82.9405,     -inf,     -inf,
            -inf, -81.7026, -84.6494], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -87.9586,     -inf,     -inf,
            -inf, -87.3273, -88.0706], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -83.0488,     -inf,     -inf,
            -inf,     -inf, -84.9298], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 328: Reward=-306.82, route=[0, 5, 6, 7, 1, 2, 3, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -74.4204, -76.6653, -81.1505, -84.1238,     -inf,     -inf,
            -inf, -81.2673, -85.5370], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.5657, -80.1117, -82.5926,     -inf,     -inf,
            -inf,     -inf, -84.6028], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.2026,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.1480], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 329: Reward=-232.14, route=[0, 5, 6, 7, 1, 8, 2, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False  True False  True]
greedy_action q_values = tensor([    -inf, -79.3608, -79.8967, -84.5843,     -inf, -85.6448, -71.4177,
            -inf, -88.5010,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.3505, -79.2293,     -inf,     -inf,     -inf,
            -inf, -79.1442,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.5043,     -inf,     -inf,     -inf,
            -inf, -81.8265,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -87.4734,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 330: Reward=-336.52, route=[0, 4, 7, 9, 6, 1, 5, 2, 3, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.3670, -81.2695, -84.9883, -79.4281,     -inf,
        -74.6997, -84.3281, -86.7290], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.3047, -79.0219, -81.4132, -73.5913,     -inf,
            -inf,     -inf, -84.4446], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.1141, -78.1665, -80.5656,     -inf,     -inf,
            -inf,     -inf, -83.7722], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.4093, -81.4358,     -inf,     -inf,
            -inf,     -inf, -84.3095], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -86.3266,     -inf,     -inf,
            -inf,     -inf, -87.6455], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.0169], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 331: Reward=-238.46, route=[0, 6, 1, 7, 8, 5, 2, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.5622, -74.4006, -79.5372, -82.8381, -76.7649, -65.5426,
        -73.0026, -82.1281, -85.1142], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.2157, -73.4842, -78.5923, -81.4165, -74.6146,     -inf,
        -71.5125, -80.1154, -84.2752], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.1863, -73.0124, -78.0491, -80.4624,     -inf,     -inf,
            -inf, -78.4138, -83.6717], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.2508, -79.9303,     -inf,     -inf,     -inf,
            -inf, -84.9542, -85.8827], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.3493,     -inf,     -inf,     -inf,
            -inf, -81.1396, -84.2767], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -88.0817,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 332: Reward=-260.8, route=[0, 6, 7, 5, 1, 4, 2, 3, 9, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -71.1768, -72.9810, -78.0089, -80.4461,     -inf, -62.9007,
        -70.1397, -78.4279, -83.6250], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.2610, -73.5114, -78.6197, -81.4531,     -inf,     -inf,
        -71.5386, -80.1697, -84.3208], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.2466, -75.4029, -80.0528, -82.9480,     -inf,     -inf,
            -inf, -80.6401, -85.4072], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.3006, -79.8073, -84.0659,     -inf,     -inf,
            -inf, -83.2010, -86.3008], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.3411,     -inf,     -inf,
            -inf,     -inf, -87.1614], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -85.5593], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 333: Reward=-282.94, route=[0, 5, 6, 7, 1, 2, 8, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.3982, -73.3385, -78.0929, -81.9079, -74.6604, -64.6180,
        -72.8120, -81.0158, -84.6707], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0808, -72.4473, -77.1894, -80.5151, -72.5425,     -inf,
        -71.3231, -79.0153, -83.8556], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.2793, -79.7795, -84.0307, -77.2786,     -inf,
        -74.5058, -83.1946, -86.2642], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.3567, -78.6553, -82.0301, -73.7452,     -inf,
            -inf, -79.4862, -84.9832], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.3093, -77.6657, -80.5663,     -inf,     -inf,
            -inf,     -inf, -84.0843], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.9964, -80.5239,     -inf,     -inf,
            -inf,     -inf, -83.8848], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.3411,     -inf,     -inf,
            -inf,     -inf, -87.1614], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 334: Reward=-259.08, route=[0, 6, 1, 7, 5, 8, 2, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.3982, -73.3385, -78.0929, -81.9079, -74.6604, -64.6180,
        -72.8120, -81.0158, -84.6707], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0808, -72.4473, -77.1894, -80.5151, -72.5425,     -inf,
        -71.3231, -79.0153, -83.8556], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.2793, -79.7795, -84.0307, -77.2786,     -inf,
        -74.5058, -83.1946, -86.2642], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.3567, -78.6553, -82.0301, -73.7452,     -inf,
            -inf, -79.4862, -84.9832], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.0212, -76.7304, -79.6118,     -inf,     -inf,
            -inf, -77.3425, -83.3192], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.9353, -80.4521,     -inf,     -inf,
            -inf, -80.0463, -83.8361], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.6581,     -inf,     -inf,
            -inf, -84.6305, -86.5847], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.1059,     -inf,     -inf,
            -inf,     -inf, -83.7265], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 335: Reward=-303.52, route=[0, 6, 1, 7, 5, 2, 3, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.6873, -72.3701, -77.2889, -81.3365, -73.1039, -64.1842,
        -72.7509, -80.0418, -84.1874], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -72.9647, -72.1276, -77.5429,     -inf, -75.2525,     -inf,
        -75.2017, -82.8491, -84.8346], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.3954,     -inf, -77.8781,     -inf, -72.2347,     -inf,
            -inf, -78.5348, -84.5413], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -84.6297, -86.6004], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 336: Reward=-320.39, route=[0, 6, 4, 2, 7, 1, 5, 3, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.6873, -72.3701, -77.2889, -81.3365, -73.1039, -64.1842,
        -72.7509, -80.0418, -84.1874], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.3925, -71.5050, -76.4180, -79.9679, -71.0101,     -inf,
        -71.2625, -78.0531, -83.3999], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.1103,     -inf, -79.0877,     -inf,     -inf,
        -69.9857, -76.4606, -82.9112], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.4388,     -inf, -81.5180,     -inf,     -inf,
            -inf, -78.5833, -84.5819], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.9018,     -inf,     -inf,
            -inf, -79.1240, -83.3960], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.1059,     -inf,     -inf,
            -inf,     -inf, -83.7265], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 337: Reward=-308.79, route=[0, 6, 1, 3, 5, 7, 2, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.2303, -71.6898, -76.6833, -80.6504, -71.9181, -64.0680,
        -72.8229, -78.9738, -83.9095], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.9544, -70.8465, -75.8419, -79.3093, -69.8420,     -inf,
        -71.3335, -76.9994, -83.1474], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.9979, -70.4323, -75.3711, -78.4140,     -inf,     -inf,
        -69.9978, -75.3577, -82.6045], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7460, -76.3547, -79.3997,     -inf,     -inf,
        -70.0559,     -inf, -83.4181], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.6344, -79.2991,     -inf,     -inf,
            -inf,     -inf, -83.1662], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.7166,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 338: Reward=-247.82, route=[0, 6, 5, 1, 8, 7, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.2303, -71.6898, -76.6833, -80.6504, -71.9181, -64.0680,
        -72.8229, -78.9738, -83.9095], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -72.6098, -71.5072, -77.0106,     -inf,     -inf,     -inf,
            -inf, -81.8670,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -70.2197,     -inf, -75.5800,     -inf,     -inf,     -inf,
            -inf, -78.1080,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 339: Reward=-281.05, route=[0, 6, 7, 5, 9, 4, 2, 1, 3, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False False  True False]
greedy_action q_values = tensor([    -inf, -69.1022,     -inf, -75.8412,     -inf, -68.2830, -61.9932,
        -70.0404,     -inf, -83.0462], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False  True  True]
greedy_action q_values = tensor([    -inf, -75.2065,     -inf, -79.8660,     -inf, -77.7783,     -inf,
        -77.4915,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.9707,     -inf, -74.0628,     -inf,
        -74.7405,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 340: Reward=-279.38, route=[0, 2, 4, 8, 6, 9, 1, 5, 7, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.7230, -71.6188, -76.1850, -80.0635, -71.3268, -64.0615,
        -72.8801, -77.9381, -83.5723], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -69.0921, -71.6476, -75.8217, -78.7931, -68.2373,     -inf,
        -70.0505,     -inf, -83.0295], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.5858, -70.4533, -74.9810, -77.9430,     -inf,     -inf,
        -70.0817,     -inf, -82.3614], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.1552, -78.7283,     -inf,     -inf,
        -72.4012,     -inf, -82.8576], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.6106,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.3860], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -85.9527], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 341: Reward=-264.08, route=[0, 6, 8, 5, 1, 2, 7, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False  True False]
greedy_action q_values = tensor([    -inf, -68.5478, -70.4152, -74.9394, -77.9237,     -inf, -61.4785,
        -70.0296,     -inf, -82.3031], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -69.3840,     -inf, -74.7979, -78.3344,     -inf,     -inf,
        -72.6100,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.5914, -81.8953,     -inf,     -inf,
        -74.9006,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.6500, -80.0588,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.9462,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 342: Reward=-278.96, route=[0, 8, 5, 6, 9, 2, 1, 7, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.2766, -72.1768, -75.8021, -79.6271, -70.9817, -64.1035,
        -73.0163, -76.9220, -83.6978], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.0401, -71.3464, -75.0159, -78.3357, -68.9136,     -inf,
        -71.5241, -74.9745, -82.9822], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.1089, -70.9411, -74.5836, -77.4764,     -inf,     -inf,
        -70.1771, -73.3429, -82.4705], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.1084, -77.4097, -81.7032,     -inf,     -inf,
        -74.7418, -79.0696, -85.2587], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.7324, -78.2355,     -inf,     -inf,
        -72.5135, -76.0889, -82.9494], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.5298, -79.9298,     -inf,     -inf,
            -inf, -75.4588, -84.1890], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.2058,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.5006], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.0540], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 343: Reward=-256.95, route=[0, 6, 5, 1, 2, 7, 8, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.2766, -72.1768, -75.8021, -79.6271, -70.9817, -64.1035,
        -73.0163, -76.9220, -83.6978], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.0401, -71.3464, -75.0159, -78.3357, -68.9136,     -inf,
        -71.5241, -74.9745, -82.9822], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.7170, -72.8818,     -inf,     -inf,     -inf,     -inf,
        -70.3231,     -inf, -83.3317], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8210,     -inf,     -inf,     -inf,     -inf,
        -74.9054,     -inf, -85.3538], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -72.6835,     -inf, -83.0740], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.3155], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 344: Reward=-301.25, route=[0, 6, 5, 4, 3, 8, 1, 2, 7, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.2392, -72.7745, -75.6217, -79.2348, -71.1384, -64.3863,
        -73.1108, -76.1795, -83.7232], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4728, -72.4888, -75.7868,     -inf, -73.3129,     -inf,
        -75.6432, -79.0207, -84.3039], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.0266,     -inf,     -inf, -75.7440,     -inf,
            -inf, -80.5766, -85.8896], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.7211], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 345: Reward=-297.81, route=[0, 6, 4, 1, 7, 3, 2, 8, 5, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.2392, -72.7745, -75.6217, -79.2348, -71.1384, -64.3863,
        -73.1108, -76.1795, -83.7232], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.0154, -71.9459, -74.8589, -77.9683, -69.0638,     -inf,
        -71.6173, -74.2397, -83.0288], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.0088,     -inf, -82.2826, -75.7514,     -inf,
        -76.8040, -80.6249, -85.8826], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.8263, -69.5751,     -inf,
        -72.6191, -75.3425, -82.9654], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.2238,     -inf,     -inf,
        -70.3539, -72.7161, -82.6640], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -83.5659,     -inf,     -inf,
            -inf, -81.2437,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 346: Reward=-289.5, route=[0, 6, 1, 3, 2, 5, 7, 9, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.6122, -73.1376, -75.5026, -78.7735, -71.3466, -64.7886,
        -73.0533, -75.5595, -83.6320], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -74.9299, -77.1688, -78.9157, -83.4325, -77.7551,     -inf,
        -77.6196, -81.1352,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.1121, -77.1086, -80.8336, -73.9986,     -inf,
        -74.8434, -77.7144,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.3263, -76.2628, -79.1128,     -inf,     -inf,
            -inf, -74.0926,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.3106, -75.4056, -77.7584,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.0064,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 347: Reward=-256.91, route=[0, 6, 9, 1, 5, 7, 8, 2, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.6122, -73.1376, -75.5026, -78.7735, -71.3466, -64.7886,
        -73.0533, -75.5595, -83.6320], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False  True False]
greedy_action q_values = tensor([    -inf, -71.9032, -72.9143, -75.7077,     -inf, -73.5797,     -inf,
        -75.6371,     -inf, -84.2454], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.2924, -79.0310,     -inf, -77.8313,     -inf,
        -77.6841,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.5582,     -inf, -69.9250,     -inf,
        -72.6722,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.3847,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 348: Reward=-281.18, route=[0, 6, 8, 4, 1, 9, 2, 5, 7, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False  True  True]
greedy_action q_values = tensor([    -inf, -69.9669,     -inf, -74.5190, -77.0841, -70.1613, -64.0316,
        -72.4359,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -69.8956,     -inf, -75.0102, -77.3659, -69.7085,     -inf,
        -71.5582,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -74.1222,     -inf,     -inf, -81.5571,     -inf,     -inf,
        -76.7543,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.6105,     -inf,     -inf,
        -74.7996,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.8929,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 349: Reward=-297.58, route=[0, 8, 9, 2, 6, 5, 3, 1, 7, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.9244, -73.6387, -75.5503, -78.3958, -71.6361, -65.1759,
        -72.8909, -75.3156, -83.6020], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.7120, -72.8179, -74.8290, -77.1774, -69.5435,     -inf,
        -71.4005, -73.3761, -82.9522], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.7899, -72.4167, -74.4389, -76.3691,     -inf,     -inf,
        -70.0385, -71.7322, -82.4817], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.6006, -77.1133, -80.4181,     -inf,     -inf,
        -74.6146, -77.4412, -85.1190], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.7930, -76.2701, -78.7005,     -inf,     -inf,
            -inf, -73.7511, -84.0845], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.4644, -75.8285,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.2925], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 350: Reward=-238.8, route=[0, 6, 5, 1, 7, 8, 4, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -69.3252, -73.6791, -75.2931, -77.2733, -68.4742, -63.0396,
        -69.9729,     -inf, -83.1446], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -70.1215, -73.4383, -75.2611, -77.0107, -69.8065,     -inf,
        -71.5010,     -inf, -83.0564], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.2016, -73.0386, -74.8808, -76.2190,     -inf,     -inf,
        -70.1330,     -inf, -82.6003], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.2305, -77.5270, -80.2145,     -inf,     -inf,
        -74.7195,     -inf, -85.1887], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.4275, -76.7061, -78.5344,     -inf,     -inf,
            -inf,     -inf, -84.1866], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.9597, -76.8712,     -inf,     -inf,
            -inf,     -inf, -82.9965], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 351: Reward=-259.98, route=[0, 8, 6, 5, 1, 7, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.2638, -74.1812, -75.9052, -78.1351, -71.8640, -65.6324,
        -72.9594, -75.1890, -83.6338], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.3115, -75.7840, -77.1129, -68.7174,     -inf,
        -70.1042,     -inf, -83.3302], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.0115, -76.9220,     -inf,     -inf,
        -72.6195,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.8256, -78.6502,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 352: Reward=-300.55, route=[0, 6, 1, 8, 5, 9, 2, 7, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.2638, -74.1812, -75.9052, -78.1351, -71.8640, -65.6324,
        -72.9594, -75.1890, -83.6338], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.0572, -73.3629, -75.1987, -76.9391, -69.7619,     -inf,
        -71.4673, -73.2438, -83.0054], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5375, -73.9010, -76.0502,     -inf,     -inf,     -inf,
        -75.5723, -78.1517, -84.2104], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.7607, -77.9804,     -inf,     -inf,     -inf,
        -74.7016, -77.2181, -84.8910], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.9623, -77.1770,     -inf,     -inf,     -inf,
            -inf, -73.4853, -83.9305], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.0072,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 353: Reward=-253.31, route=[0, 6, 5, 4, 1, 7, 8, 3, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -72.7083, -74.3954, -76.4823,     -inf, -74.8004, -67.7886,
        -75.5167, -77.9852, -83.8371], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -70.3292, -73.9581, -75.7255,     -inf, -70.4532,     -inf,
        -71.4801, -73.1292, -82.8052], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.9347, -77.1494,     -inf, -71.6041,     -inf,
            -inf, -73.4362, -83.8849], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.5868, -75.4146,     -inf,     -inf,     -inf,
            -inf, -71.4395, -82.4155], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.9418, -76.3536,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.1921], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.4823,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.7886], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -85.5840], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 354: Reward=-254.52, route=[0, 4, 6, 1, 7, 5, 8, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False  True False]
greedy_action q_values = tensor([    -inf, -69.4302, -73.5699, -75.3682, -76.0189,     -inf, -63.5885,
        -70.0792,     -inf, -82.3403], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.4783, -76.6652,     -inf,     -inf,
        -72.5488,     -inf, -82.7807], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.0642, -78.4577,     -inf,     -inf,
            -inf,     -inf, -83.9269], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.9764], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 355: Reward=-276.19, route=[0, 8, 5, 6, 1, 2, 7, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.7130, -75.2105, -77.1615, -77.9489, -73.4668, -66.8551,
        -73.0556, -75.0752, -83.2657], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.5221, -74.3977, -76.4751, -76.7922, -71.3235,     -inf,
        -71.5610, -73.1144, -82.6891], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.4191,     -inf,     -inf,     -inf,
            -inf, -78.1135, -83.9060], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -79.6528, -85.3636], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.1917], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 356: Reward=-308.54, route=[0, 6, 1, 7, 2, 5, 4, 3, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.7130, -75.2105, -77.1615, -77.9489, -73.4668, -66.8551,
        -73.0556, -75.0752, -83.2657], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.5221, -74.3977, -76.4751, -76.7922, -71.3235,     -inf,
        -71.5610, -73.1144, -82.6891], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1797, -78.6997, -79.9019, -76.1334,     -inf,
        -74.7628, -77.1722, -84.6870], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.3880, -77.9088, -78.2892, -72.4854,     -inf,
            -inf, -73.4158, -83.7678], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.5078,     -inf, -80.8602,     -inf,     -inf,
            -inf, -79.6016, -85.2899], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.6341,     -inf,     -inf,
            -inf, -74.2779, -82.6310], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.1123,     -inf,     -inf,
            -inf,     -inf, -83.1795], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.7983], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 357: Reward=-313.41, route=[0, 6, 1, 7, 5, 3, 2, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.2446, -75.4076, -77.9799, -77.9266, -74.1372, -67.2336,
        -73.1607, -75.1562, -83.1110], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0566, -74.6026, -77.3007, -76.7885, -71.9755,     -inf,
        -71.6646, -73.1867, -82.5604], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.6092,     -inf, -78.2934, -73.1344,     -inf,
            -inf, -73.5114, -83.6552], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.2469,     -inf, -76.0781,     -inf,     -inf,
            -inf, -71.5020, -82.2274], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.6627,     -inf, -82.5517,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.7437,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 358: Reward=-261.23, route=[0, 6, 1, 3, 7, 5, 8, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.2446, -75.4076, -77.9799, -77.9266, -74.1372, -67.2336,
        -73.1607, -75.1562, -83.1110], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.9927, -76.5726, -78.6872, -78.2593, -73.1251,     -inf,
            -inf, -73.4600, -83.5835], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.9104, -79.0694,     -inf,
            -inf,     -inf, -85.1621], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.2119,     -inf,     -inf,
            -inf,     -inf, -82.3409], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.7983], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 359: Reward=-322.46, route=[0, 6, 7, 1, 2, 8, 3, 5, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.2446, -75.4076, -77.9799, -77.9266, -74.1372, -67.2336,
        -73.1607, -75.1562, -83.1110], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.8010, -74.8595, -78.0669, -77.0245, -72.4285,     -inf,
        -71.8035, -73.5782, -82.4889], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.6339, -80.2885, -80.0889, -77.3188,     -inf,
        -75.0166, -77.6884, -84.3979], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.8696, -79.5203, -78.5344, -73.6007,     -inf,
            -inf, -73.8742, -83.5627], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.9293, -82.2859,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 360: Reward=-321.72, route=[0, 6, 1, 7, 5, 4, 8, 9, 2, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.9890, -75.6571, -78.7375, -78.1475, -74.6049, -67.7255,
        -73.3017, -75.5623, -83.0134], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.8010, -74.8595, -78.0669, -77.0245, -72.4285,     -inf,
        -71.8035, -73.5782, -82.4889], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.6339, -80.2885, -80.0889, -77.3188,     -inf,
        -75.0166, -77.6884, -84.3979], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.3435, -78.8961,     -inf, -76.9521,     -inf,
            -inf, -78.5545, -83.4990], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.7160,     -inf, -72.9967,     -inf,
            -inf, -74.6850, -82.3600], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.8356,     -inf,     -inf,     -inf,
            -inf, -71.9001, -82.2299], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.8119,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.0148], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -85.0803], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 361: Reward=-253.21, route=[0, 6, 1, 7, 4, 2, 5, 8, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.9890, -75.6571, -78.7375, -78.1475, -74.6049, -67.7255,
        -73.3017, -75.5623, -83.0134], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.8010, -74.8595, -78.0669, -77.0245, -72.4285,     -inf,
        -71.8035, -73.5782, -82.4889], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1623, -80.3801, -78.6793, -74.0684,     -inf,
            -inf, -74.4134, -83.5163], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.7905, -78.6268, -76.4743,     -inf,     -inf,
            -inf, -72.3697, -82.1312], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.0436,     -inf,     -inf,
            -inf,     -inf, -82.4101], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 362: Reward=-263.28, route=[0, 6, 1, 7, 5, 8, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
greedy_action q_values = tensor([    -inf, -76.6674, -78.1262,     -inf,     -inf, -79.9966, -71.7202,
        -77.2169, -80.6910, -84.6827], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.9361,     -inf,     -inf, -77.7965,     -inf,
            -inf, -78.2401, -84.3361], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8152,     -inf,     -inf,     -inf,     -inf,
            -inf, -72.3952, -82.1603], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 363: Reward=-284.84, route=[0, 4, 3, 6, 7, 1, 5, 8, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.5329, -75.1403, -78.9151, -77.1615, -72.8914,     -inf,
        -72.0129, -74.1156, -82.4436], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -73.4859, -77.1317, -80.3215, -78.6477, -74.0493,     -inf,
            -inf, -74.3899, -83.4629], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.9115, -81.1457, -80.2089, -77.7932,     -inf,
            -inf, -78.2146, -84.3070], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.4114, -83.7643, -82.8567,     -inf,     -inf,
            -inf, -82.6185,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.3322, -77.1256,     -inf,     -inf,
            -inf, -75.9819,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.4444, -77.7405,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 364: Reward=-316.41, route=[0, 6, 7, 1, 5, 9, 2, 8, 4, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False  True  True False]
greedy_action q_values = tensor([    -inf, -77.4950, -78.4926,     -inf,     -inf, -80.6972, -72.1135,
            -inf,     -inf, -84.4719], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.3585, -75.5451,     -inf,     -inf, -73.5287,     -inf,
            -inf,     -inf, -82.3422], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.3138,     -inf,     -inf, -78.4998,     -inf,
            -inf,     -inf, -84.1556], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -74.1229,     -inf,
            -inf,     -inf, -82.1807], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.1138], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 365: Reward=-359.7, route=[0, 7, 4, 8, 3, 6, 1, 2, 5, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.1607, -81.7650, -80.2663, -78.4498, -70.5734,
        -75.2876, -78.8742, -84.0030], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.3834, -83.7260, -82.8154, -82.6046,     -inf,
        -78.3056, -82.6200,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.5260, -81.1382, -78.8589, -74.7653,     -inf,
            -inf, -75.1041,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.1480, -79.3825, -76.6616,     -inf,     -inf,
            -inf, -73.0378,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 366: Reward=-278.12, route=[0, 1, 6, 9, 7, 5, 8, 3, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.8465, -75.7409, -80.3968, -77.4153, -73.5906,     -inf,
        -72.2529, -75.2632, -82.0057], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -74.8152, -77.7561, -81.8221, -78.9159, -74.7555,     -inf,
            -inf, -75.5437, -83.0185], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.9062, -75.3729, -80.0623, -76.7268,     -inf,     -inf,
            -inf, -73.4573, -81.6842], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.5335, -82.6476, -80.4432,     -inf,     -inf,
            -inf, -79.4923, -83.8093], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -80.5159, -82.9663], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.6201], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 367: Reward=-307.24, route=[0, 6, 7, 5, 1, 2, 3, 4, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.0285, -76.5144, -81.0405, -78.4816, -75.8094, -68.5801,
        -73.7566, -77.2986, -82.4434], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.5334, -82.6388, -80.4364,     -inf,     -inf,
        -75.5101, -79.5430, -83.8093], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.8151, -81.9116, -78.9826,     -inf,     -inf,
            -inf, -75.6162, -83.1173], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.8247, -81.1287, -77.7849,     -inf,     -inf,
            -inf,     -inf, -82.5310], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.1257, -77.2665,     -inf,     -inf,
            -inf,     -inf, -81.9289], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.3418,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.0005], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 368: Reward=-214.92, route=[0, 6, 5, 1, 7, 8, 2, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.6520, -77.1214, -81.8294, -78.6748, -76.1001, -68.8912,
        -73.9820, -77.8389, -82.5188], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.5571, -75.9854, -80.8578, -76.9443,     -inf,     -inf,
        -71.0617, -74.0137, -81.8031], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -75.4947, -78.4102, -82.6612, -79.1700,     -inf,     -inf,
            -inf, -76.1167, -83.1657], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.1530, -83.4426, -80.6316,     -inf,     -inf,
            -inf, -80.0544, -83.8698], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.8494, -77.3909,     -inf,     -inf,
            -inf, -76.9893, -81.9664], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.0107, -78.0803,     -inf,     -inf,
            -inf,     -inf, -82.7175], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.1242,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.0502], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 369: Reward=-254.0, route=[0, 6, 5, 7, 1, 2, 8, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.6520, -77.1214, -81.8294, -78.6748, -76.1001, -68.8912,
        -73.9820, -77.8389, -82.5188], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.4731, -76.3509, -81.1949, -77.6258, -73.8672,     -inf,
        -72.4750, -75.7862, -82.1062], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -75.4486, -78.3819, -82.6307, -79.1352, -75.0343,     -inf,
            -inf, -76.0680, -83.1203], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.5337, -75.9858, -80.8670, -76.9516,     -inf,     -inf,
            -inf, -73.9626, -81.8038], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.8459,     -inf,     -inf,     -inf,
            -inf, -76.9857, -81.9760], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.0072,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.7271], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.3997], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 370: Reward=-265.17, route=[0, 6, 7, 5, 1, 4, 2, 8, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.6520, -77.1214, -81.8294, -78.6748, -76.1001, -68.8912,
        -73.9820, -77.8389, -82.5188], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -74.6000, -78.0437, -82.4830, -78.4621, -72.6559,     -inf,
        -71.0034,     -inf, -82.7454], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -79.1116, -80.0644,     -inf, -81.9086, -81.1606,     -inf,
            -inf,     -inf, -84.3326], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.8547,     -inf, -81.1544, -78.8903,     -inf,
            -inf,     -inf, -84.0212], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.9474,     -inf,     -inf,
            -inf,     -inf, -82.1902], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.1826], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 371: Reward=-241.45, route=[0, 6, 8, 7, 3, 1, 5, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.0471, -77.7545, -82.4386, -79.1548, -76.0768, -69.0323,
        -73.9776, -78.1602, -82.6593], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -74.7210, -78.1199, -82.5711, -78.5460,     -inf,     -inf,
        -71.1140,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -76.0449, -79.1904, -83.4172, -79.7998,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.9256, -84.1802, -81.2362,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 372: Reward=-267.73, route=[0, 6, 9, 5, 8, 7, 1, 2, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.0471, -77.7545, -82.4386, -79.1548, -76.0768, -69.0323,
        -73.9776, -78.1602, -82.6593], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -77.2792, -77.3489, -82.4868,     -inf, -78.5473,     -inf,
        -76.7112, -81.3383, -82.9504], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False False]
greedy_action q_values = tensor([    -inf, -75.8559, -79.0517, -83.2559,     -inf, -75.0113,     -inf,
            -inf, -76.3692, -83.2966], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -75.7400,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -77.7670,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -80.9504,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 373: Reward=-305.04, route=[0, 6, 4, 7, 5, 3, 9, 2, 1, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.7416, -82.6047, -79.2553, -73.7750,     -inf,
        -72.3327, -76.4861, -82.2434], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.0894, -83.2597,     -inf, -78.4874,     -inf,
            -inf, -81.7246, -82.8611], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.1466,     -inf, -74.3648,     -inf,
            -inf, -77.6356, -81.9881], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.3581,     -inf,     -inf,     -inf,
            -inf, -74.6801, -82.0539], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.3958,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.8629], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -86.8091,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 374: Reward=-250.25, route=[0, 1, 6, 7, 4, 2, 5, 8, 9, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.6741, -78.4737, -83.1550, -80.2520, -76.0065, -69.1625,
        -73.8114, -78.5439, -82.5481], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.0883, -83.2495,     -inf, -78.5135,     -inf,
        -76.5822, -81.7763, -82.8590], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.7610,     -inf,     -inf, -81.0974,     -inf,
            -inf, -83.3494, -84.1813], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -74.7454,     -inf,
            -inf, -77.8785, -82.2534], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 375: Reward=-301.99, route=[0, 6, 1, 4, 7, 3, 2, 5, 8, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False  True False]
greedy_action q_values = tensor([    -inf, -75.8992, -79.8240,     -inf, -81.1695, -72.9018, -67.2517,
        -71.1059,     -inf, -82.9211], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False  True False]
greedy_action q_values = tensor([    -inf, -76.2792, -78.8715,     -inf, -80.8928, -74.1748,     -inf,
        -72.6829,     -inf, -82.5226], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -77.2796, -80.9647,     -inf, -82.4733, -75.3483,     -inf,
            -inf,     -inf, -83.5468], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -81.7237,     -inf, -83.9320,     -inf,     -inf,
            -inf,     -inf, -84.1638], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.6165,     -inf,     -inf,
            -inf,     -inf, -82.3445], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.2467], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 376: Reward=-285.49, route=[0, 3, 8, 6, 7, 5, 1, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -78.5307, -79.0695, -83.7802,     -inf, -78.8924, -71.1008,
        -76.8324, -81.9536, -82.9326], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -76.2001, -78.8010, -83.2267,     -inf, -74.1502,     -inf,
        -72.6253, -76.6613, -82.4605], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False False]
greedy_action q_values = tensor([    -inf, -77.2006, -80.8943, -84.6958,     -inf, -75.3237,     -inf,
            -inf, -76.9417, -83.4847], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -75.2719, -78.4440, -82.9291,     -inf,     -inf,     -inf,
            -inf, -74.7937, -82.2222], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -80.5339,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.4874], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 377: Reward=-246.64, route=[0, 4, 6, 7, 5, 8, 2, 3, 1, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -77.5458, -80.1431, -84.2501, -83.2504, -76.4710, -69.7301,
        -74.1886, -78.9038, -82.5004], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -76.3931, -79.3780, -83.6676, -82.2189, -74.1886,     -inf,
        -72.6745, -76.7949, -82.1983], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -75.4733, -79.0247, -83.3837, -81.5690,     -inf,     -inf,
            -inf, -74.9139, -81.9863], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -76.1817, -80.5180, -84.4397, -82.6813,     -inf,     -inf,
            -inf,     -inf, -82.8098], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -82.3248, -85.9452, -85.3625,     -inf,     -inf,
            -inf,     -inf, -83.8377], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -86.1959,     -inf,     -inf,
            -inf,     -inf, -84.1897], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -87.9658,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 378: Reward=-244.88, route=[0, 6, 7, 5, 8, 1, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -76.0979, -80.4253, -84.3270, -82.5922, -72.9537, -67.4961,
        -71.1335,     -inf, -82.6798], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -76.4631, -79.4599, -83.7393, -82.2970, -74.2336,     -inf,
        -72.7077,     -inf, -82.2519], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -77.4689, -81.5727, -85.2190, -83.9092, -75.4119,     -inf,
            -inf,     -inf, -83.2763], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.5433, -79.1066, -83.4554, -81.6471,     -inf,     -inf,
            -inf,     -inf, -82.0399], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -84.4886,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.9048], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 379: Reward=-249.67, route=[0, 8, 6, 7, 5, 1, 2, 4, 9, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -77.5458, -80.1431, -84.2501, -83.2504, -76.4710, -69.7301,
        -74.1886, -78.9038, -82.5004], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -82.7521, -85.9301, -86.7250, -79.6121,     -inf,
        -76.0063, -81.5991, -83.3289], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -82.0662, -85.3450, -85.3578, -75.6371,     -inf,
            -inf, -77.4691, -82.9301], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.5871, -83.5930, -83.0668,     -inf,     -inf,
            -inf, -75.2901, -81.7211], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -81.0908, -84.6530, -84.2003,     -inf,     -inf,
            -inf,     -inf, -82.5482], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.4756, -83.4513,     -inf,     -inf,
            -inf,     -inf, -81.6974], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 380: Reward=-240.08, route=[0, 6, 1, 7, 5, 8, 2, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -78.6000, -80.1637, -84.2620,     -inf, -79.2589, -71.6651,
        -76.9751, -82.5414, -82.1884], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False  True]
greedy_action q_values = tensor([    -inf, -81.8996, -84.9830, -87.7276,     -inf, -83.9154,     -inf,
        -79.0027, -85.4980,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf, -77.4002, -82.0972, -85.3335,     -inf, -75.7004,     -inf,
            -inf, -77.5178,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -75.4837, -79.6164, -83.5814,     -inf,     -inf,     -inf,
            -inf, -75.3392,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -76.1965, -81.1212, -84.6413,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 381: Reward=-268.54, route=[0, 4, 6, 9, 7, 5, 8, 1, 3, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -81.8408, -84.9075, -87.6650, -89.2119, -83.8763, -75.3040,
        -78.9354, -85.4578,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -86.0218, -88.2792,     -inf,     -inf,
            -inf, -82.0891,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -84.7675, -85.7162,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -89.1217,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 382: Reward=-282.96, route=[0, 9, 6, 2, 5, 7, 1, 8, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -77.1697, -81.1855, -84.3000, -86.0771, -76.7563, -69.9349,
        -73.9885, -79.6336, -81.8410], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False  True]
greedy_action q_values = tensor([    -inf, -81.5765, -85.5252, -87.6239,     -inf, -83.9860,     -inf,
        -78.7391, -85.8983,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf, -77.1242, -82.6300, -85.2978,     -inf, -75.7163,     -inf,
            -inf, -77.8425,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -83.4601, -86.0215,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.4772,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 383: Reward=-274.65, route=[0, 6, 4, 9, 7, 5, 8, 1, 2, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -75.7772, -81.4964, -84.4642, -85.4668, -73.1838, -67.6897,
        -70.9169,     -inf, -82.1380], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -83.3650, -85.9269, -88.1964, -79.7004,     -inf,
        -75.7747,     -inf, -83.0785], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.6052, -83.3479, -85.3613,     -inf,     -inf,
            -inf,     -inf, -81.2661], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.0938, -85.6221,     -inf,     -inf,
            -inf,     -inf, -81.1137], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -89.9430,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 384: Reward=-248.85, route=[0, 8, 6, 1, 7, 5, 2, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.9960, -81.5948, -83.9492, -86.8977, -76.8831, -69.4844,
        -74.1804, -79.7461, -81.5022], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False  True]
greedy_action q_values = tensor([    -inf, -78.2429, -81.1803, -83.9175,     -inf, -79.5652,     -inf,
        -77.0928, -83.1932,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf, -76.9621, -83.0582, -84.9716,     -inf, -75.8297,     -inf,
            -inf, -77.9344,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -75.0715, -80.5492, -83.2614,     -inf,     -inf,     -inf,
            -inf, -75.7267,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -83.7977, -85.5755,     -inf,     -inf,     -inf,
            -inf, -82.1589,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -82.1154, -84.3951,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.1416,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 385: Reward=-316.94, route=[0, 6, 9, 4, 7, 5, 1, 8, 2, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.9960, -81.5948, -83.9492, -86.8977, -76.8831, -69.4844,
        -74.1804, -79.7461, -81.5022], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.8880, -80.8341, -83.4395, -85.8769, -74.5531,     -inf,
        -72.6576, -77.5868, -81.2951], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -76.8916, -82.9976, -84.9239, -87.5722, -75.7466,     -inf,
            -inf, -77.8616, -82.3128], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -81.4068, -85.9762, -87.2669, -91.5555,     -inf,     -inf,
            -inf, -86.0571,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -83.7845, -85.5828, -89.0487,     -inf,     -inf,
            -inf, -82.1661,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.4372, -85.2554,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -89.4563,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 386: Reward=-272.27, route=[0, 6, 7, 5, 9, 1, 8, 2, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.5083, -81.4749, -83.2162, -86.4680, -76.8898, -68.9397,
        -74.4077, -80.0176, -80.9380], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.5685, -80.3833, -82.5294, -84.8567,     -inf,     -inf,
        -71.4239, -75.9433, -80.6507], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.4648, -82.9239, -84.2495, -87.2133,     -inf,     -inf,
            -inf, -78.1607, -81.8226], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.3755,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.5769], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 387: Reward=-266.41, route=[0, 6, 5, 7, 1, 4, 8, 2, 9, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.5083, -81.4749, -83.2162, -86.4680, -76.8898, -68.9397,
        -74.4077, -80.0176, -80.9380], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.4203, -80.7244, -82.7420, -85.4778, -74.5456,     -inf,
        -72.8787, -77.8408, -80.7668], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -76.4173, -82.8965, -84.2178, -87.1755, -75.7408,     -inf,
            -inf, -78.1124, -81.7767], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -74.5480, -80.3869, -82.5437, -84.8685,     -inf,     -inf,
            -inf, -75.8898, -80.6573], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -81.0654, -83.2016,     -inf,     -inf,     -inf,
            -inf, -83.4420, -81.0873], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.3036,     -inf,     -inf,     -inf,
            -inf, -79.1371, -80.5236], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.3927], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 388: Reward=-265.17, route=[0, 6, 7, 5, 1, 4, 2, 8, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.1664, -81.0246, -82.0748, -85.8388, -76.6591, -68.3109,
        -74.9425, -80.2844, -80.4265], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -76.0862, -82.4616, -83.1029, -86.5764, -75.4959,     -inf,
            -inf, -78.3548, -81.2932], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -74.2338, -79.9619, -81.4769, -84.2975,     -inf,     -inf,
            -inf, -76.1178, -80.2084], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -85.4176, -85.2518,     -inf,     -inf,     -inf,
            -inf, -86.7209,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -83.4086,     -inf,     -inf,     -inf,     -inf,
            -inf, -85.5063,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -79.5082,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 389: Reward=-268.54, route=[0, 6, 7, 5, 1, 4, 9, 3, 2, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.1664, -81.0246, -82.0748, -85.8388, -76.6591, -68.3109,
        -74.9425, -80.2844, -80.4265], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -80.4728, -85.3391, -85.1527, -90.3147, -84.0116,     -inf,
        -79.7959, -86.7107,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -76.1578, -82.5083, -83.1553, -86.6256, -75.5704,     -inf,
            -inf, -78.4350,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -74.3054, -80.0086, -81.5293, -84.3467,     -inf,     -inf,
            -inf, -76.1979,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -83.2022, -83.6293, -87.9395,     -inf,     -inf,
            -inf, -82.7420,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.5911, -82.6614, -85.5792,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.3227, -84.6408,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -88.7636,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 390: Reward=-294.88, route=[0, 6, 9, 7, 5, 1, 8, 2, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.1664, -81.0246, -82.0748, -85.8388, -76.6591, -68.3109,
        -74.9425, -80.2844, -80.4265], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.0950, -80.2884, -81.6428, -84.8810, -74.3036,     -inf,
        -73.4011, -78.0889, -80.2909], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -75.5588, -82.0215, -82.3275, -85.8099, -75.2172,     -inf,
            -inf, -78.4446, -80.9661], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.7830, -80.0883, -81.1187,     -inf,     -inf,     -inf,
            -inf, -83.8851, -80.0950], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -79.7632], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 391: Reward=-300.96, route=[0, 6, 7, 5, 4, 1, 3, 8, 2, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False  True False]
greedy_action q_values = tensor([    -inf, -73.7549, -79.5462, -80.7228, -83.5834,     -inf, -65.1309,
        -72.4554,     -inf, -79.8707], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.6910, -79.9589, -80.9800, -84.2377,     -inf,     -inf,
        -74.0349,     -inf, -80.0654], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -81.3166], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 392: Reward=-235.9, route=[0, 8, 5, 6, 7, 4, 2, 3, 1, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -75.4945, -81.9560, -82.2544, -85.7608, -75.1845, -67.3506,
            -inf, -78.3945, -80.8799], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -74.5562, -79.8507, -80.8935, -84.1325, -74.0021,     -inf,
            -inf, -78.1327, -79.9759], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.8166,     -inf, -79.1791, -82.5783,     -inf,     -inf,
            -inf, -78.8821, -79.4727], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -85.0179, -81.0997], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 393: Reward=-254.8, route=[0, 7, 6, 5, 2, 1, 4, 3, 9, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -74.6831, -81.2172, -81.1412, -84.6978, -74.7262,     -inf,
            -inf, -77.7867, -80.8107], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 394: Reward=-293.69, route=[0, 6, 7, 1, 9, 4, 5, 3, 8, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.7395, -79.7470, -80.0610, -83.9004, -75.9259, -67.2508,
        -75.7300, -79.7721, -79.8858], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.7157, -79.0479, -79.7095, -83.0186, -73.5497,     -inf,
        -74.1652, -77.5503, -79.8161], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.8957, -79.2401, -79.8472,     -inf,     -inf,     -inf,
        -78.7027, -83.3447, -79.8699], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -81.8532, -81.4558,     -inf,     -inf,     -inf,
        -77.5689, -82.2092, -80.9770], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -81.2889, -81.2227,     -inf,     -inf,     -inf,
            -inf, -77.8485, -80.9122], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.4623, -79.7294,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.4612], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.2701,     -inf,     -inf,     -inf,
            -inf,     -inf, -79.3175], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.8032], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 395: Reward=-245.34, route=[0, 6, 5, 4, 1, 7, 8, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.8561, -78.8228, -79.0026, -82.7461, -75.7805, -66.7522,
        -76.2118, -79.4586, -79.5997], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.8599, -78.1484, -78.6935, -81.9071, -73.3917,     -inf,
        -74.6346, -77.2252, -79.5653], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.3217, -78.8074,     -inf,     -inf,     -inf,
        -79.2493, -83.0963, -79.6021], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.1842,     -inf,     -inf,     -inf,
        -75.8397, -78.6487, -79.2558], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.2479,     -inf,     -inf,     -inf,
            -inf, -77.5471, -80.7089], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 396: Reward=-263.6, route=[0, 6, 1, 5, 4, 2, 7, 8, 9, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.8561, -78.8228, -79.0026, -82.7461, -75.7805, -66.7522,
        -76.2118, -79.4586, -79.5997], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.8599, -78.1484, -78.6935, -81.9071, -73.3917,     -inf,
        -74.6346, -77.2252, -79.5653], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.8652, -80.3328, -84.6333, -78.7556,     -inf,
        -78.0444, -81.8620, -80.6152], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.2287, -81.4937, -74.1479,     -inf,
            -inf, -78.6349,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.7884, -81.5540,     -inf,     -inf,
            -inf, -75.3515,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 397: Reward=-273.69, route=[0, 6, 1, 7, 9, 2, 5, 8, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.3857, -77.7585, -78.1496, -81.7461, -75.7852, -66.5141,
        -76.6589, -79.0564, -79.4231], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.4109, -77.1107, -77.8795, -80.9473, -73.3808,     -inf,
        -75.0705, -76.8127, -79.4228], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.7729, -79.4414, -83.5951, -78.7755,     -inf,
        -78.5054, -81.4622, -80.4130], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.2920, -79.3401, -82.6391, -74.5604,     -inf,
            -inf, -77.0313, -80.4615], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.2338, -77.9526,     -inf,     -inf,     -inf,
            -inf, -82.6524, -79.4038], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.3734,     -inf,     -inf,     -inf,
            -inf, -78.1997, -79.1066], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -84.3109, -80.5189], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -85.6139,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 398: Reward=-262.88, route=[0, 6, 1, 7, 5, 4, 2, 3, 9, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.3857, -77.7585, -78.1496, -81.7461, -75.7852, -66.5141,
        -76.6589, -79.0564, -79.4231], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.4109, -77.1107, -77.8795, -80.9473, -73.3808,     -inf,
        -75.0705, -76.8127, -79.4228], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.3846, -80.5018, -74.1818,     -inf,
        -76.3557, -78.2997,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.9832, -80.6076,     -inf,     -inf,
        -73.6839, -74.9777,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.0605,     -inf,     -inf,     -inf,
            -inf, -82.7707,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -84.3890,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 399: Reward=-288.11, route=[0, 6, 1, 9, 2, 5, 7, 4, 3, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.6610,     -inf,     -inf, -78.2857, -67.8733,
        -79.7005, -81.9644, -78.6635], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.7387,     -inf,     -inf, -73.1170,     -inf,
        -75.1818, -76.1706, -78.9521], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.3913,     -inf,     -inf,     -inf,     -inf,
        -81.7774, -84.9219,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -76.4787, -77.7005,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -76.5051,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 400: Reward=-268.54, route=[0, 1, 3, 4, 6, 5, 9, 2, 7, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -75.2493, -78.2688,     -inf, -82.9281, -80.9649, -69.8696,
        -80.6937, -83.5210, -79.6241], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.7295, -75.6996,     -inf, -79.8958, -73.0943,     -inf,
        -75.1584, -76.1572, -78.8972], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.2922,     -inf, -82.4631, -78.5113,     -inf,
        -78.6047, -80.8100, -79.8123], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.3912, -73.8374,     -inf,
        -76.3738, -77.5876, -78.5115], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.5414,     -inf,     -inf,
        -73.6742, -74.2285, -79.0419], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.6632,     -inf,     -inf,
            -inf, -76.4362, -80.0204], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 401: Reward=-283.08, route=[0, 3, 6, 1, 2, 5, 7, 8, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.6761, -76.3167, -77.0710, -80.6585, -75.5261, -66.1560,
        -76.7320, -78.3849, -78.8475], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.3155, -78.3346,     -inf, -82.9775, -80.9987,     -inf,
        -80.7692, -83.5722, -79.7140], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1407,     -inf, -81.4209, -78.4172,     -inf,
        -78.2717, -80.4863, -79.2499], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.6481, -74.1633,     -inf,
            -inf, -76.0284, -79.4784], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.6140,     -inf,     -inf,
            -inf, -73.8092, -78.5907], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.3444], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 402: Reward=-285.19, route=[0, 6, 3, 1, 2, 7, 5, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.1044, -75.1938, -75.9429, -79.6533, -75.4185, -65.5731,
        -76.4038, -78.0564, -78.3203], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1767, -74.6036, -75.7548, -78.9325, -72.9855,     -inf,
        -74.8085, -75.7923, -78.3990], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.5839, -75.6792,     -inf, -78.2274,     -inf,
            -inf, -81.6387, -78.1882], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.1966,     -inf, -73.7166,     -inf,
            -inf, -77.1769, -78.0087], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -83.2985, -79.2739], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -84.5906,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 403: Reward=-279.29, route=[0, 6, 1, 7, 4, 2, 5, 3, 9, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True False False False False]
greedy_action q_values = tensor([    -inf, -70.3684, -74.3133,     -inf, -78.4625,     -inf, -62.7707,
        -73.2097, -73.7540, -78.3863], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.2233, -74.6268,     -inf, -78.9610,     -inf,     -inf,
        -74.8512, -75.8585, -78.4510], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1660,     -inf, -81.4544,     -inf,     -inf,
        -78.2938, -80.5297, -79.2923], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.0113,     -inf,     -inf,
        -72.7095,     -inf, -79.2383], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.9487,     -inf,     -inf,
            -inf,     -inf, -79.3498], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.8607,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 404: Reward=-282.15, route=[0, 3, 5, 6, 1, 2, 8, 7, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -72.5511, -73.6777, -74.9448,     -inf, -78.1198, -66.5206,
        -78.8455, -81.1441, -77.7450], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -70.6842, -73.8480, -75.2344,     -inf, -72.8468,     -inf,
        -74.2746, -75.2373, -78.1833], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.3463, -76.5645,     -inf, -78.3225,     -inf,
        -77.7063, -79.9187, -78.9615], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.6593,     -inf, -73.6199,     -inf,
        -75.5178, -76.7116, -77.7671], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.3693,     -inf,     -inf,     -inf,
        -72.7774, -73.2742, -78.3808], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -82.8064, -78.9552], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -84.0963,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 405: Reward=-283.2, route=[0, 4, 6, 1, 2, 5, 7, 3, 9, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.5959, -74.4099, -75.4020, -78.8184, -75.2908, -64.8091,
        -75.8719, -77.5215, -78.0688], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.1526, -76.3328,     -inf, -80.9825, -80.8380,     -inf,
        -79.9284, -82.7715, -78.8004], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.3363,     -inf, -80.5529, -78.3032,     -inf,
        -77.7306, -79.9516, -78.9701], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.5911, -73.6006,     -inf,
        -75.5421, -76.7445, -77.7757], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.8259,     -inf,     -inf,
        -72.8017, -73.3070, -78.3894], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.8723,     -inf,     -inf,
            -inf, -75.5026, -79.2974], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.1472,     -inf,     -inf,
            -inf,     -inf, -79.2280], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -77.9192], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 406: Reward=-271.07, route=[0, 6, 3, 1, 2, 5, 7, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.2336, -73.5638, -75.0889, -77.8739, -75.0776, -64.2226,
        -75.2087, -76.9858, -77.9821], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.3513, -73.0186, -74.9647, -77.2283, -72.6167,     -inf,
        -73.6228, -74.7034, -78.1326], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.4693, -76.2376, -79.5766, -78.1165,     -inf,
        -77.0330, -79.3936, -78.8476], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.3787, -76.6749, -73.4043,     -inf,
        -74.8776, -76.1984, -77.7005], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.1219, -76.9556,     -inf,     -inf,
        -72.1248, -72.7260, -78.3570], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.1756, -78.1537,     -inf,     -inf,
            -inf,     -inf, -79.2199], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.1123,     -inf,     -inf,
            -inf,     -inf, -78.8481], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.7575,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 407: Reward=-250.3, route=[0, 6, 1, 2, 5, 7, 8, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -70.1976, -74.2678, -75.9420, -77.9719, -71.1446, -61.9771,
        -71.8734,     -inf, -78.9725], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -70.4166, -73.0959, -75.0317, -77.3040, -72.6558,     -inf,
        -73.6534,     -inf, -78.1849], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.5465, -76.3046, -79.6523, -78.1557,     -inf,
        -77.0637,     -inf, -78.8999], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.4457, -76.7506, -73.4435,     -inf,
        -74.9083,     -inf, -77.7529], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.0301,     -inf,     -inf,
            -inf,     -inf, -79.2943], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -77.9192], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 408: Reward=-323.54, route=[0, 8, 6, 1, 2, 5, 3, 7, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.2903, -72.8426, -75.3521, -77.0912, -74.9353, -63.7726,
        -74.6713, -76.3542, -78.0815], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4252, -72.3192, -75.2521, -76.4830, -72.4614,     -inf,
        -73.0899, -74.0644, -78.2649], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.7273, -76.4874, -78.7600, -77.9857,     -inf,
        -76.4842, -78.7592, -78.9249], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.6554, -75.9117, -73.2636,     -inf,
        -74.3575, -75.5799, -77.8172], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.4269, -76.2390,     -inf,     -inf,
        -71.5895, -72.0741, -78.5141], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.7376, -78.2077,     -inf,     -inf,
            -inf, -74.2484, -79.3650], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.8525, -80.8627,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.2682,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 409: Reward=-238.36, route=[0, 6, 1, 2, 5, 7, 8, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -70.2829, -73.5834, -76.2505, -77.2564, -70.9681, -61.5278,
        -71.3261,     -inf, -79.1337], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False  True False]
greedy_action q_values = tensor([    -inf, -72.3654, -72.2036, -74.9439,     -inf, -77.9223,     -inf,
        -77.8385,     -inf, -77.8218], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False  True False]
greedy_action q_values = tensor([    -inf, -70.5315,     -inf, -74.6509,     -inf, -73.2879,     -inf,
        -74.3569,     -inf, -77.8160], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.5942,     -inf, -78.0566,     -inf,
        -76.5315,     -inf, -79.0251], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.7639,     -inf, -73.6679,     -inf,
            -inf,     -inf, -79.3747], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.4988,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.5764], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 410: Reward=-261.88, route=[0, 8, 6, 4, 2, 1, 7, 5, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.2903, -72.8426, -75.3521, -77.0912, -74.9353, -63.7726,
        -74.6713, -76.3542, -78.0815], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4252, -72.3192, -75.2521, -76.4830, -72.4614,     -inf,
        -73.0899, -74.0644, -78.2649], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.8976, -74.9472,     -inf, -77.9145,     -inf,
        -77.3674, -79.6948, -78.1849], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.6975,     -inf, -73.2507,     -inf,
        -73.8683, -75.0511, -78.2239], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.5027,     -inf,     -inf,     -inf,
        -71.0849, -71.5102, -78.9583], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.7889,     -inf,     -inf,     -inf,
            -inf, -73.6767, -79.7902], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 411: Reward=-237.18, route=[0, 6, 1, 4, 2, 5, 7, 8, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.7033, -72.6052, -75.3916, -76.5885, -74.9207, -63.8895,
        -74.1719, -75.8268, -78.4762], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8510, -72.0973, -75.3207, -76.0142, -72.4322,     -inf,
        -72.5942, -73.5272, -78.6888], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.4801, -76.5062, -78.2293, -77.9851,     -inf,
        -75.9746, -78.2324, -79.3039], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.4962, -80.6140,     -inf,
        -78.3940, -81.2951, -79.1299], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.6957, -73.5734,     -inf,
            -inf, -73.6696, -79.7571], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.1605,     -inf,     -inf,
            -inf, -82.5376,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 412: Reward=-325.74, route=[0, 6, 1, 2, 3, 7, 5, 9, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.7033, -72.6052, -75.3916, -76.5885, -74.9207, -63.8895,
        -74.1719, -75.8268, -78.4762], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.1568, -71.9388, -75.4062, -75.7161,     -inf,     -inf,
        -71.0443, -71.4657, -78.8589], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7262, -75.4791,     -inf,     -inf,     -inf,
        -76.8535, -79.7148, -78.9479], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.2564,     -inf,     -inf,     -inf,
        -73.2801, -74.9967, -79.0230], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.2553,     -inf,     -inf,     -inf,
            -inf, -82.4773,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 413: Reward=-264.75, route=[0, 6, 5, 1, 4, 2, 7, 9, 3, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.0186, -72.4401, -75.9130, -76.3226, -74.6599, -64.1008,
        -73.5478, -75.7276, -79.2254], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1807, -71.9475, -75.8654, -75.7777, -72.1615,     -inf,
        -71.9742, -73.4115, -79.4613], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.3039, -77.0209, -77.9246, -77.7248,     -inf,
        -75.3641, -78.1572, -80.0461], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.7285, -70.7010,     -inf,
        -70.3218,     -inf, -80.5820], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -75.6661,     -inf,     -inf,
            -inf,     -inf, -79.8221], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -79.0681], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 414: Reward=-294.1, route=[0, 6, 1, 2, 3, 8, 7, 5, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.0186, -72.4401, -75.9130, -76.3226, -74.6599, -64.1008,
        -73.5478, -75.7276, -79.2254], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -71.1329, -73.3101, -76.9901, -76.6609, -70.6686,     -inf,
        -70.2578,     -inf, -80.4800], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.1363, -74.1300, -77.2836, -77.4641, -73.3028,     -inf,
            -inf,     -inf, -80.4846], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.3855, -77.1077, -78.0184, -77.7277,     -inf,
            -inf,     -inf, -80.1119], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.3311, -75.2624, -72.9932,     -inf,
            -inf,     -inf, -79.0496], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 415: Reward=-239.26, route=[0, 6, 8, 7, 1, 2, 5, 4, 9, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.3875, -72.6587, -76.9193, -76.5444, -73.9489, -64.3640,
        -73.0084, -75.8310, -80.6558], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.5628, -72.1758, -76.8893, -76.0228, -71.4458,     -inf,
        -71.4380, -73.4959, -80.9056], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -72.4538, -74.2898, -78.2513, -77.6428, -72.5337,     -inf,
            -inf, -73.5349, -81.8932], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.5205, -78.0555, -78.1037, -76.9561,     -inf,
            -inf, -78.2479, -81.4964], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.2760, -75.4173, -72.2541,     -inf,
            -inf, -75.0147, -80.4285], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.9072,     -inf,     -inf,
            -inf, -82.6992,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -79.9645,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 416: Reward=-283.74, route=[0, 6, 7, 1, 2, 5, 3, 9, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.3875, -72.6587, -76.9193, -76.5444, -73.9489, -64.3640,
        -73.0084, -75.8310, -80.6558], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.5628, -72.1758, -76.8893, -76.0228, -71.4458,     -inf,
        -71.4380, -73.4959, -80.9056], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -72.4538, -74.2898, -78.2513, -77.6428, -72.5337,     -inf,
            -inf, -73.5349, -81.8932], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.5205, -78.0555, -78.1037, -76.9561,     -inf,
            -inf, -78.2479, -81.4964], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.2760, -75.4173, -72.2541,     -inf,
            -inf, -75.0147, -80.4285], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 417: Reward=-245.71, route=[0, 6, 7, 1, 2, 5, 8, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.3618, -72.6581, -77.8821, -76.6268, -72.9966, -64.3987,
        -72.6322, -75.4998, -81.7923], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -75.9221, -76.3252, -80.0979, -79.8262, -80.5931,     -inf,
            -inf, -82.2898,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.5477, -79.0601, -78.1946, -76.0605,     -inf,
            -inf, -78.0030,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.2805, -75.5839, -71.3998,     -inf,
            -inf, -74.7394,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.3655,     -inf,     -inf,
            -inf, -81.2108,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -79.6837,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 418: Reward=-286.92, route=[0, 6, 7, 9, 1, 2, 5, 3, 4, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -70.8600, -71.9936, -77.8909, -75.8877,     -inf, -61.4956,
        -69.3464, -70.9595, -82.1556], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.5287, -74.3396, -79.2631, -77.8492,     -inf,     -inf,
            -inf, -73.1691, -83.1088], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.2395, -79.9414,     -inf,     -inf,
            -inf, -82.3802,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -81.1956,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 419: Reward=-288.53, route=[0, 5, 6, 7, 1, 2, 9, 4, 3, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -72.5524, -74.5824, -80.1221, -78.6308, -71.0374, -63.6886,
            -inf, -72.8298, -84.0482], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.7192, -72.5311, -78.8513, -77.0564, -69.9779,     -inf,
            -inf, -72.8217, -83.1560], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.3487, -72.1841, -78.3243,     -inf,     -inf,     -inf,
            -inf, -79.3937, -82.4720], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.7405,     -inf, -78.1534,     -inf,     -inf,     -inf,
            -inf, -74.4860, -82.6190], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.0413,     -inf,     -inf,     -inf,
            -inf, -77.8039, -83.7774], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.9503,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.0960], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.5339], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 420: Reward=-269.48, route=[0, 7, 6, 5, 4, 2, 1, 8, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -70.9677, -72.3019, -78.7839, -76.7581,     -inf, -61.5548,
        -69.0535, -70.8294, -83.1301], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.7787, -72.5479, -78.8593, -77.0681,     -inf,     -inf,
        -70.6781, -72.9252, -83.1852], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -71.8102,     -inf, -78.2088, -76.3804,     -inf,     -inf,
            -inf, -74.5740,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 421: Reward=-302.75, route=[0, 5, 6, 7, 9, 2, 1, 3, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.4584, -72.9705, -78.8343, -77.4239, -72.4931, -64.4865,
        -72.3589, -75.3098, -82.8440], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.7351, -72.5244, -78.8302, -77.0347, -70.0134,     -inf,
        -70.6621, -72.8875, -83.1413], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.0388, -72.3693, -78.8580, -76.8085,     -inf,     -inf,
        -69.1362, -70.8976, -83.2186], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.0898, -75.7161, -80.9220, -79.9379,     -inf,     -inf,
            -inf, -72.8689, -85.5694], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.0708, -74.9193, -80.5052, -79.2983,     -inf,     -inf,
            -inf,     -inf, -85.3245], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.9728, -80.7217, -80.2627,     -inf,     -inf,
            -inf,     -inf, -85.1334], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.9652, -77.6337,     -inf,     -inf,
            -inf,     -inf, -84.0770], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.8617], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 422: Reward=-210.37, route=[0, 6, 5, 7, 8, 1, 2, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.8598, -73.9887, -79.4854, -78.6016, -72.4065, -65.0548,
        -72.4934, -75.2913, -84.1790], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.1506, -73.5420, -79.5045, -78.2268, -69.9128,     -inf,
        -70.7887, -72.8506, -84.4946], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.4612, -73.3786, -79.4910, -78.0585,     -inf,     -inf,
        -69.2246, -70.8923, -84.5142], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.8980, -80.6328,     -inf,     -inf,     -inf,
            -inf, -77.7668, -85.0704], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.8617], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 423: Reward=-280.78, route=[0, 6, 5, 7, 4, 1, 2, 8, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.8598, -73.9887, -79.4854, -78.6016, -72.4065, -65.0548,
        -72.4934, -75.2913, -84.1790], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.1506, -73.5420, -79.5045, -78.2268, -69.9128,     -inf,
        -70.7887, -72.8506, -84.4946], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.4612, -73.3786, -79.4910, -78.0585,     -inf,     -inf,
        -69.2246, -70.8923, -84.5142], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.4392,     -inf, -81.1419,     -inf,     -inf,
            -inf, -80.5926, -85.6988], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.4681,     -inf,     -inf,
            -inf, -74.1219, -84.9979], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.3323,     -inf,     -inf,
            -inf,     -inf, -86.3731], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 424: Reward=-270.41, route=[0, 6, 5, 7, 1, 3, 2, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.1079, -74.6378, -79.8253, -79.5222, -72.0141, -65.4025,
        -72.6562, -74.8785, -85.1453], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.4152, -74.1947, -79.8724, -79.1658, -69.5103,     -inf,
        -70.9437, -72.4244, -85.4849], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.4828,     -inf, -79.2607, -78.5198,     -inf,     -inf,
            -inf,     -inf, -84.9971], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.1797, -82.9228,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 425: Reward=-205.43, route=[0, 6, 5, 7, 8, 2, 1, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -73.2344, -76.2851, -81.1696, -80.8003, -70.5170, -64.5831,
            -inf, -72.3307, -86.4158], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -72.4004, -74.2025, -79.8953, -79.1893, -69.4742,     -inf,
            -inf, -72.3574, -85.5013], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.6789, -74.0260, -79.8506, -79.0259,     -inf,     -inf,
            -inf, -70.4728, -85.4635], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.4828,     -inf, -79.2607, -78.5198,     -inf,     -inf,
            -inf,     -inf, -84.9971], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.9842,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.1633], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 426: Reward=-238.6, route=[0, 7, 6, 5, 8, 2, 1, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.6555, -75.6885, -80.3809, -80.8103, -71.9102, -65.8166,
        -73.0825, -74.8299, -86.4314], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.9755, -75.2435, -80.4519, -80.4685, -69.3923,     -inf,
        -71.3585, -72.3569, -86.7904], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.2470, -75.0647, -80.4129, -80.3214,     -inf,     -inf,
        -69.8408, -70.4805, -86.7475], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.9249, -77.4582, -81.8803, -82.2285,     -inf,     -inf,
            -inf, -72.3383, -87.8982], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.2195,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 427: Reward=-248.82, route=[0, 6, 5, 7, 8, 3, 2, 1, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.6555, -75.6885, -80.3809, -80.8103, -71.9102, -65.8166,
        -73.0825, -74.8299, -86.4314], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.9755, -75.2435, -80.4519, -80.4685, -69.3923,     -inf,
        -71.3585, -72.3569, -86.7904], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.2470, -75.0647, -80.4129, -80.3214,     -inf,     -inf,
        -69.8408, -70.4805, -86.7475], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -74.5101, -74.8880, -79.7949,     -inf,     -inf,     -inf,
            -inf, -79.0510, -85.9934], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.6346, -81.5059,     -inf,     -inf,     -inf,
            -inf, -77.3213, -87.3276], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.8716,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.3394], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -87.0787], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 428: Reward=-269.17, route=[0, 6, 5, 7, 4, 1, 8, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.1166, -76.5383, -80.8974, -81.8679, -72.0763, -66.3024,
        -73.3983, -75.2612, -87.2849], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.4514, -76.0937, -80.9933, -81.5433, -69.5405,     -inf,
        -71.6614, -72.7619, -87.6682], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -70.0113,     -inf, -88.6215], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -88.9549], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 429: Reward=-257.37, route=[0, 6, 5, 2, 3, 1, 4, 8, 7, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -77.5578,     -inf,     -inf, -85.0358, -79.8281, -72.0583,
        -78.6971, -82.3213,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True False False  True]
greedy_action q_values = tensor([    -inf, -73.5429,     -inf,     -inf, -81.6145, -69.6136,     -inf,
        -71.7676, -72.8822,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -72.8418,     -inf,     -inf, -81.4992,     -inf,     -inf,
        -70.2160, -70.9397,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -74.4987,     -inf,     -inf, -83.3974,     -inf,     -inf,
            -inf, -72.8544,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -73.4668,     -inf,     -inf, -82.7983,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -83.6329,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 430: Reward=-241.44, route=[0, 2, 3, 9, 6, 5, 7, 8, 1, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.1166, -76.5383, -80.8974, -81.8679, -72.0763, -66.3024,
        -73.3983, -75.2612, -87.2849], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.7198,     -inf, -80.5585, -81.4383, -70.7542,     -inf,
        -73.1221, -75.1002, -87.4657], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -77.9632,     -inf, -83.3008, -85.8521,     -inf,     -inf,
        -78.7937, -83.0688,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.3981, -84.2550,     -inf,     -inf,
        -75.4336, -78.5879,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.6035,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 431: Reward=-304.3, route=[0, 6, 2, 5, 9, 1, 7, 4, 8, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True False False False False]
greedy_action q_values = tensor([    -inf, -73.0411, -76.5859, -81.3134,     -inf,     -inf, -63.3605,
        -69.9304, -71.1891, -88.1280], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.8097, -76.8326, -81.3483,     -inf,     -inf,     -inf,
        -71.6496, -73.3526, -88.1644], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -74.7234, -79.0568, -82.7533,     -inf,     -inf,     -inf,
            -inf, -73.2798, -89.2429], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.7531, -78.2731, -82.4635,     -inf,     -inf,     -inf,
            -inf,     -inf, -89.1172], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.3077, -82.3869,     -inf,     -inf,     -inf,
            -inf,     -inf, -88.6518], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.7327,     -inf,     -inf,     -inf,
            -inf,     -inf, -87.6449], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -88.2890], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 432: Reward=-254.61, route=[0, 4, 5, 6, 7, 8, 1, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.4203, -77.2485, -81.2122, -82.5846, -72.3982, -66.4593,
        -73.3908, -75.8580, -87.7112], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.7742, -76.8064, -81.3355, -82.2819, -69.8438,     -inf,
        -71.6453, -73.3315, -88.1243], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.7832, -78.2670, -82.4664, -83.5129,     -inf,     -inf,
        -69.8671,     -inf, -89.1180], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.1242, -79.7363, -83.0121, -84.7608,     -inf,     -inf,
            -inf,     -inf, -89.6118], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1217, -80.8087,     -inf,     -inf,     -inf,
            -inf,     -inf, -87.5605], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.8817,     -inf,     -inf,     -inf,
            -inf,     -inf, -87.9225], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -88.5004], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 433: Reward=-202.19, route=[0, 6, 5, 8, 7, 1, 4, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -74.9252, -79.5456, -82.8043, -84.5698, -71.2315, -65.9971,
            -inf, -74.2508, -89.3804], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -74.0793, -77.3990, -81.5243, -82.8893, -70.1994,     -inf,
            -inf, -74.3149, -88.4378], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.5222, -77.2901, -81.7241, -82.8505,     -inf,     -inf,
            -inf, -72.0815, -88.7078], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -78.2565, -81.7960, -83.4209, -86.4423,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.2009,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 434: Reward=-225.86, route=[0, 7, 6, 5, 8, 9, 1, 3, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.7182, -77.8279, -81.3436, -83.1408, -72.8100, -66.8595,
        -73.7518, -76.9422, -87.9722], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.1356, -78.8800, -82.7446, -84.1445, -68.7908,     -inf,
            -inf,     -inf, -89.5474], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.5876, -77.3696, -81.7953, -82.9311,     -inf,     -inf,
            -inf,     -inf, -88.7657], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.9012, -82.5203, -84.8341,     -inf,     -inf,
            -inf,     -inf, -88.9046], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.1311, -82.8528,     -inf,     -inf,
            -inf,     -inf, -88.4108], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -87.1685,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 435: Reward=-237.1, route=[0, 6, 7, 8, 5, 1, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -75.3200, -80.1648, -83.0474, -85.2734, -71.4263, -66.1353,
            -inf, -75.5059, -89.8800], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.4093, -82.6065, -85.3796, -76.1348,     -inf,
            -inf, -80.8347, -89.2464], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.2951, -85.0480,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.4923,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 436: Reward=-327.41, route=[0, 7, 6, 1, 5, 9, 2, 8, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -73.9027, -77.8223, -81.9198, -83.4697,     -inf, -63.7507,
        -70.4759, -73.2149, -89.1659], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.5294, -78.0221, -81.7735, -83.5888,     -inf,     -inf,
        -72.3613, -75.6776, -88.9609], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -75.4537, -80.2775, -83.1838, -85.3864,     -inf,     -inf,
            -inf, -75.6049, -90.0524], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.5894, -83.2056, -84.9666,     -inf,     -inf,
            -inf,     -inf, -90.3145], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.4620,     -inf,     -inf,
            -inf,     -inf, -88.9326], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -88.3713], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 437: Reward=-271.32, route=[0, 5, 6, 7, 1, 8, 2, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.6212, -78.9161, -81.7081, -84.3635, -73.1324, -67.0274,
        -74.5992, -79.5714, -88.7975], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.0310, -78.4890, -81.9285, -84.1349, -70.5244,     -inf,
        -72.8139, -76.9444, -89.3075], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.5526, -78.4092, -82.2388, -84.1522,     -inf,     -inf,
        -71.0180, -74.5494, -89.7124], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.0113, -80.7873, -83.3760, -85.9898,     -inf,     -inf,
            -inf, -76.9132, -90.4560], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.1119, -81.0301,     -inf,     -inf,     -inf,
            -inf, -84.1319, -88.2544], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -89.2361], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 438: Reward=-243.38, route=[0, 6, 5, 7, 1, 4, 2, 8, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -75.1624, -79.9621, -83.2493, -85.4206, -68.8095, -64.2598,
        -70.6446,     -inf, -90.5639], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -75.1003, -78.5710, -82.0041, -84.2182, -70.5554,     -inf,
        -72.8393,     -inf, -89.3716], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.6218, -78.4912, -82.3144, -84.2356,     -inf,     -inf,
        -71.0434,     -inf, -89.7765], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -76.0805, -80.8693, -83.4516, -86.0731,     -inf,     -inf,
            -inf,     -inf, -90.5200], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -81.0155, -82.8507, -86.0566,     -inf,     -inf,
            -inf,     -inf, -89.7061], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.3062, -83.4185,     -inf,     -inf,
            -inf,     -inf, -88.7913], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.9871,     -inf,     -inf,
            -inf,     -inf, -89.2454], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 439: Reward=-261.72, route=[0, 8, 6, 5, 7, 1, 2, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.6212, -78.9161, -81.7081, -84.3635, -73.1324, -67.0274,
        -74.5992, -79.5714, -88.7975], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.4453, -78.3875, -82.1802, -84.6724, -70.4308,     -inf,
        -73.1171, -77.9458, -89.4487], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.7146, -79.9953,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -90.9337], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.8813,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -89.7791], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 440: Reward=-332.48, route=[0, 6, 5, 4, 7, 3, 8, 1, 2, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.6843, -82.8020, -86.3310, -76.1895, -69.1861,
        -76.8135, -83.2899, -89.5229], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.4192, -82.2437, -84.7120, -70.4475,     -inf,
        -73.1409, -77.9678, -89.5082], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.3537, -82.5826, -84.7534,     -inf,     -inf,
        -71.3337, -75.5458, -89.9443], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.8749, -88.1157,     -inf,     -inf,
            -inf, -88.1866,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -86.4096,     -inf,     -inf,
            -inf, -86.9425,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -85.3483,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 441: Reward=-271.15, route=[0, 1, 6, 5, 7, 2, 9, 3, 4, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.2578,     -inf, -81.2320, -83.6635, -71.3585, -65.5117,
        -74.5811, -79.7573, -88.5897], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.4797,     -inf, -82.2366, -84.7244, -70.4536,     -inf,
        -73.1336, -77.9778, -89.5023], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.0763,     -inf, -82.3832, -84.6983,     -inf,     -inf,
        -71.3263, -75.8716, -89.2507], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.5041,     -inf, -83.4579, -86.5057,     -inf,     -inf,
            -inf, -78.2734, -89.9178], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.9469,     -inf,     -inf,     -inf,
            -inf, -85.6600, -87.5321], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -87.2566, -88.3372], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 442: Reward=-268.41, route=[0, 2, 6, 5, 7, 1, 4, 3, 8, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False  True False  True]
greedy_action q_values = tensor([    -inf, -76.3711, -80.0995, -83.2652,     -inf, -71.0124, -65.4339,
            -inf, -78.1911,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf, -75.7872, -79.5254, -83.4924,     -inf, -68.2904,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -75.1458, -77.9578, -82.4428,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.1934,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 443: Reward=-254.97, route=[0, 4, 9, 7, 6, 8, 5, 1, 3, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.0204, -78.2756, -81.6526, -84.7381, -72.6007, -66.2942,
        -74.9264, -80.9570, -88.1207], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.4796, -77.8857, -81.9522, -84.5734, -69.9696,     -inf,
        -73.1247, -78.2807, -88.7199], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.0420, -77.8388, -82.3268, -84.6464,     -inf,     -inf,
        -71.3100, -75.8396, -89.1974], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.7934, -79.5294, -83.5198, -86.0899,     -inf,     -inf,
            -inf,     -inf, -90.2580], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.7090,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 444: Reward=-261.97, route=[0, 6, 5, 7, 8, 1, 4, 9, 2, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.7528, -77.4480, -81.0222, -84.5591, -72.2997, -65.8991,
        -74.8475, -81.1027, -87.1401], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.2454, -77.0859, -81.3740, -84.4346, -69.6577,     -inf,
        -73.0421, -78.4105, -87.7951], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.8354, -77.0634, -81.7915, -84.5425,     -inf,     -inf,
        -71.2219, -75.9539, -88.3182], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.4214, -81.9923, -86.1192,     -inf,     -inf,
            -inf, -83.8580, -87.8672], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.6262, -83.5723,     -inf,     -inf,
            -inf, -80.3255, -87.1595], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -86.0184,     -inf,     -inf,
            -inf,     -inf, -87.3215], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.5527], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 445: Reward=-273.51, route=[0, 6, 5, 7, 1, 2, 8, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.7528, -77.4480, -81.0222, -84.5591, -72.2997, -65.8991,
        -74.8475, -81.1027, -87.1401], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.2454, -77.0859, -81.3740, -84.4346, -69.6577,     -inf,
        -73.0421, -78.4105, -87.7951], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.8354, -77.0634, -81.7915, -84.5425,     -inf,     -inf,
        -71.2219, -75.9539, -88.3182], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.5901, -78.7553, -82.9863, -85.9972,     -inf,     -inf,
            -inf,     -inf, -89.3780], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.5031, -82.0692, -86.2043,     -inf,     -inf,
            -inf,     -inf, -87.9317], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.7030, -83.6574,     -inf,     -inf,
            -inf,     -inf, -87.2240], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -87.3616,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 446: Reward=-232.54, route=[0, 6, 5, 7, 8, 1, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.6267, -76.7360, -80.3798, -84.2776, -72.2450, -65.7911,
        -74.5206, -81.3867, -86.1463], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -75.4841, -78.0504, -82.3723, -85.7257, -67.8516,     -inf,
        -70.5634,     -inf, -88.4092], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.8381, -76.4805, -81.3229, -84.4223,     -inf,     -inf,
        -70.9123,     -inf, -87.4934], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -76.2086, -78.7834, -82.2944, -86.1714,     -inf,     -inf,
            -inf,     -inf, -88.0436], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 447: Reward=-250.58, route=[0, 6, 8, 5, 7, 1, 2, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.6267, -76.7360, -80.3798, -84.2776, -72.2450, -65.7911,
        -74.5206, -81.3867, -86.1463], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.1510, -76.3991, -80.7847, -84.1936, -69.5894,     -inf,
        -72.7127, -78.6771, -86.8587], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.7677, -76.3991, -81.2460, -84.3370,     -inf,     -inf,
        -70.8885, -76.2044, -87.4292], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.1382, -78.7020, -82.2174, -86.0861,     -inf,     -inf,
            -inf, -78.6185, -87.9793], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.6881, -81.3037, -85.8109,     -inf,     -inf,
            -inf, -84.1584, -86.8200], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.0186, -83.3107,     -inf,     -inf,
            -inf, -80.6157, -86.2036], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.5803,     -inf,     -inf,
            -inf, -87.7881, -86.1506], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -86.1799, -85.4361], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -89.1129,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 448: Reward=-269.14, route=[0, 6, 5, 7, 1, 2, 3, 4, 9, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.4004, -76.3162, -79.5588, -83.7566, -72.4983, -65.6023,
        -74.0518, -81.4721, -84.8067], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.9598, -76.0024, -80.0182, -83.7182, -69.8232,     -inf,
        -72.2420, -78.7470, -85.5827], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.3453, -80.5014, -85.3298,     -inf,     -inf,
        -76.1515,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.4431, -81.6036, -85.7584,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.3376, -82.9227,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 449: Reward=-242.7, route=[0, 6, 5, 8, 9, 1, 7, 2, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.4004, -76.3162, -79.5588, -83.7566, -72.4983, -65.6023,
        -74.0518, -81.4721, -84.8067], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -75.9456, -78.3021, -81.4268, -85.5914, -70.8990,     -inf,
            -inf, -78.7067,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -77.3591, -77.9749,     -inf, -84.9079,     -inf,     -inf,
            -inf, -87.9307,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.7605,     -inf, -85.4144,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.9044,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 450: Reward=-280.77, route=[0, 6, 9, 7, 5, 3, 1, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -75.7963, -78.1860, -81.2884, -85.4831, -70.7905, -64.6714,
            -inf, -78.5656, -86.5013], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -74.6002, -75.6679, -79.5452, -83.1522, -70.0176,     -inf,
            -inf, -78.6144, -84.1236], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -74.2781, -75.7089, -80.0926, -83.3773,     -inf,     -inf,
            -inf, -76.1105, -84.8013], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.8662, -79.8297, -84.5638,     -inf,     -inf,
            -inf, -84.2206, -83.7921], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.3711, -84.9079,     -inf,     -inf,
            -inf,     -inf, -85.9275], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.3190,     -inf,     -inf,
            -inf,     -inf, -83.0542], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.9751,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 451: Reward=-277.7, route=[0, 7, 6, 5, 1, 2, 8, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.0083, -75.9448, -79.0003, -83.1057, -72.7523, -65.1183,
        -73.8613, -81.4273, -83.2519], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.6068, -75.6540, -79.5106, -83.1172, -70.0572,     -inf,
        -72.0458, -78.6871, -84.0950], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.2846, -75.6950, -80.0580, -83.3424,     -inf,     -inf,
        -70.2098, -76.1832, -84.7727], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.8508, -77.5433,     -inf, -84.1426,     -inf,     -inf,
            -inf, -87.8453, -82.8814], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.8508,     -inf, -84.5444,     -inf,     -inf,
            -inf, -84.2371, -83.7857], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.1711,     -inf,     -inf,
            -inf, -80.6932, -83.3913], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -85.9751,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 452: Reward=-273.44, route=[0, 6, 5, 7, 3, 1, 2, 8, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.0083, -75.9448, -79.0003, -83.1057, -72.7523, -65.1183,
        -73.8613, -81.4273, -83.2519], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.6068, -75.6540, -79.5106, -83.1172, -70.0572,     -inf,
        -72.0458, -78.6871, -84.0950], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.2846, -75.6950, -80.0580, -83.3424,     -inf,     -inf,
        -70.2098, -76.1832, -84.7727], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -75.5856, -77.9604, -80.9215, -85.0082,     -inf,     -inf,
            -inf, -78.5996, -85.1767], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 453: Reward=-286.27, route=[0, 6, 5, 7, 1, 8, 3, 2, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.4333, -75.3549, -78.8723, -82.5167, -72.7285, -64.8963,
        -73.9283, -81.1944, -81.8211], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -77.3574, -78.8934, -79.9436, -85.0409, -80.9940,     -inf,
        -79.5044, -88.9980,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.5618, -81.5681, -71.1581,     -inf,
        -73.8654, -80.5598,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.1536, -82.9558,     -inf,     -inf,
        -70.3646, -76.0464,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.3273,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 454: Reward=-312.48, route=[0, 6, 9, 1, 2, 5, 7, 4, 8, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.4333, -75.3549, -78.8723, -82.5167, -72.7285, -64.8963,
        -73.9283, -81.1944, -81.8211], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.0729, -75.0879, -79.4278, -82.5783, -70.0149,     -inf,
        -72.1023, -78.4398, -82.7308], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.7850, -75.1505, -80.0125, -82.8469,     -inf,     -inf,
        -70.2548, -75.9210, -83.4637], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -75.0446, -77.3943, -80.8361, -84.4702,     -inf,     -inf,
            -inf, -78.3341, -83.7941], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.2579, -79.6689, -83.9363,     -inf,     -inf,
            -inf, -83.9940, -82.2939], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.6130, -81.6277,     -inf,     -inf,
            -inf, -80.4559, -82.0113], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.6854,     -inf,     -inf,
            -inf, -87.6733, -79.8543], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -83.7473,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 455: Reward=-268.43, route=[0, 6, 5, 7, 1, 2, 3, 9, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.3651, -75.0247, -78.4783, -81.7461, -72.7378, -64.6522,
        -74.1342, -81.1397, -80.3825], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.0526, -74.7769, -79.0803, -81.8598, -70.0035,     -inf,
        -72.2952, -78.3685, -81.3579], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.9018, -79.2009, -83.0863,     -inf,     -inf,
        -76.1576, -84.0229, -80.7578], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.5760,     -inf, -82.6283,     -inf,     -inf,
            -inf, -87.6514, -79.7974], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.2975,     -inf,     -inf,
            -inf, -89.0156,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -86.1681,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 456: Reward=-308.38, route=[0, 6, 5, 1, 7, 3, 2, 9, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.3651, -75.0247, -78.4783, -81.7461, -72.7378, -64.6522,
        -74.1342, -81.1397, -80.3825], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.0526, -74.7769, -79.0803, -81.8598, -70.0035,     -inf,
        -72.2952, -78.3685, -81.3579], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.8042, -74.8570, -79.7028, -82.1732,     -inf,     -inf,
        -70.4333, -75.8323, -82.1445], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.5632, -76.5657, -80.9050, -83.6625,     -inf,     -inf,
            -inf,     -inf, -83.1802], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.6569,     -inf, -82.7136,     -inf,     -inf,
            -inf,     -inf, -79.8594], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.9488,     -inf,     -inf,
            -inf,     -inf, -80.6712], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 457: Reward=-246.97, route=[0, 6, 5, 7, 8, 1, 3, 2, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -72.6194, -76.5449, -79.9109, -82.7396, -71.0260, -63.6666,
            -inf, -77.9155, -80.6787], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.8270, -74.3746, -78.7125, -81.0238, -70.0391,     -inf,
            -inf, -78.0985, -79.8740], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.6180, -74.4716, -79.3728, -81.3823,     -inf,     -inf,
            -inf, -75.5429, -80.7159], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.4689, -78.7481, -82.1524,     -inf,     -inf,
            -inf, -83.7813, -79.1356], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.8319, -79.9868,     -inf,     -inf,
            -inf, -80.2498, -79.0798], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.6580,     -inf,     -inf,
            -inf, -87.5344, -78.1324], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -83.2457,     -inf,     -inf,
            -inf, -88.8748,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 458: Reward=-282.78, route=[0, 7, 6, 5, 1, 2, 3, 9, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.0952, -74.5886, -78.0267, -80.8195, -72.8369, -64.6562,
        -74.1022, -80.9625, -78.7992], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.6150, -76.0315,     -inf, -81.4781, -79.1457,     -inf,
        -78.9105, -87.5270, -77.9333], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.4048,     -inf, -82.0472, -76.1210,     -inf,
        -76.1221, -83.8297, -79.0414], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.4674,     -inf, -81.3591,     -inf,     -inf,
        -70.4106, -75.6556, -80.7295], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.6816,     -inf, -82.8884,     -inf,     -inf,
            -inf, -78.0672, -80.9109], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.9031,     -inf,     -inf,
            -inf,     -inf, -81.8085], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 459: Reward=-297.52, route=[0, 6, 3, 1, 5, 7, 2, 8, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.6072,     -inf, -77.1188, -79.1121, -71.3913, -63.9282,
        -73.7880, -79.5063, -77.7214], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -71.5521,     -inf, -76.3089,     -inf, -76.7661,     -inf,
        -78.0838, -85.3206, -76.3968], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.3856,     -inf, -81.5724,     -inf,
        -79.6807, -88.1795,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 460: Reward=-213.14, route=[0, 2, 6, 4, 1, 9, 3, 7, 8, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -73.5992, -77.9110, -78.1829, -82.2098, -81.4893, -71.2351,
        -79.5659, -88.0784,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -70.9695, -74.3609, -78.2573, -80.3628, -70.3737,     -inf,
        -72.2098, -77.5319,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -70.7958, -74.4696, -78.9563, -80.7646,     -inf,     -inf,
        -70.3211, -74.9616,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -71.8967, -76.6783, -79.6442, -82.2507,     -inf,     -inf,
            -inf, -77.3604,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.4560, -78.2430, -81.4391,     -inf,     -inf,
            -inf, -83.1499,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.4701,     -inf,     -inf,     -inf,
            -inf, -85.3787,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -86.9092,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 461: Reward=-275.16, route=[0, 9, 6, 5, 7, 1, 2, 4, 3, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -71.6983, -76.5316, -79.4652, -82.1010, -71.2502, -64.1809,
            -inf, -77.1760, -79.6016], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -70.9208, -74.3571, -78.2772, -80.3875, -70.2671,     -inf,
            -inf, -77.3853, -78.8142], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -73.4036, -78.0730, -77.8087, -81.5930,     -inf,     -inf,
            -inf, -87.0379,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.9483, -78.6751,     -inf,     -inf,
            -inf, -78.5792,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 462: Reward=-288.39, route=[0, 7, 6, 5, 9, 1, 2, 3, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.8619, -74.5940, -77.0645, -79.4456, -73.0319, -65.7027,
        -73.8549, -79.1879, -77.1181], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -73.3511, -78.0276, -77.7245, -81.5051, -81.5270,     -inf,
        -79.5463, -87.0719,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.7315, -79.2273, -81.6068, -71.2851,     -inf,
            -inf, -76.2233,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.5732, -78.6654, -80.2491,     -inf,     -inf,
            -inf, -73.8085,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.2837, -79.8342, -81.7170,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.1730,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 463: Reward=-247.46, route=[0, 6, 9, 1, 7, 5, 8, 2, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.8619, -74.5940, -77.0645, -79.4456, -73.0319, -65.7027,
        -73.8549, -79.1879, -77.1181], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.6738, -74.3892, -77.8085, -79.7128, -70.2230,     -inf,
        -71.9812, -76.3750, -78.2779], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.5270, -74.5094, -78.5472, -80.1585,     -inf,     -inf,
        -70.0793, -73.7922, -79.2157], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.4720, -77.7059, -80.6973,     -inf,     -inf,
            -inf, -81.9927, -77.3484], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.4295,     -inf,     -inf,     -inf,
            -inf, -82.9325, -75.7161], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -84.3924, -75.9759], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -85.6569,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 464: Reward=-229.95, route=[0, 6, 5, 7, 1, 2, 4, 3, 9, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.7468, -74.8480, -76.6531, -79.2347, -72.7844, -66.1335,
        -73.4484, -77.7952, -76.9900], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.5895, -74.6527, -77.4460, -79.5465, -69.9535,     -inf,
        -71.5666, -74.9776, -78.1994], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.4676, -74.7825, -78.2251, -80.0310,     -inf,     -inf,
        -69.6539, -72.3865, -79.1779], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.5108, -76.9912, -78.8242, -81.4442,     -inf,     -inf,
            -inf, -74.7383, -79.2022], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.7315, -77.2561, -80.4588,     -inf,     -inf,
            -inf, -80.5807, -77.1857], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.5077,     -inf,     -inf,     -inf,
            -inf,     -inf, -75.7780], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 465: Reward=-254.0, route=[0, 6, 5, 7, 1, 2, 8, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.7468, -74.8480, -76.6531, -79.2347, -72.7844, -66.1335,
        -73.4484, -77.7952, -76.9900], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.6832, -77.1741, -80.3721, -76.1537,     -inf,
        -75.4667, -80.6179, -77.0965], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.7385, -75.3442,     -inf, -76.5537,     -inf,
            -inf, -82.9392,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.4922,     -inf, -71.1599,     -inf,
            -inf, -77.1453,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.5249,     -inf,     -inf,     -inf,
            -inf, -71.4195,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 466: Reward=-258.86, route=[0, 6, 1, 7, 9, 4, 2, 5, 8, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.0551, -75.6656, -76.7309, -79.2883, -72.9699, -66.9777,
        -73.4340, -76.8334, -77.7194], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.3562,     -inf,     -inf, -79.6376, -79.5179,     -inf,
        -78.3644, -83.4823, -76.5172], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.4233, -76.3617,     -inf,
        -75.4815, -79.6918, -77.8434], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.5694, -71.0938,     -inf,
            -inf, -73.7606, -80.0227], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.2677,     -inf,     -inf,
            -inf, -71.3868, -80.1096], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 467: Reward=-254.67, route=[0, 6, 2, 3, 1, 7, 5, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.1536, -80.3550, -76.3371, -69.4928,
        -75.3745, -79.6073, -77.7166], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.4086,     -inf, -76.7410,     -inf,
            -inf, -81.9743, -76.3382], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -81.5675,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 468: Reward=-330.87, route=[0, 2, 1, 6, 7, 4, 3, 8, 9, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.7531, -76.4614, -77.3157, -79.5341, -73.1176, -67.8521,
        -73.0951, -76.0080, -78.3891], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.6453, -76.2727, -78.1878, -79.9288, -70.2333,     -inf,
        -71.1931, -73.1656, -79.6814], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5660, -76.4136, -79.0352, -80.4894,     -inf,     -inf,
        -69.2576, -70.5467, -80.7316], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.5864, -78.6549, -79.5859, -81.8618,     -inf,     -inf,
            -inf, -72.8718, -80.7153], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.9499,     -inf,     -inf,
            -inf, -82.7290,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 469: Reward=-259.59, route=[0, 6, 5, 7, 1, 2, 9, 3, 4, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.6453, -76.2727, -78.1878, -79.9288, -70.2333,     -inf,
        -71.1931, -73.1656, -79.6814], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5660, -76.4136, -79.0352, -80.4894,     -inf,     -inf,
        -69.2576, -70.5467, -80.7316], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.5864, -78.6549, -79.5859, -81.8618,     -inf,     -inf,
            -inf, -72.8718, -80.7153], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.9611,     -inf, -79.8928,     -inf,     -inf,
            -inf, -82.6331, -77.2203], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.0089,     -inf, -81.4643,     -inf,     -inf,
            -inf, -83.8690,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.7708,     -inf,     -inf,
            -inf, -75.4611,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.0955,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 470: Reward=-251.41, route=[0, 6, 5, 7, 1, 3, 9, 2, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.7531, -76.4614, -77.3157, -79.5341, -73.1176, -67.8521,
        -73.0951, -76.0080, -78.3891], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.6453, -76.2727, -78.1878, -79.9288, -70.2333,     -inf,
        -71.1931, -73.1656, -79.6814], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5679, -77.0825, -79.8470, -80.8228,     -inf,     -inf,
        -68.7762, -69.7654, -81.9275], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.5893, -79.3397, -80.3855, -82.1801,     -inf,     -inf,
            -inf, -72.0826, -81.9042], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.4724,     -inf, -78.0258, -79.1093,     -inf,     -inf,
            -inf,     -inf, -79.9525], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.7562, -81.1022,     -inf,     -inf,
            -inf,     -inf, -79.7958], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.2287,     -inf,     -inf,
            -inf,     -inf, -78.4226], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.7949,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 471: Reward=-217.19, route=[0, 6, 5, 7, 8, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.7199, -77.1248, -78.0654, -79.7959, -73.0088, -68.7956,
        -72.6310, -75.2586, -79.5198], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.6306, -76.9375, -78.9704, -80.2277, -70.1004,     -inf,
        -70.7210, -72.4006, -80.8465], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5679, -77.0825, -79.8470, -80.8228,     -inf,     -inf,
        -68.7762, -69.7654, -81.9275], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.5893, -79.3397, -80.3855, -82.1801,     -inf,     -inf,
            -inf, -72.0826, -81.9042], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.3591, -78.8396, -81.0636, -82.3459,     -inf,     -inf,
            -inf,     -inf, -83.0057], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.1473, -78.7010, -81.0541,     -inf,     -inf,
            -inf,     -inf, -79.7465], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.7875,     -inf, -81.7500,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.1260,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 472: Reward=-207.79, route=[0, 6, 5, 7, 8, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.7199, -77.1248, -78.0654, -79.7959, -73.0088, -68.7956,
        -72.6310, -75.2586, -79.5198], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.6306, -76.9375, -78.9704, -80.2277, -70.1004,     -inf,
        -70.7210, -72.4006, -80.8465], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5679, -77.0825, -79.8470, -80.8228,     -inf,     -inf,
        -68.7762, -69.7654, -81.9275], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.5893, -79.3397, -80.3855, -82.1801,     -inf,     -inf,
            -inf, -72.0826, -81.9042], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -76.1109, -81.3314, -78.9626, -81.7839,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.5979,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 473: Reward=-197.69, route=[0, 6, 5, 7, 8, 9, 1, 3, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -74.1470, -79.2070, -81.3244, -82.3300, -68.0651, -66.2508,
        -67.9996,     -inf, -84.0614], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -73.6316, -77.5430, -79.5044, -80.4617, -70.1518,     -inf,
        -70.4810,     -inf, -82.1742], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.5849, -77.6899, -80.4117, -81.0909,     -inf,     -inf,
        -68.5242,     -inf, -83.2829], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.6068, -79.9634, -80.9309, -82.4310,     -inf,     -inf,
            -inf,     -inf, -83.2562], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.6857, -79.1009, -81.1444,     -inf,     -inf,
            -inf,     -inf, -80.9766], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.2353,     -inf,     -inf,
            -inf,     -inf, -81.2293], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -79.3354], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 474: Reward=-238.95, route=[0, 8, 6, 5, 7, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.6296, -77.6462, -78.4813, -79.9039, -73.0635, -69.4679,
        -72.3840, -74.8257, -80.7485], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf, -73.7810, -76.4140,     -inf,     -inf, -76.9550,     -inf,
        -76.6862, -80.1475, -79.0617], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -81.5531,     -inf,
        -78.2319, -82.4100,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 475: Reward=-279.1, route=[0, 6, 3, 4, 1, 2, 9, 7, 5, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.7662, -78.1971, -79.3242, -79.7878, -72.6954, -70.0235,
        -72.4306, -74.4318, -82.4130], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -75.4398, -79.8750, -82.3771, -82.4096, -67.6915,     -inf,
        -68.0984,     -inf, -85.9479], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.7514, -78.2388, -81.3152, -81.0536,     -inf,     -inf,
        -68.5418,     -inf, -84.9964], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.7782, -80.5286, -81.8231, -82.3688,     -inf,     -inf,
            -inf,     -inf, -84.9761], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.2540, -79.9364, -81.0024,     -inf,     -inf,
            -inf,     -inf, -82.6526], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.8244,     -inf, -80.0312,     -inf,     -inf,
            -inf,     -inf, -81.2150], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.1317,     -inf,     -inf,
            -inf,     -inf, -82.8991], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.9706], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 476: Reward=-227.81, route=[0, 6, 8, 5, 7, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False  True False False]
greedy_action q_values = tensor([    -inf, -74.8031, -76.9000, -77.5750,     -inf, -76.5574, -72.6391,
            -inf, -79.6451, -80.5999], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False False]
greedy_action q_values = tensor([    -inf, -74.6923, -78.0120, -80.3133,     -inf, -69.6862,     -inf,
            -inf, -71.4287, -83.8193], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -74.6590, -78.1587, -81.2480,     -inf,     -inf,     -inf,
            -inf, -68.7508, -84.9499], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.4772, -79.9035, -82.4232,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.0220], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.2389, -79.9043,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.6317], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -82.7462,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 477: Reward=-249.42, route=[0, 7, 4, 6, 5, 8, 1, 3, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.9592, -78.7927, -81.1868, -80.5878, -69.3451,     -inf,
        -70.4260, -71.2168, -85.4703], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.9400, -78.9375, -82.1512, -81.2897,     -inf,     -inf,
        -68.4419, -68.5171, -86.6248], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.9715, -81.2443, -82.6436, -82.5830,     -inf,     -inf,
            -inf, -70.8349, -86.6075], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -76.7797, -80.7198, -83.3983, -82.8371,     -inf,     -inf,
            -inf,     -inf, -87.7697], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -81.0659, -80.7811, -81.2323,     -inf,     -inf,
            -inf,     -inf, -84.3077], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.3926,     -inf,     -inf,
            -inf,     -inf, -84.5528], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.5854], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 478: Reward=-226.79, route=[0, 6, 5, 7, 8, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -76.0109, -77.6707, -78.3343,     -inf, -76.2683, -72.6775,
        -76.6458, -79.4877, -82.1624], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -75.9369, -78.7770, -81.1543,     -inf, -69.3370,     -inf,
        -70.4069, -71.1945, -85.4488], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.9177, -78.9218, -82.1187,     -inf,     -inf,     -inf,
        -68.4228, -68.4948, -86.6033], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.9493, -81.2311, -82.6118,     -inf,     -inf,     -inf,
            -inf, -70.8105, -86.5862], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -76.7565, -80.6979, -83.3563,     -inf,     -inf,     -inf,
            -inf,     -inf, -87.7432], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -81.0502, -80.7486,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.2861], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.6236,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.8181], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.5312], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 479: Reward=-259.43, route=[0, 4, 6, 5, 7, 8, 1, 3, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.9985, -78.9869, -80.1791, -80.0374, -72.3202, -69.9983,
        -72.3725, -74.1392, -84.0593], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -77.1208, -79.5440, -82.2715, -80.8018, -69.2313,     -inf,
        -70.0366, -70.7122, -86.6811], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -78.1512, -82.0121, -83.7455, -82.8107,     -inf,     -inf,
            -inf, -70.3104, -87.8388], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -77.9723, -81.4818, -84.5282, -83.1021,     -inf,     -inf,
            -inf,     -inf, -89.0291], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -83.5799, -81.6326, -81.8793,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.4280,     -inf, -80.3129,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 480: Reward=-181.61, route=[0, 6, 5, 7, 8, 1, 9, 3, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -77.1426, -79.7405, -81.2309, -80.2095, -72.2290, -69.5846,
        -71.9928, -73.6543, -85.2359], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -77.1208, -79.5440, -82.2715, -80.8018, -69.2313,     -inf,
        -70.0366, -70.7122, -86.6811], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -77.1166, -79.6883, -83.2638, -81.5410,     -inf,     -inf,
        -68.0414, -67.9928, -87.8646], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -77.9679, -81.4654, -84.4829, -83.0577,     -inf,     -inf,
        -67.6173,     -inf, -88.9862], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -78.2277, -82.1001, -83.8318, -82.9025,     -inf,     -inf,
            -inf,     -inf, -87.9112], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.7066, -79.7292,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.6888], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.0040], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 481: Reward=-202.19, route=[0, 6, 5, 8, 7, 1, 4, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -77.1426, -79.7405, -81.2309, -80.2095, -72.2290, -69.5846,
        -71.9928, -73.6543, -85.2359], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -77.1208, -79.5440, -82.2715, -80.8018, -69.2313,     -inf,
        -70.0366, -70.7122, -86.6811], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -77.1166, -79.6883, -83.2638, -81.5410,     -inf,     -inf,
        -68.0414, -67.9928, -87.8646], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -78.9794, -82.4578, -84.7531, -82.9002,     -inf,     -inf,
            -inf,     -inf, -88.5141], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -82.1950, -82.6861, -81.2933,     -inf,     -inf,
            -inf,     -inf, -86.0081], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -81.7497,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.4317], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.2835], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 482: Reward=-239.39, route=[0, 6, 5, 8, 7, 1, 4, 3, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -77.8587, -80.0845, -82.1010, -80.1497, -72.6172, -69.3360,
        -72.0838, -73.4976, -85.7845], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -77.8606, -79.8888, -83.1777, -80.7870, -69.5917,     -inf,
        -70.1129, -70.5317, -87.2725], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -77.8761, -80.0345, -84.1997, -81.5654,     -inf,     -inf,
        -68.1023, -67.7884, -88.4916], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -78.7409, -81.8325, -85.4517, -83.1183,     -inf,     -inf,
        -67.6391,     -inf, -89.6360], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -78.9794, -82.4578, -84.7531, -82.9002,     -inf,     -inf,
            -inf,     -inf, -88.5141], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -82.1950, -82.6861, -81.2933,     -inf,     -inf,
            -inf,     -inf, -86.0081], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.0488, -80.5585,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.1851], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.4834], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 483: Reward=-202.19, route=[0, 6, 5, 8, 7, 1, 4, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -77.8587, -80.0845, -82.1010, -80.1497, -72.6172, -69.3360,
        -72.0838, -73.4976, -85.7845], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -77.8606, -79.8888, -83.1777, -80.7870, -69.5917,     -inf,
        -70.1129, -70.5317, -87.2725], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -77.8761, -80.0345, -84.1997, -81.5654,     -inf,     -inf,
        -68.1023, -67.7884, -88.4916], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -78.7409, -81.8325, -85.4517, -83.1183,     -inf,     -inf,
        -67.6391,     -inf, -89.6360], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -82.4434, -83.6031,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.4156], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.1419,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.7792], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 484: Reward=-239.6, route=[0, 6, 5, 8, 7, 4, 1, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -78.4115, -80.3421, -83.0635, -80.4168, -72.9504, -68.6579,
        -72.2395, -73.2378, -86.2404], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -78.4389, -80.1479, -84.1770, -81.0960, -69.8955,     -inf,
        -70.2542, -70.2488, -87.7734], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -79.5759, -81.8920,     -inf, -80.1795,     -inf,     -inf,
        -77.3890, -80.2173, -84.6548], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -78.5124, -79.1593,     -inf,     -inf,     -inf,     -inf,
            -inf, -78.7872, -84.4293], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -82.3301,     -inf,     -inf,     -inf,     -inf,
            -inf, -76.0621, -86.3197], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.7566], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 485: Reward=-324.64, route=[0, 6, 5, 3, 7, 4, 1, 8, 2, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -79.5160, -81.8563,     -inf, -80.1301, -79.9126,     -inf,
        -77.3695, -80.1806, -84.5921], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf, -79.4111, -82.5765,     -inf, -83.0508, -70.7970,     -inf,
            -inf, -69.7822, -88.8669], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -79.2576, -82.0716,     -inf, -83.4742, -67.6262,     -inf,
            -inf,     -inf, -90.1286], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -80.8192, -84.1576,     -inf, -81.8515,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 486: Reward=-244.44, route=[0, 6, 3, 7, 8, 5, 9, 1, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False  True False]
greedy_action q_values = tensor([    -inf, -79.5083,     -inf, -87.0167, -83.4955, -67.8730, -64.2510,
        -67.7635,     -inf, -90.3111], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -79.8464,     -inf, -86.3529, -83.2413, -71.1227,     -inf,
            -inf,     -inf, -89.2799], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -79.9244,     -inf,     -inf, -80.2537,     -inf,     -inf,
            -inf,     -inf, -84.9570], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 487: Reward=-276.65, route=[0, 2, 8, 6, 7, 5, 3, 1, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -78.6846, -80.1050, -83.5929, -80.3814, -73.2527, -67.6676,
        -72.4394, -73.2511, -86.4521], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -78.7402, -79.9148, -84.7460, -81.1060, -70.1658,     -inf,
        -70.4387, -70.2343, -88.0333], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -78.7779, -80.0727, -85.8356, -81.9721,     -inf,     -inf,
        -68.4089, -67.4685, -89.3036], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -79.6621, -81.9063, -87.1575, -83.6094,     -inf,     -inf,
        -67.8669,     -inf, -90.4920], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -79.8724, -82.4919, -86.3453, -83.2439,     -inf,     -inf,
            -inf,     -inf, -89.2915], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -82.2224, -84.1473, -81.4741,     -inf,     -inf,
            -inf,     -inf, -86.6203], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -83.9529, -83.8006,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.7799,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 488: Reward=-207.95, route=[0, 6, 5, 8, 7, 1, 4, 9, 3, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -78.1365, -79.5146, -83.7315, -80.1096, -73.8305, -66.7233,
        -72.7975, -73.6964, -85.8318], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -81.4796, -84.0622, -80.9686, -77.4731,     -inf,
        -74.8933, -76.6255, -85.7607], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.9686,     -inf, -78.0743,     -inf,
            -inf, -79.3634, -83.9560], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -87.5264,     -inf,     -inf,     -inf,
            -inf,     -inf, -90.1079], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.2551], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 489: Reward=-260.74, route=[0, 6, 1, 7, 2, 4, 5, 8, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -81.3472, -83.8774,     -inf, -77.4130, -69.3648,
        -74.7709, -76.5340, -85.5693], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.8043, -86.4231,     -inf, -71.7022,     -inf,
            -inf, -70.2063,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.3368, -87.4233,     -inf, -68.4329,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.6250, -86.2303,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.8532,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 490: Reward=-267.63, route=[0, 4, 1, 6, 9, 7, 8, 5, 2, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -78.1365, -79.5146, -83.7315, -80.1096, -73.8305, -66.7233,
        -72.7975, -73.6964, -85.8318], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -77.0491, -78.2270, -85.5533, -80.9818,     -inf,     -inf,
            -inf, -68.2556,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -77.9254, -80.0487, -86.8852, -82.6355,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.2614, -78.6161,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.3875,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 491: Reward=-256.27, route=[0, 6, 9, 7, 5, 8, 1, 2, 4, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -76.7627, -78.1840, -83.0762, -79.1379, -74.1768, -65.6061,
        -72.9107, -74.1723, -84.2417], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -76.9011, -78.0182, -84.3265, -79.9710, -71.0214,     -inf,
        -70.8797, -71.0943, -85.9490], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -77.8710, -80.4558, -85.7817, -81.9714, -71.9436,     -inf,
            -inf, -70.5799, -87.0469], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.2371, -83.5042, -80.0851, -77.8886,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.3397, -85.7053, -81.1090,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.2614, -78.6161,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.3875,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 492: Reward=-233.55, route=[0, 6, 7, 8, 9, 1, 5, 2, 4, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -78.6462, -81.6806, -82.7022, -79.9604, -83.5101, -72.2727,
        -78.8158, -82.4329,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -76.9341, -78.0274, -84.3280, -79.9652, -71.0854,     -inf,
        -70.9468, -71.1622,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -75.6904,     -inf,     -inf, -80.5257,     -inf,     -inf,
            -inf, -69.0878,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -76.5584,     -inf,     -inf, -82.1889,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.5169,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 493: Reward=-291.38, route=[0, 9, 6, 7, 3, 2, 5, 8, 1, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.3128, -77.1029, -82.4280, -78.5639, -74.5148, -64.8716,
        -72.8565, -75.0183, -82.6994], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -75.1732, -75.8405, -80.3594,     -inf, -78.8859,     -inf,
        -77.5030, -80.8508, -80.4843], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.5237,     -inf,     -inf, -81.7967,     -inf,
        -78.1405, -82.2543, -80.5816], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.3572,     -inf,     -inf, -72.2335,     -inf,
            -inf, -71.4056, -85.5599], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -72.7529,     -inf,
            -inf,     -inf, -83.2689], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 494: Reward=-279.07, route=[0, 6, 4, 1, 3, 7, 8, 2, 5, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.3128, -77.1029, -82.4280, -78.5639, -74.5148, -64.8716,
        -72.8565, -75.0183, -82.6994], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.5000, -76.9511, -83.7333, -79.4556, -71.3253,     -inf,
        -70.8124, -71.9061, -84.4774], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -76.4524, -79.3793, -85.1808, -81.4592, -72.2477,     -inf,
            -inf, -71.3898, -85.5590], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.1456,     -inf, -82.5288, -77.9860, -72.7671,     -inf,
            -inf,     -inf, -83.2680], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.7535,     -inf, -85.1486, -80.6624,     -inf,     -inf,
            -inf,     -inf, -86.0709], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.8383,     -inf,     -inf,     -inf,
            -inf,     -inf, -79.0652], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.4458,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 495: Reward=-245.69, route=[0, 6, 7, 8, 2, 5, 1, 4, 9, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -74.9864, -78.0392, -85.5696, -81.6475, -69.2430,     -inf,
        -68.1739,     -inf, -85.5392], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.0073, -78.5642, -84.5498, -81.0618, -72.5792,     -inf,
            -inf,     -inf, -84.0658], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.2684, -76.3626, -84.4274, -80.1707,     -inf,     -inf,
            -inf,     -inf, -84.5434], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.0573,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.9903], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 496: Reward=-235.28, route=[0, 6, 8, 7, 5, 1, 3, 4, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.7630, -76.2010, -81.6630, -78.0160, -74.8641, -63.9823,
        -72.9284, -75.8464, -81.0838], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.9987, -76.0602, -83.0238, -78.9641, -71.6384,     -inf,
        -70.8653, -72.6974, -82.9312], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -74.9331, -78.4828, -84.4630, -80.9722, -72.5596,     -inf,
            -inf, -72.1768, -83.9960], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.9923, -78.0610, -85.6276, -81.7088, -69.1882,     -inf,
            -inf,     -inf, -85.5876], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.2684, -76.3626, -84.4274, -80.1707,     -inf,     -inf,
            -inf,     -inf, -84.5434], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.7518,     -inf, -77.4427,     -inf,     -inf,
            -inf,     -inf, -79.0289], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.0573,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.9903], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.3802], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 497: Reward=-229.36, route=[0, 6, 7, 8, 5, 1, 3, 4, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.2163, -75.5265, -80.8774, -77.5494, -74.7603, -62.9973,
        -72.8238, -76.3112, -79.6845], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.7474, -75.5919, -83.5958, -79.6441,     -inf,     -inf,
        -68.6245, -70.1846, -83.1747], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.4783, -81.1162, -78.3320,     -inf,     -inf,
            -inf, -79.3343, -79.4380], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.0626, -77.0076,     -inf,     -inf,
            -inf, -75.7352, -80.3699], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -85.1059, -81.4659,     -inf,     -inf,
            -inf,     -inf, -84.5094], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 498: Reward=-259.34, route=[0, 6, 5, 7, 1, 2, 8, 4, 9, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.2163, -75.5265, -80.8774, -77.5494, -74.7603, -62.9973,
        -72.8238, -76.3112, -79.6845], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -71.9570, -74.2425, -78.6736,     -inf, -79.2527,     -inf,
        -77.5645, -82.2874, -77.2900], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.4038, -80.9690,     -inf, -78.5278,     -inf,
        -74.9455, -79.3596, -79.2952], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.6173, -83.6751,     -inf,     -inf,     -inf,
            -inf, -70.0977, -83.2534], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.4254, -85.0113,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.4346], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -77.4998], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 499: Reward=-248.07, route=[0, 6, 4, 1, 7, 5, 8, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.2163, -75.5265, -80.8774, -77.5494, -74.7603, -62.9973,
        -72.8238, -76.3112, -79.6845], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0109, -75.1252, -81.2426, -77.8845, -71.1071,     -inf,
        -70.5512, -73.4584, -80.4183], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.9122, -77.5501, -82.6665, -79.9049, -72.0099,     -inf,
            -inf, -72.9183, -81.4629], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1858, -79.9042, -77.5229, -78.1473,     -inf,
            -inf, -79.6906, -78.0694], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.6632,     -inf, -78.9281,     -inf,
            -inf, -82.6822, -76.1089], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.1366,     -inf, -84.0862,     -inf,
            -inf, -85.3279,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -81.9240,     -inf,
            -inf, -84.1684,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -70.5085,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 500: Reward=-243.5, route=[0, 6, 7, 1, 2, 4, 9, 3, 5, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0109, -75.1252, -81.2426, -77.8845, -71.1071,     -inf,
        -70.5512, -73.4584, -80.4183], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.9122, -77.5501, -82.6665, -79.9049, -72.0099,     -inf,
            -inf, -72.9183, -81.4629], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1858, -79.9042, -77.5229, -78.1473,     -inf,
            -inf, -79.6906, -78.0694], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.6632,     -inf, -78.9281,     -inf,
            -inf, -82.6822, -76.1089], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.7166,     -inf,     -inf,     -inf,
            -inf, -70.4916,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -84.0531,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 501: Reward=-276.93, route=[0, 6, 7, 1, 2, 4, 9, 5, 8, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.6818, -75.2597, -79.7679, -76.8289, -74.3976, -61.9255,
        -72.6474, -76.6742, -78.4368], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0109, -75.1252, -81.2426, -77.8845, -71.1071,     -inf,
        -70.5512, -73.4584, -80.4183], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.9122, -77.5501, -82.6665, -79.9049, -72.0099,     -inf,
            -inf, -72.9183, -81.4629], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.2215, -78.8078, -77.2614, -77.8896,     -inf,
            -inf, -79.9760, -77.0209], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.7312,     -inf, -75.5787, -81.7046,     -inf,
            -inf, -84.5014,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.1298,     -inf,     -inf, -68.2983,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 502: Reward=-216.94, route=[0, 6, 7, 1, 9, 3, 4, 8, 5, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -70.6501, -77.4699, -81.5239, -79.6241, -71.6346, -59.3976,
            -inf, -73.0556, -80.3653], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -69.8944, -75.1689, -80.3184, -77.7682, -70.7372,     -inf,
            -inf, -73.5933, -79.5479], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -81.8279, -79.0270,     -inf,     -inf,
            -inf, -70.6391, -81.3235], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.1652, -80.7360,     -inf,     -inf,
            -inf,     -inf, -82.5088], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 503: Reward=-259.56, route=[0, 7, 6, 1, 2, 5, 8, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.5111, -75.2846, -78.7259, -76.5997, -74.1145, -60.8375,
        -72.3537, -76.9309, -77.4463], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.8833, -75.1491, -80.2593, -77.7068, -70.7909,     -inf,
        -70.2428, -73.6820, -79.4924], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.2017, -78.7486, -77.2000, -77.9433,     -inf,
        -74.5135, -80.0647, -76.9654], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.6091, -81.7364, -79.7742, -71.7058,     -inf,
            -inf, -73.1547, -80.5829], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.0282,     -inf, -75.6837,     -inf,     -inf,
            -inf, -84.3317, -74.2017], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.4356,     -inf, -80.8774,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.2592,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 504: Reward=-264.78, route=[0, 6, 1, 7, 5, 3, 9, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.9316, -75.5344, -77.5452, -76.7261, -73.5535, -59.7065,
        -71.9061, -76.7340, -76.8528], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.3428, -75.3952, -79.1402, -77.8833, -70.1988,     -inf,
        -69.7832, -73.4567, -78.9620], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.4684, -77.5084, -77.3003, -77.4028,     -inf,
        -74.0680, -79.8867, -76.3201], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.8672, -80.6077, -79.9688, -71.1018,     -inf,
            -inf, -72.9109, -80.0516], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.0282,     -inf, -75.6837,     -inf,     -inf,
            -inf, -84.3317, -74.2017], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.1616,     -inf, -77.0978,     -inf,     -inf,
            -inf, -85.5831,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.4107,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 505: Reward=-279.99, route=[0, 6, 1, 7, 5, 3, 9, 4, 8, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.3552, -77.3571, -77.1835, -77.3527, -62.3512,
        -73.9645, -79.8131, -76.1540], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.6203, -80.6488, -79.1455,     -inf,     -inf,
        -67.6428, -70.4505, -80.7462], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.7566, -75.9403,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 506: Reward=-282.83, route=[0, 1, 6, 5, 7, 4, 8, 9, 3, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -69.0159, -77.3224,     -inf, -75.8669, -80.6410, -63.9434,
        -77.0309, -84.1309, -73.2794], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.3257, -75.8298,     -inf, -78.3984, -69.6071,     -inf,
        -69.5072, -73.2307, -78.5210], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.6969,     -inf, -77.5351, -82.9391,     -inf,
        -77.9042,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.8039,     -inf,     -inf, -77.8069,     -inf,
        -76.6676,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 507: Reward=-298.12, route=[0, 3, 6, 1, 8, 9, 4, 2, 7, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.9048, -76.0039, -76.9162, -77.2425, -73.0142, -58.8599,
        -71.6382, -76.5196, -76.3833], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -70.0870, -79.6227, -75.7286, -77.4542, -82.9250,     -inf,
        -77.8608, -85.4356,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.4689,     -inf, -76.0055, -80.7755,     -inf,
        -77.2261, -84.2998,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -71.3172,     -inf,
        -71.8034, -76.0691,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -67.4035, -70.2654,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 508: Reward=-214.12, route=[0, 6, 9, 1, 3, 4, 2, 5, 7, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -70.6935, -78.1949, -80.9985, -81.9857, -66.1941, -54.6371,
        -66.2836,     -inf, -81.4567], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -69.6787, -76.3793, -78.3947, -79.1665, -68.8733,     -inf,
        -69.2924,     -inf, -78.7064], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.5291, -76.6192, -78.5183,     -inf,     -inf,
        -73.6411,     -inf, -75.9188], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.0610,     -inf, -76.7519,     -inf,     -inf,
            -inf,     -inf, -73.6120], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.3752,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 509: Reward=-252.33, route=[0, 8, 6, 5, 1, 7, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.6883, -79.6272, -81.0895, -69.6850, -56.9004,
            -inf, -72.3689, -79.5692], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.3461, -78.4324, -79.1753, -68.8233,     -inf,
            -inf, -72.9660, -78.7488], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.5440, -79.9712, -80.4813,     -inf,     -inf,
            -inf, -69.8783, -80.5812], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.3799, -81.3079, -82.2407,     -inf,     -inf,
            -inf,     -inf, -81.8070], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.6165, -78.2688,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.7735,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 510: Reward=-229.29, route=[0, 1, 7, 6, 5, 8, 2, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.1298, -76.4435, -76.6073, -77.8311, -72.2774, -58.4272,
        -71.4374, -76.3675, -76.4095], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.6066, -76.2985, -78.3092, -79.0746, -68.8595,     -inf,
        -69.2822, -73.0317, -78.6374], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.8247, -76.7385, -79.8445, -81.1849,     -inf,     -inf,
        -66.6586, -69.6005, -80.7347], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.3664, -79.0641, -79.7295, -82.0178,     -inf,     -inf,
            -inf, -72.1152, -79.9731], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.7198, -76.4593, -79.1938,     -inf,     -inf,
            -inf, -79.2297, -76.0208], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.4461, -75.2750, -78.7938,     -inf,     -inf,
            -inf, -85.0846,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.5768,     -inf, -82.9704,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.0949,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 511: Reward=-221.96, route=[0, 6, 5, 7, 1, 9, 3, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.8887, -76.6808, -76.5046, -78.5450, -71.3693, -58.2235,
        -71.0378, -76.0808, -76.5581], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.3923, -76.5370, -78.2598, -79.8357, -67.9209,     -inf,
        -68.8704, -72.7155, -78.8486], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.8247, -76.7385, -79.8445, -81.1849,     -inf,     -inf,
        -66.6586, -69.6005, -80.7347], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.7582, -78.5783, -81.2182, -82.9958,     -inf,     -inf,
            -inf,     -inf, -82.0618], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.5271, -75.3613, -78.8869,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.3117,     -inf, -77.3789,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.5279,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 512: Reward=-181.61, route=[0, 6, 5, 7, 8, 1, 9, 3, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.3923, -76.5370, -78.2598, -79.8357, -67.9209,     -inf,
        -68.8704, -72.7155, -78.8486], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.8247, -76.7385, -79.8445, -81.1849,     -inf,     -inf,
        -66.6586, -69.6005, -80.7347], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.3664, -79.0641, -79.7295, -82.0178,     -inf,     -inf,
            -inf, -72.1152, -79.9731], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.3551, -73.6514,     -inf,     -inf,     -inf,
            -inf, -82.1870, -74.1682], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.3565,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 513: Reward=-278.59, route=[0, 6, 5, 7, 1, 4, 3, 8, 9, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.7386, -76.5729, -76.2056, -78.4314, -70.1812, -58.3956,
        -70.7204, -75.7651, -76.9713], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -71.8239, -80.2586, -74.6851, -78.4204, -80.2267,     -inf,
        -77.0130, -84.8562,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.5652, -75.9928, -78.9091, -74.1517,     -inf,
        -72.9675, -79.0555,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.0553, -78.0436,     -inf,
            -inf, -83.6585,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -75.0658,     -inf,
            -inf, -82.2580,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -69.2415,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 514: Reward=-269.5, route=[0, 6, 9, 1, 7, 2, 3, 4, 5, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.7386, -76.5729, -76.2056, -78.4314, -70.1812, -58.3956,
        -70.7204, -75.7651, -76.9713], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8567, -78.0311,     -inf, -76.9330, -78.0096,     -inf,
        -76.3092, -83.6355, -73.7192], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.5264,     -inf, -78.8797, -74.0676,     -inf,
        -72.9092, -79.0039, -76.2408], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.9332,     -inf, -81.9164, -67.5203,     -inf,
            -inf, -71.7548, -80.4173], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.4831,     -inf,     -inf,
            -inf, -85.2002,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -82.6176,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 515: Reward=-288.98, route=[0, 6, 3, 1, 7, 5, 2, 9, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.7558, -76.6771, -76.1340, -78.4463, -69.4325, -59.1200,
        -70.8152, -76.0106, -77.2011], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.3166, -76.5447, -77.9997, -79.8478, -65.9213,     -inf,
        -68.6121, -72.5760, -79.6150], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.7985, -76.7601, -79.6781, -81.2956,     -inf,     -inf,
        -66.3661, -69.3987, -81.6049], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.3307, -79.0969, -79.4860, -82.0706,     -inf,     -inf,
            -inf, -71.9404, -80.7711], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.3000, -75.5033, -73.5340,     -inf,     -inf,     -inf,
            -inf,     -inf, -74.3349], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.5422,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 516: Reward=-258.74, route=[0, 6, 5, 7, 8, 4, 1, 9, 2, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False  True False False]
greedy_action q_values = tensor([    -inf, -71.7228, -78.0372,     -inf, -76.7923, -77.2158, -64.3899,
            -inf, -83.7979, -73.7268], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf, -72.3045, -76.5291,     -inf, -79.8675, -65.8413,     -inf,
            -inf, -72.4983, -79.6410], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.7863, -76.7446,     -inf, -81.3154,     -inf,     -inf,
            -inf, -69.3210, -81.6310], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.7450, -78.5785,     -inf, -83.0959,     -inf,     -inf,
            -inf,     -inf, -82.9373], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.2241,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 517: Reward=-256.07, route=[0, 7, 3, 6, 5, 8, 1, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.9079, -76.7727, -76.3792, -78.6466, -68.7629, -60.0548,
        -71.0636, -76.3698, -77.5011], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.4981, -76.6455, -78.2985, -80.1022, -65.2163,     -inf,
        -68.8394, -72.8950, -79.9804], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.0061, -76.8680, -80.0230, -81.5987,     -inf,     -inf,
        -66.5744, -69.6829, -82.0261], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -74.5366, -79.2119, -79.7997, -82.3491,     -inf,     -inf,
            -inf, -72.2477, -81.1529], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.9983, -78.7388, -81.4461, -83.4827,     -inf,     -inf,
            -inf,     -inf, -83.4144], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.9145, -76.3187, -79.3048,     -inf,     -inf,
            -inf,     -inf, -76.9316], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.3929,     -inf, -77.2114,     -inf,     -inf,
            -inf,     -inf, -74.2788], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.6051,     -inf, -78.6487,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 518: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.9079, -76.7727, -76.3792, -78.6466, -68.7629, -60.0548,
        -71.0636, -76.3698, -77.5011], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.4981, -76.6455, -78.2985, -80.1022, -65.2163,     -inf,
        -68.8394, -72.8950, -79.9804], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.9658,     -inf, -76.7373, -78.1911,     -inf,     -inf,
        -71.2198,     -inf, -78.3654], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.6383,     -inf, -79.9350, -82.4812,     -inf,     -inf,
            -inf,     -inf, -81.2661], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.3663, -79.3420,     -inf,     -inf,
            -inf,     -inf, -76.9723], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 519: Reward=-240.03, route=[0, 6, 5, 8, 2, 7, 1, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -73.7119, -78.0682,     -inf, -77.1119, -75.9423, -66.0621,
        -76.9317, -84.5008,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf, -74.4322, -76.5889,     -inf, -80.4812, -64.3843,     -inf,
        -69.0690, -72.9630,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf, -73.1845, -75.4001,     -inf,     -inf,     -inf,     -inf,
        -76.5342, -83.1938,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.7193,     -inf,     -inf,     -inf,     -inf,
        -73.5394, -79.7990,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 520: Reward=-283.58, route=[0, 9, 3, 6, 5, 4, 1, 7, 2, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.8225, -76.7452, -76.9334, -79.0498, -67.9196, -60.5570,
        -71.2413, -76.3877, -78.2692], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.4442, -76.6265, -78.9041, -80.5578, -64.3410,     -inf,
        -68.9982, -72.8774, -80.8123], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.9803, -76.8590, -80.6732, -82.1018,     -inf,     -inf,
        -66.7160, -69.6343, -82.9127], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -75.5035, -79.2050, -80.4234, -82.8305,     -inf,     -inf,
            -inf, -72.2144, -82.0067], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.9952, -78.7356, -82.1125, -84.0069,     -inf,     -inf,
            -inf,     -inf, -84.3286], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.8901, -76.8505, -79.6869,     -inf,     -inf,
            -inf,     -inf, -77.6717], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.5440,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 521: Reward=-230.56, route=[0, 6, 5, 7, 8, 1, 3, 4, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -73.6926, -78.0675,     -inf, -77.1354, -75.8795, -66.0161,
        -76.8671, -84.4322, -74.5026], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.4130, -76.5882,     -inf, -80.5047, -64.3215,     -inf,
        -69.0044, -72.8944, -80.7706], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.6610, -76.9536,     -inf, -82.1771,     -inf,     -inf,
        -66.8513, -69.2978, -83.7157], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.1707, -79.3038,     -inf, -82.8739,     -inf,     -inf,
            -inf, -71.8881, -82.7752], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -76.6762, -78.8576,     -inf, -84.1320,     -inf,     -inf,
            -inf,     -inf, -85.1449], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.6902,     -inf, -78.8767,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 522: Reward=-226.33, route=[0, 3, 6, 5, 7, 8, 1, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.4698, -76.8602, -77.5674, -79.0674, -67.9173, -61.1329,
        -71.4068, -76.0985, -78.9927], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.1264, -76.7500, -79.5916, -80.6344, -64.2964,     -inf,
        -69.1445, -72.5538, -81.6018], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.6935, -76.9928, -81.4074, -82.2315,     -inf,     -inf,
        -66.8451, -69.2805, -83.7591], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.8186, -75.5583, -74.6678,     -inf,     -inf,     -inf,
            -inf, -82.7927, -75.7931], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.8991, -77.3252,     -inf,     -inf,     -inf,
            -inf, -79.3479, -78.2529], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.5786,     -inf,     -inf,     -inf,     -inf,
            -inf, -85.4814,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -75.6089,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 523: Reward=-259.4, route=[0, 6, 5, 7, 4, 1, 3, 9, 2, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.4698, -76.8602, -77.5674, -79.0674, -67.9173, -61.1329,
        -71.4068, -76.0985, -78.9927], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.4692,     -inf, -77.8702, -78.5387,     -inf,     -inf,
        -71.5681, -75.6182, -79.8254], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.2293,     -inf, -81.1794, -82.9656,     -inf,     -inf,
            -inf, -71.8920, -82.8602], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.0747,     -inf,     -inf, -77.1839,     -inf,     -inf,
            -inf,     -inf, -76.0474], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.4693,     -inf,     -inf,
            -inf,     -inf, -78.9360], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 524: Reward=-235.9, route=[0, 6, 5, 2, 7, 8, 3, 1, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.9806, -76.4116, -78.1301, -78.9207, -67.7648, -61.5387,
        -71.3195, -75.6079, -79.6033], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.6745, -76.3150, -80.2088, -80.5492, -64.1006,     -inf,
        -69.0404, -72.0245, -82.2845], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -76.2739, -76.5716, -82.0712, -82.2008,     -inf,     -inf,
        -66.7257, -68.7172, -84.5029], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.7667, -78.9156, -81.7674, -82.8619,     -inf,     -inf,
            -inf, -71.3192, -83.5218], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -77.2884, -78.4989, -83.6060, -84.2051,     -inf,     -inf,
            -inf,     -inf, -85.9453], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.5546, -78.0015, -79.4882,     -inf,     -inf,
            -inf,     -inf, -78.9394], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.9864,     -inf, -77.1818,     -inf,     -inf,
            -inf,     -inf, -76.0574], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.2143,     -inf, -78.6102,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.1497,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 525: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -74.0477, -74.8996, -74.8572,     -inf, -72.8902, -64.9094,
        -76.5054, -82.3621, -75.9755], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False  True False]
greedy_action q_values = tensor([    -inf, -77.1608, -78.4138, -83.4352,     -inf, -61.1634,     -inf,
        -65.9117,     -inf, -85.7621], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -76.3163, -76.6210, -82.1133,     -inf,     -inf,     -inf,
        -66.7082,     -inf, -84.5403], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -76.8092, -78.9650, -81.8094,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.5592], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.5234, -77.9530,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.9009], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.5436,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -76.3490], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.7726,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 526: Reward=-227.02, route=[0, 4, 6, 8, 5, 7, 1, 3, 9, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.1331, -76.0248, -78.5166, -78.5121, -67.7330, -61.8846,
        -71.1169, -75.2601, -80.0550], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.8667, -75.9408, -80.6509, -80.2028, -64.0256,     -inf,
        -68.8222, -71.6403, -82.8082], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -76.4997, -76.2099, -82.5604, -81.9088,     -inf,     -inf,
        -66.4926, -68.3007, -85.0870], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.6985, -75.5319,     -inf,     -inf,     -inf,
            -inf, -82.1276, -76.7166], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.9413,     -inf,     -inf,     -inf,
            -inf, -74.6879, -81.0236], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -84.1821,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.6043], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 527: Reward=-243.38, route=[0, 6, 5, 7, 1, 4, 2, 8, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.8667, -75.9408, -80.6509, -80.2028, -64.0256,     -inf,
        -68.8222, -71.6403, -82.8082], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -76.4997, -76.2099, -82.5604, -81.9088,     -inf,     -inf,
        -66.4926, -68.3007, -85.0870], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.9688, -78.5494, -82.2259, -82.5303,     -inf,     -inf,
            -inf, -70.9140, -84.0635], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.8133, -76.6724,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.5420,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 528: Reward=-221.96, route=[0, 6, 5, 7, 8, 4, 1, 9, 3, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.6040, -75.0088, -78.4693, -77.6870, -67.7135, -61.9606,
        -70.7252, -74.7946, -79.9842], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -73.7104, -73.5638, -75.2161,     -inf, -73.0161,     -inf,
        -76.1106, -81.7762, -76.3552], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -77.0172, -77.1150, -84.0701,     -inf,     -inf,     -inf,
        -65.2381,     -inf, -86.5118], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.0891, -78.2223,     -inf,     -inf,     -inf,
            -inf,     -inf, -79.1887], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.0099,     -inf,     -inf,     -inf,
            -inf,     -inf, -81.0609], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -76.1861], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 529: Reward=-245.18, route=[0, 6, 4, 5, 8, 7, 1, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.6040, -75.0088, -78.4693, -77.6870, -67.7135, -61.9606,
        -70.7252, -74.7946, -79.9842], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.3816, -74.9457, -80.6631, -79.4424, -63.9642,     -inf,
        -68.4114, -71.1343, -82.8113], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -76.0509, -75.2333, -82.6218, -81.2036,     -inf,     -inf,
        -66.0628, -67.7577, -85.1507], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.4816, -77.5509, -82.2446, -81.7747,     -inf,     -inf,
            -inf, -70.3840, -84.0726], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -77.0777, -77.1713, -84.1976, -83.2464,     -inf,     -inf,
            -inf,     -inf, -86.6289], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1213, -78.2726, -78.1585,     -inf,     -inf,
            -inf,     -inf, -79.2292], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.0602, -77.4204,     -inf,     -inf,
            -inf,     -inf, -81.1014], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.5491,     -inf,     -inf,     -inf,
            -inf,     -inf, -76.6711], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -76.1861], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 530: Reward=-210.37, route=[0, 6, 5, 7, 8, 1, 2, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.6040, -75.0088, -78.4693, -77.6870, -67.7135, -61.9606,
        -70.7252, -74.7946, -79.9842], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -74.2489, -77.3672, -76.3149, -76.4531, -78.0925,     -inf,
        -76.6332, -83.2823,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.7850, -78.1414, -77.5384, -71.6043,     -inf,
        -72.3785, -77.0863,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.8578,     -inf,     -inf,
        -70.3465, -73.2661,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.5061,     -inf,     -inf,
            -inf, -69.2678,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -83.0334,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 531: Reward=-304.74, route=[0, 6, 9, 1, 5, 3, 2, 7, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.6273, -73.8414, -78.6275, -77.3730, -67.4114, -61.7410,
        -70.0490, -73.6143, -80.1144], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.4542, -73.7988, -80.8825, -79.1873, -63.6253,     -inf,
        -67.7214, -69.9206, -83.0117], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.1637, -74.1039, -82.8913, -80.9986,     -inf,     -inf,
        -65.3580, -66.5125, -85.4082], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -75.5447, -76.3959, -82.4715, -81.5290,     -inf,     -inf,
            -inf, -69.1354, -84.2792], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -76.1898, -76.0378, -84.4819, -83.0563,     -inf,     -inf,
            -inf,     -inf, -86.9015], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.8020,     -inf, -79.1868, -77.0935,     -inf,     -inf,
            -inf,     -inf, -81.2133], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.4405, -77.8388,     -inf,     -inf,
            -inf,     -inf, -79.3546], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.5992,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 532: Reward=-232.19, route=[0, 6, 5, 7, 8, 2, 1, 4, 9, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.6273, -73.8414, -78.6275, -77.3730, -67.4114, -61.7410,
        -70.0490, -73.6143, -80.1144], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.4542, -73.7988, -80.8825, -79.1873, -63.6253,     -inf,
        -67.7214, -69.9206, -83.0117], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -75.3339,     -inf, -75.6645], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.1136], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 533: Reward=-309.15, route=[0, 6, 5, 2, 1, 4, 8, 3, 7, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.1010, -72.2077, -80.8207, -78.6299, -63.1826,     -inf,
        -67.0386, -68.8356, -82.7708], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.2695, -70.7594, -75.1535,     -inf,     -inf,     -inf,
        -74.8705, -79.7314, -76.0623], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.2876,     -inf, -78.8676,     -inf,     -inf,     -inf,
        -69.5732, -72.0879, -80.7345], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -74.1640,     -inf, -82.4107,     -inf,     -inf,     -inf,
            -inf, -68.0071, -84.0395], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.8493,     -inf, -84.4676,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.7151], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.3512,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 534: Reward=-217.83, route=[0, 6, 5, 4, 2, 7, 8, 1, 9, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.2243, -72.2312, -78.5037, -76.7571, -67.0047, -61.6164,
        -69.3783, -72.5645, -79.8006], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.1010, -72.2077, -80.8207, -78.6299, -63.1826,     -inf,
        -67.0386, -68.8356, -82.7708], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.8509, -72.5289, -82.8798, -80.4908,     -inf,     -inf,
        -64.6614, -65.3939, -85.2261], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -74.1767, -74.7911, -82.4148, -80.9786,     -inf,     -inf,
            -inf, -68.0150, -84.0402], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.8673, -74.4544, -84.4777, -82.5584,     -inf,     -inf,
            -inf,     -inf, -86.7238], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.9801,     -inf, -74.8814,     -inf,     -inf,     -inf,
            -inf,     -inf, -75.8335], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.8021,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 535: Reward=-197.66, route=[0, 6, 5, 7, 8, 2, 4, 1, 9, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False  True False]
greedy_action q_values = tensor([    -inf, -69.7157, -69.0974, -74.5119,     -inf, -72.2369, -65.0701,
        -74.3390,     -inf, -75.4370], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False  True False]
greedy_action q_values = tensor([    -inf, -71.8428, -70.7116, -80.5121,     -inf, -62.9156,     -inf,
        -66.5528,     -inf, -82.5450], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.6343, -71.0470, -82.6231,     -inf,     -inf,     -inf,
        -64.1613,     -inf, -85.0603], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.4289, -71.9520,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -75.1802], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.6175,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.4547], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.5846], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 536: Reward=-300.94, route=[0, 8, 4, 6, 5, 7, 3, 1, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.8771, -70.6755, -78.0929, -75.6979, -66.7884, -61.4912,
        -68.9291, -71.6328, -79.4670], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -69.7901, -69.1434, -74.6038,     -inf, -72.2757,     -inf,
        -74.4434, -78.8373, -75.5642], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9024,     -inf, -78.4265,     -inf, -64.9408,     -inf,
        -69.1169, -71.1294, -80.3620], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5833,     -inf, -82.5798,     -inf,     -inf,     -inf,
        -64.1652, -64.3861, -85.0251], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.8541,     -inf, -82.0639,     -inf,     -inf,     -inf,
            -inf, -67.0079, -83.7811], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.5771,     -inf, -84.1658,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.5059], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.7594,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.5516], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -75.4329], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 537: Reward=-212.85, route=[0, 6, 4, 2, 5, 7, 8, 1, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -71.9711, -72.1889, -81.8297, -79.4319, -63.6708, -59.6533,
            -inf, -66.0452, -83.8602], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.1534, -69.7978, -80.5523, -77.3560, -62.9146,     -inf,
            -inf, -66.9220, -82.9369], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.9833, -70.1416, -82.7102, -79.3117,     -inf,     -inf,
            -inf, -63.4169, -85.5064], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.6455, -71.0523,     -inf, -72.8176,     -inf,     -inf,
            -inf,     -inf, -75.3855], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 538: Reward=-262.99, route=[0, 7, 6, 5, 8, 3, 1, 4, 9, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.1516, -69.7709, -78.0318, -75.2868, -66.8807, -61.5409,
        -68.3517, -70.8233, -79.7432], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1265, -69.7736, -80.4701, -77.2715, -62.9825,     -inf,
        -65.9886, -67.0259, -82.8545], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.6762, -77.4911, -75.4024,     -inf,     -inf,
        -70.6337, -74.2936, -78.6298], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.3646, -82.1315, -79.6650,     -inf,     -inf,
            -inf, -66.1724, -84.1879], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.7301, -75.0928,     -inf,     -inf,
            -inf,     -inf, -80.9859], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.8046,     -inf,     -inf,     -inf,
            -inf,     -inf, -76.0750], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 539: Reward=-214.92, route=[0, 6, 5, 1, 7, 8, 2, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.1516, -69.7709, -78.0318, -75.2868, -66.8807, -61.5409,
        -68.3517, -70.8233, -79.7432], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9642, -69.6219, -80.4606, -77.3683, -63.5095,     -inf,
        -65.8799, -67.1248, -83.4551], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.8293, -69.9667, -82.6660, -79.3647,     -inf,     -inf,
        -63.4624, -63.5812, -86.0801], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -70.1725, -73.0293, -75.3026, -74.0948,     -inf,     -inf,
            -inf, -80.7937,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 540: Reward=-251.9, route=[0, 6, 5, 7, 9, 1, 4, 2, 8, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9642, -69.6219, -80.4606, -77.3683, -63.5095,     -inf,
        -65.8799, -67.1248, -83.4551], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.4530,     -inf,     -inf,     -inf,     -inf,
        -70.5308, -74.4642, -79.0213], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.1430,     -inf,     -inf,     -inf,     -inf,
            -inf, -66.2513, -84.7014], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.8359,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -87.5359], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 541: Reward=-269.84, route=[0, 6, 5, 3, 4, 1, 7, 8, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.9474, -69.6199, -77.9655, -75.3373, -67.4517, -62.1110,
        -68.2587, -70.9658, -80.2771], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9642, -69.6219, -80.4606, -77.3683, -63.5095,     -inf,
        -65.8799, -67.1248, -83.4551], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -70.2238, -73.1823, -74.7069, -74.1636,     -inf,     -inf,
        -75.2529, -81.5615,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.6903, -76.9219, -75.5875,     -inf,     -inf,
        -70.9174, -75.1295,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.3808, -81.7755, -80.0197,     -inf,     -inf,
            -inf, -66.8205,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.0690, -84.0703, -81.7900,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.2992, -75.3464,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.1734,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 542: Reward=-225.87, route=[0, 6, 5, 9, 1, 7, 8, 2, 4, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -69.1270, -70.8178,     -inf, -72.5518, -76.7687, -68.7215,
        -74.4911, -80.2789, -75.9246], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1125, -69.7337,     -inf, -77.5623, -63.9655,     -inf,
        -66.1553, -67.6490, -84.1236], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.0094, -70.0795,     -inf, -79.5943,     -inf,     -inf,
        -63.7200, -64.0655, -86.8007], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.7444,     -inf, -75.7018,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 543: Reward=-242.41, route=[0, 3, 6, 5, 7, 8, 9, 1, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.0991, -69.7776, -77.5831, -75.5586, -67.9701, -62.6905,
        -68.5483, -71.5154, -80.9437], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1543, -69.7787, -80.1359, -77.6303, -63.9837,     -inf,
        -66.1497, -67.6284, -84.1848], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.0513, -70.1244, -82.3892, -79.6623,     -inf,     -inf,
        -63.7143, -64.0448, -86.8619], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -68.9419, -68.2784, -74.0082,     -inf,     -inf,     -inf,
            -inf, -78.8923, -76.9444], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -69.6093,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -80.7313, -76.5916], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -75.3738, -80.1494], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -88.9916], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 544: Reward=-268.78, route=[0, 6, 5, 7, 4, 2, 3, 1, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.4128, -70.2192, -77.2277, -76.0743, -68.6153, -63.3002,
        -68.7327, -71.8797, -81.3599], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.5077, -70.2163, -79.8390, -78.1843, -64.5843,     -inf,
        -66.3141, -67.9462, -84.6695], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.4631, -72.4758, -83.7184, -82.3185,     -inf,     -inf,
        -62.9554,     -inf, -88.9220], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.6609, -72.8933, -81.5457, -80.6985,     -inf,     -inf,
            -inf,     -inf, -86.0789], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.2568, -76.7271, -76.3117,     -inf,     -inf,
            -inf,     -inf, -80.2955], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.0012, -75.9093,     -inf,     -inf,
            -inf,     -inf, -82.6831], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.4479,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 545: Reward=-198.48, route=[0, 6, 5, 8, 7, 1, 2, 4, 9, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -69.3710, -71.2763,     -inf, -73.0037, -77.5123, -69.4046,
        -74.7204, -80.7425, -76.2171], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.9547,     -inf, -75.8483, -72.9162, -66.3942,
        -70.9360, -75.3850, -79.7749], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.4104,     -inf, -82.1815, -61.3587,     -inf,
        -63.0273,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.6025,     -inf, -80.2660,     -inf,     -inf,
        -63.9525,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.8253,     -inf, -81.8954,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.0106,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 546: Reward=-268.31, route=[0, 3, 1, 6, 9, 8, 5, 7, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -69.5745, -69.4817, -73.2585,     -inf, -74.9904, -67.5700,
        -74.3055, -79.5894, -77.5469], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -72.1743, -71.1217, -79.9377,     -inf, -65.1088,     -inf,
        -66.2140, -68.0376, -85.4309], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.1354, -71.4658, -82.2859,     -inf,     -inf,     -inf,
        -63.7414, -64.3754, -88.2188], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.2664, -73.7484, -81.5620,     -inf,     -inf,     -inf,
            -inf, -67.1116, -86.7800], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -71.3705,     -inf, -77.9767,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.7460,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 547: Reward=-264.45, route=[0, 4, 6, 5, 7, 8, 9, 2, 1, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -73.0164, -71.3748, -82.1481, -81.3709,     -inf, -58.8401,
        -63.6599, -64.3356, -88.0455], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.2815, -71.1907, -80.0529, -79.4878,     -inf,     -inf,
        -66.2601, -68.1013, -85.5532], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.1508, -76.6950, -77.4244,     -inf,     -inf,
            -inf, -75.5588, -80.9250], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.0300, -77.0261,     -inf,     -inf,
            -inf, -71.5246, -83.3716], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -84.1233, -83.7785,     -inf,     -inf,
            -inf,     -inf, -89.9865], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -73.7962,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.1030], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 548: Reward=-263.43, route=[0, 5, 6, 7, 1, 2, 8, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.7713, -76.1483, -77.9697, -73.9226, -67.3720,
        -70.6823, -75.9846, -81.1564], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.9706, -79.9504, -80.3693, -65.4256,     -inf,
        -66.0332, -68.4352, -86.2556], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.3176, -82.3480, -82.5058,     -inf,     -inf,
        -63.5425, -64.7333, -89.1004], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.6189, -81.5813, -82.8498,     -inf,     -inf,
            -inf, -67.4970, -87.6229], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.2925, -84.0406, -84.7214,     -inf,     -inf,
            -inf,     -inf, -90.7556], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.2041, -76.8743,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -75.3879,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 549: Reward=-231.39, route=[0, 1, 6, 5, 7, 8, 2, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.5751, -71.9522, -77.1682, -78.1492, -69.5181, -64.2024,
        -68.4635, -72.4269, -82.7639], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.7047, -72.2587, -82.2371,     -inf,     -inf,     -inf,
        -63.4909, -64.6766, -89.0044], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.8134, -74.5601, -81.4704,     -inf,     -inf,     -inf,
            -inf, -67.4403, -87.5269], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.7909, -74.2304, -83.9279,     -inf,     -inf,     -inf,
            -inf,     -inf, -90.6508], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.8769,     -inf, -77.8782,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.0431], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.1497,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 550: Reward=-240.65, route=[0, 6, 4, 5, 7, 8, 2, 1, 9, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -73.6234, -74.4329, -81.2696, -82.5999, -66.1010, -62.1783,
            -inf, -67.3627, -87.2742], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -73.5521, -73.0926, -79.9478, -81.1479, -65.5046,     -inf,
            -inf, -68.3086, -86.9362], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -74.5785, -73.4367, -82.3944, -83.3202,     -inf,     -inf,
            -inf, -64.5850, -89.8267], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.1810, -76.4385, -79.0270,     -inf,     -inf,
            -inf,     -inf, -82.1493], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.9149, -78.6751,     -inf,     -inf,
            -inf,     -inf, -84.7312], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.0193,     -inf,     -inf,
            -inf,     -inf, -78.3882], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 551: Reward=-261.31, route=[0, 7, 6, 5, 8, 1, 2, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -75.3813, -75.2095, -83.6598, -85.1522, -62.1354, -59.6264,
        -61.9035,     -inf, -91.0124], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -73.5948, -73.1413, -79.9490, -81.1532, -65.5721,     -inf,
        -65.4733,     -inf, -86.9244], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.6437, -75.7800, -81.5236, -83.5983, -66.3122,     -inf,
            -inf,     -inf, -88.2295], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.1810, -76.4385, -79.0270,     -inf,     -inf,
            -inf,     -inf, -82.1493], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.9149, -78.6751,     -inf,     -inf,
            -inf,     -inf, -84.7312], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.0193,     -inf,     -inf,
            -inf,     -inf, -78.3882], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 552: Reward=-283.51, route=[0, 8, 6, 7, 5, 1, 2, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.3032, -73.0698, -77.0682, -78.8169, -69.7323, -64.4152,
        -67.9525, -72.4777, -83.3274], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -72.1034, -76.6045, -73.6200, -77.1536, -81.3382,     -inf,
        -74.7718, -82.8909,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.8496,     -inf,     -inf, -79.1171,     -inf,
        -73.7500, -81.8085,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.1864,     -inf,     -inf, -66.3384,     -inf,
            -inf, -67.4318,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.8860,     -inf,     -inf,     -inf,     -inf,
            -inf, -64.5769,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.8715,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 553: Reward=-252.58, route=[0, 6, 9, 1, 4, 3, 7, 5, 8, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.1506, -74.5980, -76.8162, -79.5626, -69.7425, -64.4745,
        -67.4483, -72.4444, -83.8772], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.4062, -74.5895, -79.6656, -81.8482, -65.5418,     -inf,
        -64.9534, -68.3396, -87.4629], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -75.4708, -77.2596, -81.2422, -84.3178, -66.2799,     -inf,
            -inf, -67.3362, -88.7808], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -75.4992, -74.9551, -82.2523, -84.1480,     -inf,     -inf,
            -inf, -64.4928, -90.4886], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.1826, -79.7883,     -inf,     -inf,
            -inf,     -inf, -82.6972], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.6899,     -inf,     -inf,
            -inf,     -inf, -78.8166], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -79.5351], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 554: Reward=-246.54, route=[0, 6, 7, 5, 8, 2, 1, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True False False False False]
greedy_action q_values = tensor([    -inf, -71.5511, -72.9429, -72.5549,     -inf,     -inf, -68.4283,
        -73.2369, -80.2791, -79.1084], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.4369, -74.5891, -79.6736,     -inf,     -inf,     -inf,
        -64.9517, -68.3508, -87.4933], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.6319, -75.9888,     -inf,     -inf,     -inf,
            -inf, -76.0381, -82.5251], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.6689,     -inf,     -inf,     -inf,     -inf,
            -inf, -81.9428, -78.4484], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -72.1013, -85.0832], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -92.1029], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 555: Reward=-300.27, route=[0, 5, 4, 6, 7, 1, 3, 2, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.6587, -76.3014, -76.2563, -79.8704, -69.7141, -64.5061,
        -67.4379, -72.6231, -83.8229], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.8635,     -inf, -76.8514, -79.4617, -67.7774,     -inf,
        -67.7231, -72.1408, -84.9793], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -76.0550,     -inf, -80.7871, -84.7240, -66.2114,     -inf,
            -inf, -67.4823, -88.8469], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.1069,     -inf, -81.8504, -84.5760,     -inf,     -inf,
            -inf, -64.6140, -90.6086], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -77.1790,     -inf, -83.4405, -86.7369,     -inf,     -inf,
            -inf,     -inf, -92.1769], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -72.8694, -78.3752,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.8686,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 556: Reward=-212.75, route=[0, 6, 2, 7, 5, 8, 1, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.4880, -83.1308, -86.4343, -62.0128, -59.6572,
        -61.3442,     -inf, -91.8196], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.3936, -79.3155, -82.3337, -65.4951,     -inf,
        -64.9466,     -inf, -87.6141], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.9146,     -inf,     -inf,
            -inf,     -inf, -78.6204], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 557: Reward=-287.11, route=[0, 1, 8, 6, 7, 2, 5, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.5059, -77.5102, -75.2904, -79.4596, -69.9764, -64.6257,
        -67.8513, -73.1047, -82.8115], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.8492, -77.5028, -78.2709, -81.8484, -65.6873,     -inf,
        -65.3108, -68.9107, -86.5591], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -73.7703,     -inf, -76.0132, -79.1654, -67.9563,     -inf,
            -inf, -72.5092, -84.1046], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -76.0400,     -inf, -81.0107, -84.2711,     -inf,     -inf,
            -inf, -65.0045, -89.7607], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -77.1453,     -inf, -82.6338, -86.4618,     -inf,     -inf,
            -inf,     -inf, -91.3742], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.2456], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 558: Reward=-248.98, route=[0, 6, 7, 2, 5, 8, 1, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -74.9282, -77.5710, -78.3222, -81.9006, -65.7510,     -inf,
        -65.3672,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf, -76.0055, -80.3052, -79.8877, -84.3969, -66.4921,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -76.0996, -77.9504, -81.0209, -84.2980,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.2923,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 559: Reward=-273.54, route=[0, 9, 8, 6, 7, 5, 1, 2, 4, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -71.5844, -79.5045,     -inf, -75.2366, -80.1630, -71.0842,
        -74.7581, -83.6233, -75.5206], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.4876, -76.7194,     -inf,     -inf,     -inf,     -inf,
        -74.5164, -82.2719, -76.7084], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.3422,     -inf,     -inf,     -inf,     -inf,
        -70.8728, -77.9609, -79.9099], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -81.0405,     -inf,     -inf,     -inf,     -inf,
            -inf, -68.9213, -86.7954], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 560: Reward=-288.07, route=[0, 3, 6, 5, 4, 1, 7, 8, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.1435, -78.3105, -74.2203, -78.9017, -70.6192, -64.5968,
        -68.4634, -74.1010, -81.6567], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.5357, -78.3105, -77.2693, -81.3473, -66.2818,     -inf,
        -65.8988, -69.8615, -85.4901], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -72.7714, -82.1084, -70.3663, -77.0560,     -inf,     -inf,
            -inf, -84.8788,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -71.5259, -76.7384,     -inf,     -inf,     -inf,     -inf,
            -inf, -82.2356,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.3612,     -inf,     -inf,     -inf,     -inf,
            -inf, -77.9246,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.6777,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 561: Reward=-260.26, route=[0, 6, 7, 5, 9, 3, 4, 1, 8, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.1435, -78.3105, -74.2203, -78.9017, -70.6192, -64.5968,
        -68.4634, -74.1010, -81.6567], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.5357, -78.3105, -77.2693, -81.3473, -66.2818,     -inf,
        -65.8988, -69.8615, -85.4901], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -75.6128, -81.0694, -78.8255, -83.8516, -67.0312,     -inf,
            -inf, -68.8487, -86.7972], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.7442, -71.9973, -77.9848,     -inf,     -inf,
            -inf, -78.9251, -78.6837], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.0007,     -inf, -74.6220,     -inf,     -inf,
            -inf, -84.7848, -74.4287], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.0401,     -inf, -85.1927,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.8546,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 562: Reward=-243.57, route=[0, 6, 7, 5, 1, 3, 9, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.4884, -78.5825, -73.0305, -78.0531, -71.0913, -64.4249,
        -69.0040, -75.1177, -80.2907], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.9313, -78.5964, -76.1501, -80.5589, -66.7071,     -inf,
        -66.4171, -70.8342, -84.2099], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -75.0029, -81.3721, -77.6935, -83.0660, -67.4621,     -inf,
            -inf, -69.8235, -85.5040], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -75.1920, -79.0076, -78.9678, -83.0679,     -inf,     -inf,
            -inf, -66.8072, -87.5449], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -72.0930, -82.4478, -69.1140, -76.1867,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -71.1871, -80.0429,     -inf, -74.6426,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 563: Reward=-221.79, route=[0, 6, 7, 5, 8, 9, 3, 1, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -76.0275, -80.8661, -80.2453, -84.9673, -63.0448, -59.3993,
        -62.6855,     -inf, -88.7660], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -74.0099, -78.6768, -76.2411, -80.6577, -66.7057,     -inf,
        -66.4130,     -inf, -84.2905], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.8646, -77.0926, -68.7299,     -inf, -77.3379,     -inf,
            -inf,     -inf, -75.4033], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -75.7225,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 564: Reward=-285.61, route=[0, 8, 6, 7, 4, 3, 9, 2, 1, 5] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -74.2229, -78.9394, -78.2898, -82.2667,     -inf, -58.7986,
        -64.1008, -67.0642, -86.1944], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.2033, -78.7304, -75.7746, -80.0342,     -inf,     -inf,
        -66.8535, -71.1292, -83.1980], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.2312, -80.1188,     -inf, -73.9225,     -inf,     -inf,
            -inf,     -inf, -73.1103], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -75.3659,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 565: Reward=-268.02, route=[0, 5, 6, 7, 8, 3, 1, 2, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.6365, -78.6625, -72.5259, -77.4048, -71.0125, -64.0408,
        -69.4350, -75.4087, -79.1142], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.7548, -71.2771, -77.1270, -75.7510,     -inf,
        -71.8840, -79.3152, -77.2470], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.9907,     -inf, -73.6896, -80.8070,     -inf,
        -75.9734, -85.2235, -72.8939], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -82.3434,     -inf, -75.0801, -83.2097,     -inf,
        -76.6357, -86.5288,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.9906,     -inf,     -inf, -77.4711,     -inf,
        -75.6511, -83.7983,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.3953,     -inf,     -inf, -67.4129,     -inf,
            -inf, -70.1745,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.8053,     -inf,     -inf,     -inf,     -inf,
            -inf, -66.7988,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.9053,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 566: Reward=-240.29, route=[0, 6, 1, 3, 9, 4, 7, 5, 8, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.3339,     -inf, -73.3854, -76.7966, -68.1558,     -inf,
        -69.5942, -74.6351, -80.1291], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.8788,     -inf, -78.7425, -82.2779,     -inf,     -inf,
        -64.0412, -66.8191, -86.2713], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.7113,     -inf, -77.5300, -82.3581,     -inf,     -inf,
            -inf, -69.8100, -84.2706], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.0454,     -inf, -80.4951, -84.6378,     -inf,     -inf,
            -inf,     -inf, -88.0225], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -68.3307,     -inf,     -inf,     -inf,
            -inf,     -inf, -73.8311], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -72.6584], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 567: Reward=-220.05, route=[0, 6, 2, 5, 7, 8, 1, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.0155, -78.4048, -72.6388, -77.1204, -70.1540, -63.2423,
        -69.2921, -75.1371, -78.7891], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.5573, -78.4495, -75.8817, -79.7421, -65.6946,     -inf,
        -66.6699, -70.7811, -82.8705], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.8609, -78.8627, -78.7044, -82.2538,     -inf,     -inf,
        -64.0380, -66.8004, -86.2399], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -79.7733,     -inf, -73.4619,     -inf,     -inf,
            -inf, -84.9566, -72.6012], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -82.1330,     -inf, -74.8404,     -inf,     -inf,
            -inf, -86.2612,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.7686,     -inf,     -inf,     -inf,     -inf,
            -inf, -83.5324,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -74.6762,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 568: Reward=-214.92, route=[0, 6, 5, 7, 1, 3, 9, 4, 2, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.4768, -77.9986, -73.1945, -76.8663, -68.9765, -62.3963,
        -69.1684, -74.6553, -78.6123], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.0741, -71.8737, -76.5125, -73.7442,     -inf,
        -71.6379, -78.6019, -76.6263], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.9044, -78.1026, -82.1123, -65.2424,     -inf,
            -inf, -69.2528, -84.1046], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.3155,     -inf, -73.0477,     -inf,     -inf,
            -inf, -84.6062,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 569: Reward=-250.2, route=[0, 6, 1, 7, 5, 9, 3, 4, 2, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.4768, -77.9986, -73.1945, -76.8663, -68.9765, -62.3963,
        -69.1684, -74.6553, -78.6123], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -73.1259, -80.8795, -78.0523, -82.0864, -65.2120,     -inf,
            -inf, -69.2155, -84.0636], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.4497, -78.5255, -79.4607, -82.2027,     -inf,     -inf,
            -inf, -66.1539, -86.3006], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.7316, -76.4544, -68.7299,     -inf,     -inf,     -inf,
            -inf,     -inf, -73.4807], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.8356, -79.3415,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -72.2672], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.1271,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -76.7532], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.7357,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 570: Reward=-239.67, route=[0, 6, 7, 5, 8, 4, 3, 1, 9, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.4768, -77.9986, -73.1945, -76.8663, -68.9765, -62.3963,
        -69.1684, -74.6553, -78.6123], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.1630, -77.8848, -80.1426, -81.8858,     -inf,     -inf,
        -64.1313, -66.0539, -86.3453], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.9183, -80.3011, -78.8676, -81.8989,     -inf,     -inf,
            -inf, -69.0640, -84.2399], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.3386, -80.0308, -81.9321, -84.2769,     -inf,     -inf,
            -inf,     -inf, -88.1187], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.5661, -72.7850, -76.4179,     -inf,     -inf,
            -inf,     -inf, -76.8575], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.7196,     -inf, -72.7751,     -inf,     -inf,
            -inf,     -inf, -72.2514], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.7191,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 571: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.1506, -77.3513, -73.8769, -76.5474, -67.9400, -61.7033,
        -69.4547, -74.5065, -78.6310], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.7833, -77.4336, -77.2293, -79.2781, -63.4178,     -inf,
        -66.7959, -70.0880, -82.8566], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.1630, -77.8848, -80.1426, -81.8858,     -inf,     -inf,
        -64.1313, -66.0539, -86.3453], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.9183, -80.3011, -78.8676, -81.8989,     -inf,     -inf,
            -inf, -69.0640, -84.2399], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.3386, -80.0308, -81.9321, -84.2769,     -inf,     -inf,
            -inf,     -inf, -88.1187], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.9703, -76.5367,     -inf,     -inf,
            -inf,     -inf, -80.3283], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.7975,     -inf,     -inf,
            -inf,     -inf, -72.2813], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.1205,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 572: Reward=-232.54, route=[0, 6, 5, 7, 8, 1, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.1506, -77.3513, -73.8769, -76.5474, -67.9400, -61.7033,
        -69.4547, -74.5065, -78.6310], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.7833, -77.4336, -77.2293, -79.2781, -63.4178,     -inf,
        -66.7959, -70.0880, -82.8566], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.1630, -77.8848, -80.1426, -81.8858,     -inf,     -inf,
        -64.1313, -66.0539, -86.3453], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.9183, -80.3011, -78.8676, -81.8989,     -inf,     -inf,
            -inf, -69.0640, -84.2399], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.0900, -79.2793, -82.8633, -84.0794,     -inf,     -inf,
            -inf,     -inf, -88.4642], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.8062, -76.2370,     -inf,     -inf,
            -inf,     -inf, -80.5599], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 573: Reward=-232.54, route=[0, 6, 5, 7, 8, 1, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.8140, -76.5602, -74.6936, -76.2389, -67.0392, -60.7373,
        -69.5451, -74.3167, -78.8392], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4909, -76.6598, -78.0969, -79.0195, -62.4832,     -inf,
        -66.8690, -69.8647, -83.1312], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.9082, -77.1290, -81.0532, -81.6721,     -inf,     -inf,
        -64.1888, -65.8016, -86.6759], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.6281, -79.5339, -79.7534, -81.6568,     -inf,     -inf,
            -inf, -68.8247, -84.5275], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.0900, -79.2793, -82.8633, -84.0794,     -inf,     -inf,
            -inf,     -inf, -88.4642], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.7595, -73.5810, -76.0760,     -inf,     -inf,
            -inf,     -inf, -77.0228], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.8862,     -inf, -72.3686,     -inf,     -inf,
            -inf,     -inf, -72.3397], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.2690,     -inf, -73.6639,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 574: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.8140, -76.5602, -74.6936, -76.2389, -67.0392, -60.7373,
        -69.5451, -74.3167, -78.8392], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4909, -76.6598, -78.0969, -79.0195, -62.4832,     -inf,
        -66.8690, -69.8647, -83.1312], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False  True]
greedy_action q_values = tensor([    -inf, -68.6263, -80.1432, -69.9063,     -inf,     -inf,     -inf,
        -76.8475, -85.6502,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.3579,     -inf,     -inf,     -inf,
        -70.2369, -74.2071,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.8002,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 575: Reward=-268.63, route=[0, 6, 5, 4, 9, 1, 2, 7, 8, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -67.3285, -73.8909, -70.4105,     -inf, -73.2093, -64.2426,
        -76.0478, -83.1066, -73.2466], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -71.2899, -75.9092, -78.9313,     -inf, -61.9784,     -inf,
        -67.0800, -70.0357, -83.4568], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.7420, -76.3932, -81.9297,     -inf,     -inf,     -inf,
        -64.3822, -65.9366, -87.0546], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.4301, -78.7897, -80.6056,     -inf,     -inf,     -inf,
            -inf, -68.9859, -84.8652], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.9312, -78.5481, -83.7610,     -inf,     -inf,     -inf,
            -inf,     -inf, -88.8597], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.9832, -74.3450,     -inf,     -inf,     -inf,
            -inf,     -inf, -77.2448], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 576: Reward=-226.0, route=[0, 4, 6, 5, 7, 8, 1, 3, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3976, -76.8092,     -inf, -71.4403, -76.6153, -66.6623,
        -76.4109, -84.6255, -71.9944], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.2781, -75.8964,     -inf, -78.6215, -61.9818,     -inf,
        -67.1122, -70.0895, -83.4271], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.7302, -76.3804,     -inf, -81.3199,     -inf,     -inf,
        -64.4144, -65.9904, -87.0249], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.0727,     -inf,     -inf, -75.6731,     -inf,     -inf,
            -inf, -74.0437, -80.6934], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -75.5124,     -inf,     -inf,
            -inf, -78.5703, -77.1622], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -83.1871, -73.6690], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 577: Reward=-301.88, route=[0, 3, 6, 5, 7, 2, 1, 4, 9, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.4570, -74.9190, -76.4891, -75.9185, -66.3918, -59.5785,
        -70.1352, -74.6699, -79.4744], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.2160, -75.0509, -79.9962, -78.8001, -61.7485,     -inf,
        -67.4187, -70.1292, -83.8926], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.7033, -75.5545, -83.0403, -81.5439,     -inf,     -inf,
        -64.7032, -65.9904, -87.5433], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.3618, -77.9384, -81.6939, -81.4765,     -inf,     -inf,
            -inf, -69.0625, -85.3168], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.8434, -77.7290, -84.8293, -83.9604,     -inf,     -inf,
            -inf,     -inf, -89.2912], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.0876, -75.3371, -75.6935,     -inf,     -inf,
            -inf,     -inf, -77.5804], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.1621,     -inf, -71.8550,     -inf,     -inf,
            -inf,     -inf, -72.7516], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.1906,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -73.9392], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -81.0929], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 578: Reward=-224.8, route=[0, 6, 5, 7, 8, 1, 3, 4, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.4570, -74.9190, -76.4891, -75.9185, -66.3918, -59.5785,
        -70.1352, -74.6699, -79.4744], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.2160, -75.0509, -79.9962, -78.8001, -61.7485,     -inf,
        -67.4187, -70.1292, -83.8926], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.7581,     -inf,     -inf,     -inf,
            -inf, -83.3799, -73.9733], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -84.8754, -72.6408], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 579: Reward=-245.23, route=[0, 6, 5, 1, 7, 2, 4, 3, 9, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False False False False]
greedy_action q_values = tensor([    -inf, -66.8732,     -inf, -71.8033,     -inf, -73.0339, -63.6698,
        -76.5793, -83.0883, -73.4334], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0361,     -inf, -80.5771,     -inf, -61.5763,     -inf,
        -67.4737, -69.7480, -83.9637], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5621,     -inf, -83.6681,     -inf,     -inf,     -inf,
        -64.7423, -65.5709, -87.6741], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.1860,     -inf, -82.2900,     -inf,     -inf,     -inf,
            -inf, -68.6605, -85.3980], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.2226,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -72.5818], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -77.4411], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 580: Reward=-222.09, route=[0, 2, 4, 6, 5, 7, 8, 3, 1, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.8740, -75.3725, -75.2924, -71.1395, -62.7224,
        -72.6715, -78.3667, -77.0387], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.1974, -80.6552, -78.9541, -61.6198,     -inf,
        -67.5305, -69.7968, -84.0319], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.8704, -85.3962, -84.0499,     -inf,     -inf,
        -63.8124,     -inf, -89.3300], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1697, -82.4645, -81.7538,     -inf,     -inf,
            -inf,     -inf, -85.5492], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.2135, -76.0183,     -inf,     -inf,
            -inf,     -inf, -81.2943], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -72.3379,     -inf,     -inf,     -inf,
            -inf,     -inf, -73.9885], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -72.6206], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 581: Reward=-204.69, route=[0, 1, 6, 5, 8, 7, 2, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.2616, -74.0232, -77.0427, -75.9955, -66.2730, -59.3418,
        -70.2312, -74.3420, -79.5037], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.6878,     -inf, -77.8916, -75.7226, -64.2537,     -inf,
        -70.5905, -73.8742, -80.9799], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5057,     -inf, -84.6096, -82.4733,     -inf,     -inf,
        -64.6523, -64.9346, -88.1041], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.0951,     -inf, -83.2050, -82.3684,     -inf,     -inf,
            -inf, -68.0362, -85.7852], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.6519, -76.3892,     -inf,     -inf,
            -inf,     -inf, -77.7938], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -72.7473], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 582: Reward=-220.05, route=[0, 6, 2, 5, 7, 8, 1, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.0708, -73.4527, -77.8176, -76.6349, -66.3846, -59.3608,
        -70.1415, -73.7586, -79.7503], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -66.7704, -71.5302, -72.6813,     -inf, -73.2443,     -inf,
        -76.6422, -82.6446, -73.7972], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.3930, -76.2740,     -inf, -71.3096,     -inf,
        -72.6746, -77.8467, -77.4282], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.1312, -84.5580,     -inf,     -inf,     -inf,
        -64.6556, -64.9277, -88.0564], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 583: Reward=-255.54, route=[0, 6, 4, 1, 5, 7, 8, 9, 3, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.0708, -73.4527, -77.8176, -76.6349, -66.3846, -59.3608,
        -70.1415, -73.7586, -79.7503], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9229, -73.6154, -81.4349, -79.6173, -61.6563,     -inf,
        -67.3922, -69.1289, -84.3077], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.1391, -75.6569,     -inf,     -inf,     -inf,     -inf,
            -inf, -67.0673, -86.0153], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.5259, -75.4952,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -89.8284], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.7038,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -77.9025], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -81.7726], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 584: Reward=-290.78, route=[0, 6, 5, 3, 4, 7, 8, 1, 2, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -66.6128, -73.4902,     -inf, -72.6108, -76.5438, -65.9077,
        -76.5505, -83.2900, -72.4179], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0195, -72.7909,     -inf, -80.3411, -61.4102,     -inf,
        -67.0388, -68.2371, -84.6125], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5686, -73.3483,     -inf, -83.1841,     -inf,     -inf,
        -64.3329, -64.0712, -88.3500], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.7384,     -inf,     -inf, -77.2139,     -inf,     -inf,
        -70.2104,     -inf, -81.6801], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.9410,     -inf,     -inf,
        -72.3915,     -inf, -77.8765], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -83.2503,     -inf,     -inf,
            -inf,     -inf, -86.2249], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -74.2932], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 585: Reward=-287.59, route=[0, 3, 6, 5, 8, 2, 1, 7, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.1807, -72.6766, -78.7906, -77.4047, -66.1828, -59.0497,
        -69.7937, -72.8789, -80.0809], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -67.4882, -76.0496, -73.5784, -74.1949, -79.0720,     -inf,
        -77.2777, -84.6152,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.6306, -77.2273, -76.7818, -71.2216,     -inf,
        -72.4150, -77.0834,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.4085, -85.5840, -83.2417,     -inf,     -inf,
        -64.4154, -64.1468,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.8378, -77.2680,     -inf,     -inf,
        -70.2976,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -73.6618,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 586: Reward=-283.32, route=[0, 6, 9, 1, 5, 8, 2, 7, 4, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.7780, -71.0966, -78.6489, -77.2507, -66.4360, -58.8973,
        -69.0910, -72.2977, -79.1174], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.7311, -71.2837, -82.3898, -80.3407, -61.6308,     -inf,
        -66.3171, -67.5854, -83.8196], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -66.4139, -72.0793,     -inf, -72.7092,     -inf,     -inf,
            -inf, -82.7862, -71.7448], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.0621,     -inf, -76.7355,     -inf,     -inf,
            -inf, -76.4175, -76.8386], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -73.2221], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 587: Reward=-282.89, route=[0, 6, 5, 7, 3, 1, 2, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.2826, -73.1213, -73.7649, -79.4266, -67.6903,
        -76.4986, -84.0766,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.0895,     -inf, -82.9131, -62.4118,     -inf,
            -inf, -66.5196,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.8335,     -inf, -83.2126,     -inf,     -inf,
            -inf, -63.4084,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.2060,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 588: Reward=-267.66, route=[0, 1, 9, 6, 3, 7, 5, 8, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -65.6974, -67.5039, -72.4719,     -inf, -74.0158, -63.6395,
        -75.1197, -81.0732, -71.7606], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -70.3376, -69.7947, -81.8184,     -inf, -62.1498,     -inf,
        -65.8078, -67.2301, -82.9719], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.0322, -70.3662, -85.1138,     -inf,     -inf,     -inf,
        -63.0301, -62.9088, -86.9195], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -66.5593, -72.9752, -72.6711,     -inf,     -inf,     -inf,
        -76.1106,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.6227, -76.5019,     -inf,     -inf,     -inf,
        -71.2340,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.6287,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 589: Reward=-255.25, route=[0, 4, 6, 5, 8, 9, 1, 7, 3, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.3799, -69.6476, -78.0766, -76.8262, -67.0110, -59.1503,
        -68.6214, -72.0138, -78.2532], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False  True]
greedy_action q_values = tensor([    -inf, -66.4020, -72.8596, -72.4996,     -inf, -80.0975,     -inf,
        -76.0872, -83.8695,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.5071, -76.3304,     -inf, -72.1202,     -inf,
        -71.2105, -76.2386,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.6498, -83.4827,     -inf, -62.9500,     -inf,
            -inf, -66.1192,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.4024, -85.2118,     -inf,     -inf,     -inf,
            -inf, -62.9159,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.5626, -86.7913,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.2266,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 590: Reward=-249.01, route=[0, 6, 4, 9, 1, 7, 5, 8, 2, 3] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.3080,     -inf, -77.9926, -75.5556, -65.5987,     -inf,
        -68.4008, -71.2293, -78.5241], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5842,     -inf, -84.2783, -82.0252,     -inf,     -inf,
        -62.3970, -62.5410, -85.7829], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.0035,     -inf, -82.6610, -81.7760,     -inf,     -inf,
            -inf, -65.7018, -83.1923], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.6987,     -inf, -86.0663, -84.5184,     -inf,     -inf,
            -inf,     -inf, -87.4800], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -75.6326, -75.3600,     -inf,     -inf,
            -inf,     -inf, -74.6501], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.6771, -72.4809,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.0489,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 591: Reward=-198.64, route=[0, 6, 2, 5, 7, 8, 1, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -70.0883, -75.3168, -75.0625, -72.7783,     -inf,
        -70.5335, -75.8865, -74.3446], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.0403, -75.5771, -65.6354,     -inf,
        -68.4359, -71.2724, -78.5587], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -84.3260, -82.0468,     -inf,     -inf,
        -62.4321, -62.5841, -85.8175], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.5800, -72.3798,     -inf,     -inf,
            -inf, -83.6450,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.9478,     -inf,     -inf,
            -inf, -82.4712,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -80.9673,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 592: Reward=-266.23, route=[0, 6, 1, 2, 5, 7, 9, 3, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.7695, -68.1800, -77.0052, -75.7611, -67.6746, -59.1768,
        -67.9796, -71.6793, -76.8830], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.8304, -68.3778, -80.8894, -78.9739, -62.7856,     -inf,
        -65.1806, -66.8779, -81.7450], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5698, -68.9554, -84.2436, -82.0076,     -inf,     -inf,
        -62.3926, -62.5201, -85.7575], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -64.5010, -68.1348,     -inf, -69.5319,     -inf,     -inf,
            -inf, -82.6857,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.1425,     -inf, -73.7602,     -inf,     -inf,
            -inf, -76.1522,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.3600,     -inf,     -inf,
            -inf, -71.4899,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 593: Reward=-251.92, route=[0, 6, 5, 7, 9, 3, 1, 2, 8, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -73.3759, -73.5843, -74.2393, -63.1178,
        -70.0084, -76.0657, -72.3963], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.8755,     -inf, -76.3124,     -inf,
        -74.2618, -81.1896, -68.8837], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.4456,     -inf, -82.5065,     -inf,
        -75.0817, -83.9747,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -62.0189, -62.7499,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -65.9456,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 594: Reward=-263.81, route=[0, 2, 1, 6, 4, 9, 3, 5, 7, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1908, -67.2504, -75.3456, -74.5129, -69.1012, -59.6060,
        -67.5551, -71.8585, -75.2517], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -70.3185, -81.0019, -80.5229, -64.9331,     -inf,
            -inf, -65.7989, -81.5470], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.9124, -73.2232,     -inf,     -inf,
            -inf, -71.3919,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.1558, -82.2877,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 595: Reward=-309.05, route=[0, 6, 1, 7, 5, 9, 2, 8, 4, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.7598, -66.3923, -73.6805, -73.2554, -70.1011, -60.0542,
        -67.1757, -71.7992, -74.0303], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.9336, -66.5920, -77.7255, -76.5948, -65.1176,     -inf,
        -64.3427, -66.8946, -79.0612], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -70.0075, -69.4384, -79.3476, -79.3035, -65.8711,     -inf,
            -inf, -65.6358, -80.3580], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.9551, -69.2979, -83.0750, -82.2615, -60.8650,     -inf,
            -inf,     -inf, -85.0238], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.8935, -67.2832, -81.4100, -79.9415,     -inf,     -inf,
            -inf,     -inf, -83.3950], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -64.1215,     -inf,     -inf, -68.3646,     -inf,     -inf,
            -inf,     -inf, -66.1360], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.7828], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 596: Reward=-234.97, route=[0, 6, 7, 8, 5, 2, 3, 1, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -70.5781, -67.0401, -80.9782, -79.5452,     -inf, -54.2743,
        -61.4186, -62.3921, -82.9513], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.0115, -66.6291, -77.7971, -76.6603,     -inf,     -inf,
        -64.3728, -66.9397, -79.1451], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.0854, -69.4755, -79.4192, -79.3691,     -inf,     -inf,
            -inf, -65.6808, -80.4419], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.0331, -69.3350, -83.1465, -82.3270,     -inf,     -inf,
            -inf,     -inf, -85.1077], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -72.1299, -72.7287,     -inf,     -inf,
            -inf,     -inf, -71.6206], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -67.9205, -69.6620,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -67.9652,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 597: Reward=-214.87, route=[0, 5, 6, 7, 8, 2, 1, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1475, -66.4233, -72.7138, -72.9834, -70.7838, -60.4706,
        -66.7999, -71.4671, -73.8087], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.3632, -66.6124, -76.8285, -76.3700, -65.7558,     -inf,
        -63.9470, -66.5161, -78.9100], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -70.4421, -69.4685, -78.4378, -79.0857, -66.5240,     -inf,
            -inf, -65.2439, -80.2002], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.8925,     -inf, -74.0246, -73.0528, -68.5791,     -inf,
            -inf,     -inf, -75.7664], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -66.7689, -69.2985, -84.3511,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -78.1109,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 598: Reward=-232.28, route=[0, 6, 7, 8, 2, 1, 9, 3, 4, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1475, -66.4233, -72.7138, -72.9834, -70.7838, -60.4706,
        -66.7999, -71.4671, -73.8087], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.3632, -66.6124, -76.8285, -76.3700, -65.7558,     -inf,
        -63.9470, -66.5161, -78.9100], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -70.4421, -69.4685, -78.4378, -79.0857, -66.5240,     -inf,
            -inf, -65.2439, -80.2002], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.4278, -69.3162, -82.2325, -82.0868, -61.4750,     -inf,
            -inf,     -inf, -84.9319], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.3563, -67.2961, -80.5663, -79.7548,     -inf,     -inf,
            -inf,     -inf, -83.2966], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.9710,     -inf, -74.0960, -73.1184,     -inf,     -inf,
            -inf,     -inf, -75.8506], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -66.8382, -69.3618,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 599: Reward=-197.15, route=[0, 6, 7, 8, 5, 2, 1, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1475, -66.4233, -72.7138, -72.9834, -70.7838, -60.4706,
        -66.7999, -71.4671, -73.8087], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.9537, -66.9084, -76.0825, -76.2566, -65.7146,     -inf,
        -63.3647, -65.5742, -78.9501], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.0401, -69.7801, -77.6821, -78.9817, -66.4877,     -inf,
            -inf, -64.2802, -80.2367], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.0620, -69.6198, -81.5477, -82.0238, -61.4024,     -inf,
            -inf,     -inf, -85.0313], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.9811, -67.5896, -79.8787, -79.6808,     -inf,     -inf,
            -inf,     -inf, -83.3893], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -64.9199,     -inf,     -inf, -67.7458,     -inf,     -inf,
            -inf,     -inf, -65.6217], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.1226,     -inf,     -inf,
            -inf,     -inf, -71.1520], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 600: Reward=-213.56, route=[0, 6, 7, 8, 5, 2, 3, 1, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -65.1034, -69.8265, -65.2939, -68.6401, -84.4019, -69.6487,
        -73.6333, -82.7274,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -72.7778, -72.4470, -68.7070, -59.0166,
        -66.6691, -70.1596,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.0844, -76.2111, -65.8326,     -inf,
        -63.4650, -65.7180,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.6840, -78.9362, -66.6057,     -inf,
            -inf, -64.4240,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -67.6108, -81.8929,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -78.1681,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 601: Reward=-263.49, route=[0, 9, 1, 2, 6, 7, 8, 3, 4, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.6957, -66.7255, -71.8935, -72.8223, -70.7825, -60.4116,
        -66.2334, -70.5650, -73.7799], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.7687, -69.4686, -72.2052, -76.1325,     -inf,
        -68.7509,     -inf, -71.5163], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.1832, -65.0836, -69.1010, -84.5531,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.7582,     -inf, -67.6963, -81.9791,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -65.7709,     -inf,     -inf, -78.2263,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -68.6435,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 602: Reward=-224.72, route=[0, 6, 8, 1, 7, 9, 3, 4, 2, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.8742, -67.7238, -71.4362, -73.0132, -70.7815, -60.5003,
        -66.1739, -69.9260, -74.3023], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1643, -67.8880, -75.6912, -76.4850, -65.6739,     -inf,
        -63.2884, -64.8935, -79.5371], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -72.2646, -70.7828, -77.2846, -79.2227, -66.4506,     -inf,
            -inf, -63.5801, -80.8275], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.2754, -70.6003, -81.1984, -82.2535, -61.3258,     -inf,
            -inf,     -inf, -85.6577], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.7341,     -inf, -72.8808, -73.1684,     -inf,     -inf,
            -inf,     -inf, -76.4061], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.6827, -72.3977,     -inf,     -inf,
            -inf,     -inf, -71.7371], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.7842], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 603: Reward=-225.92, route=[0, 6, 7, 8, 5, 2, 1, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.8742, -67.7238, -71.4362, -73.0132, -70.7815, -60.5003,
        -66.1739, -69.9260, -74.3023], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1643, -67.8880, -75.6912, -76.4850, -65.6739,     -inf,
        -63.2884, -64.8935, -79.5371], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -72.2646, -70.7828, -77.2846, -79.2227, -66.4506,     -inf,
            -inf, -63.5801, -80.8275], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.2754, -70.6003, -81.1984, -82.2535, -61.3258,     -inf,
            -inf,     -inf, -85.6577], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.2182, -68.5569, -79.5394, -79.9408,     -inf,     -inf,
            -inf,     -inf, -84.0266], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.3348,     -inf, -72.9621, -73.6876,     -inf,     -inf,
            -inf,     -inf, -77.4525], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.6912, -72.9035,     -inf,     -inf,
            -inf,     -inf, -72.7317], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.3246,     -inf,     -inf,
            -inf,     -inf, -66.9621], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.5214,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 604: Reward=-208.9, route=[0, 6, 7, 8, 5, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.4616, -68.6843, -71.4918, -73.5281, -70.4545, -60.7822,
        -66.0946, -69.0350, -75.3243], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.4147, -72.6263, -75.8449,     -inf,
        -68.6977, -73.4298, -72.4529], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -77.4703, -79.8094, -66.1271,     -inf,
            -inf, -62.6879, -81.9635], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -65.7506,     -inf, -77.8995,     -inf,
            -inf,     -inf, -68.7258], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -84.3234,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 605: Reward=-254.52, route=[0, 6, 2, 1, 7, 8, 4, 3, 9, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.4616, -68.6843, -71.4918, -73.5281, -70.4545, -60.7822,
        -66.0946, -69.0350, -75.3243], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1182,     -inf, -72.6856, -73.4104, -68.2848,     -inf,
        -66.5553, -68.5711, -77.1737], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -73.9043,     -inf, -77.4292, -79.7926, -66.0847,     -inf,
            -inf, -62.6412, -81.9349], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.8867,     -inf, -81.3794, -82.7921, -60.9203,     -inf,
            -inf,     -inf, -86.7853], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.8603,     -inf, -79.7314, -80.5195,     -inf,     -inf,
            -inf,     -inf, -85.1678], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.6912, -72.9035,     -inf,     -inf,
            -inf,     -inf, -72.7317], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.1467,     -inf,     -inf,
            -inf,     -inf, -68.3447], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.3502,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 606: Reward=-216.73, route=[0, 6, 2, 7, 8, 5, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -68.8494, -70.9589,     -inf, -68.6443, -81.2009, -68.4880,
        -73.3053, -79.6521, -67.7476], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False  True  True]
greedy_action q_values = tensor([    -inf, -77.1848, -72.5775,     -inf, -83.1330, -60.4488, -55.1619,
        -59.2995,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -72.9314,     -inf,     -inf, -74.3557,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.5673,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 607: Reward=-261.94, route=[0, 3, 9, 8, 6, 5, 7, 2, 1, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.1484, -70.0256, -72.1474, -74.3816, -69.9286, -60.9429,
        -66.2445, -68.3981, -76.7777], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.4818, -70.1390, -76.5119, -77.9056, -64.7370,     -inf,
        -63.3170, -63.2727, -82.1196], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -77.4376, -72.8149, -81.8824, -83.4784, -60.4768,     -inf,
        -59.3831,     -inf, -88.0698], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.6961, -73.1523, -78.2009, -80.7720, -65.5031,     -inf,
            -inf,     -inf, -83.5104], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.5331,     -inf, -66.3788,     -inf,     -inf,     -inf,
            -inf,     -inf, -70.1834], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.2273,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -68.2492], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -69.7963,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 608: Reward=-180.97, route=[0, 6, 8, 7, 5, 2, 4, 3, 9, 1] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.5705, -71.5084, -73.2129, -75.2605, -68.8232, -60.7084,
        -66.4207, -67.6613, -78.4755], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.9267, -71.6010, -77.6289, -78.8164, -63.5914,     -inf,
        -63.4733, -62.4913, -83.8712], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -78.6718, -74.3158, -82.8033, -84.2481, -59.5705,     -inf,
        -59.7428,     -inf, -89.5596], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -77.8667, -72.1888, -81.4214, -82.1142,     -inf,     -inf,
        -60.6873,     -inf, -88.2739], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.3584, -74.6285,     -inf,     -inf,
            -inf,     -inf, -75.8503], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 609: Reward=-228.94, route=[0, 6, 8, 5, 7, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.5705, -71.5084, -73.2129, -75.2605, -68.8232, -60.7084,
        -66.4207, -67.6613, -78.4755], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.9267, -71.6010, -77.6289, -78.8164, -63.5914,     -inf,
        -63.4733, -62.4913, -83.8712], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -78.6718, -74.3158, -82.8033, -84.2481, -59.5705,     -inf,
        -59.7428,     -inf, -89.5596], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -77.8667, -72.1888, -81.4214, -82.1142,     -inf,     -inf,
        -60.6873,     -inf, -88.2739], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -77.2425, -74.6864, -79.4060, -81.7726,     -inf,     -inf,
            -inf,     -inf, -85.3713], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.4666,     -inf, -74.7263, -75.4270,     -inf,     -inf,
            -inf,     -inf, -80.6486], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.3584, -74.6285,     -inf,     -inf,
            -inf,     -inf, -75.8503], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.9785,     -inf,     -inf,
            -inf,     -inf, -69.9697], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.1895,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 610: Reward=-228.94, route=[0, 6, 8, 5, 7, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.5705, -71.5084, -73.2129, -75.2605, -68.8232, -60.7084,
        -66.4207, -67.6613, -78.4755], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.9267, -71.6010, -77.6289, -78.8164, -63.5914,     -inf,
        -63.4733, -62.4913, -83.8712], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -79.7332, -75.8219, -83.7375, -85.0357, -58.9356,     -inf,
        -60.2304,     -inf, -90.9686], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -78.9214, -73.6811, -82.3470, -82.8960,     -inf,     -inf,
        -61.1668,     -inf, -89.6853], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -78.3945, -76.2048, -80.4252, -82.6180,     -inf,     -inf,
            -inf,     -inf, -86.9103], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.5957,     -inf, -75.7040, -76.2267,     -inf,     -inf,
            -inf,     -inf, -82.1398], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -73.1417], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 611: Reward=-245.96, route=[0, 6, 8, 5, 7, 2, 1, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.6857, -73.0134, -74.1676, -76.0548, -68.1024, -61.0120,
        -66.8580, -67.6698, -79.9408], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -77.0665, -73.0864, -78.6364, -79.6421, -62.8269,     -inf,
        -63.8847, -62.4488, -85.3940], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -72.2858, -76.8508, -67.2180, -71.8372, -82.2388,     -inf,
        -74.6849,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -71.5938, -74.2716,     -inf, -70.4272, -79.6222,     -inf,
        -74.1898,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False  True  True]
greedy_action q_values = tensor([    -inf, -71.7729, -71.1185,     -inf,     -inf, -75.8050,     -inf,
        -73.9306,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True False  True  True]
greedy_action q_values = tensor([    -inf, -75.2870,     -inf,     -inf,     -inf, -65.9477,     -inf,
        -67.3556,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -78.7939,     -inf,     -inf,     -inf,     -inf,     -inf,
        -61.1914,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 612: Reward=-220.08, route=[0, 6, 8, 9, 3, 4, 2, 5, 7, 1] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.6857, -73.0134, -74.1676, -76.0548, -68.1024, -61.0120,
        -66.8580, -67.6698, -79.9408], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -77.0665, -73.0864, -78.6364, -79.6421, -62.8269,     -inf,
        -63.8847, -62.4488, -85.3940], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -75.4500,     -inf, -75.5102, -76.0392, -65.8943,     -inf,
        -67.3150,     -inf, -81.9273], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -79.3722,     -inf, -82.8755, -83.2323,     -inf,     -inf,
        -61.7287,     -inf, -90.6495], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.1044,     -inf,     -inf, -70.8690,     -inf,     -inf,
            -inf,     -inf, -72.0537], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.3042,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -73.8798], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 613: Reward=-253.95, route=[0, 6, 8, 2, 5, 7, 3, 4, 1, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.0526, -74.3962, -74.5612, -76.2802, -67.6359, -61.3237,
        -67.5011, -68.3170, -80.7724], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.9128,     -inf, -83.0513,     -inf,     -inf,
        -61.7547, -58.6122, -90.4975], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1950,     -inf, -85.3580,     -inf,     -inf,
        -60.8501,     -inf, -91.9530], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.5551,     -inf, -82.7917,     -inf,     -inf,
            -inf,     -inf, -87.7183], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 614: Reward=-266.29, route=[0, 6, 3, 1, 5, 8, 7, 2, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -75.0526, -74.3962, -74.5612, -76.2802, -67.6359, -61.3237,
        -67.5011, -68.3170, -80.7724], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -77.4603, -74.4496, -79.0889, -79.9033, -62.3185,     -inf,
        -64.5004, -63.0446, -86.2863], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -79.2933, -74.9536, -82.7690, -83.1312,     -inf,     -inf,
        -61.7236, -58.5440, -90.5624], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -80.2586, -77.2367, -84.3166, -85.4347,     -inf,     -inf,
        -60.8167,     -inf, -92.0113], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -78.7862, -77.5974, -80.8783, -82.8872,     -inf,     -inf,
            -inf,     -inf, -87.8060], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.8794,     -inf,     -inf, -70.6989,     -inf,     -inf,
            -inf,     -inf, -72.2845], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.1086,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -74.1552], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.1910], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 615: Reward=-225.0, route=[0, 6, 5, 8, 7, 2, 3, 4, 1, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.8824, -75.0191, -74.8173, -76.1809, -66.7238, -61.4790,
        -67.8824, -69.1559, -81.1148], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -77.3181, -75.0530, -79.4039, -79.8401, -61.3698,     -inf,
        -64.8594, -63.8373, -86.6909], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -79.2199, -75.5397, -83.1533, -83.1476,     -inf,     -inf,
        -62.0093, -59.2669, -91.0415], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -80.1822, -77.8308, -84.6926, -85.4527,     -inf,     -inf,
        -61.0889,     -inf, -92.4814], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -78.6336, -78.2176, -81.1907, -82.8258,     -inf,     -inf,
            -inf,     -inf, -88.2055], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.8326,     -inf, -76.4151, -76.3783,     -inf,     -inf,
            -inf,     -inf, -83.3809], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -72.8475, -75.4892,     -inf,     -inf,
            -inf,     -inf, -78.3800], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.7151,     -inf,     -inf,
            -inf,     -inf, -72.3128], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -74.1834], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 616: Reward=-227.7, route=[0, 6, 5, 8, 7, 2, 1, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.8824, -75.0191, -74.8173, -76.1809, -66.7238, -61.4790,
        -67.8824, -69.1559, -81.1148], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -77.3181, -75.0530, -79.4039, -79.8401, -61.3698,     -inf,
        -64.8594, -63.8373, -86.6909], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.6922,     -inf, -76.2041, -76.1634,     -inf,     -inf,
        -68.3786, -68.7024, -83.1806], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -78.5649,     -inf, -81.1278, -82.7399,     -inf,     -inf,
            -inf, -62.5289, -88.1470], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.3492,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 617: Reward=-219.63, route=[0, 6, 5, 2, 7, 8, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.0412, -75.5054, -74.7855, -75.7258, -66.0864, -61.7167,
        -68.7046, -70.8157, -80.8637], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -76.5099, -75.5249, -79.4385, -79.4313, -60.6913,     -inf,
        -65.6548, -65.4453, -86.5122], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.1636, -73.7480, -68.4518,     -inf,     -inf,     -inf,
        -75.9045, -81.0238, -73.7268], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.7538, -76.8631,     -inf,     -inf,     -inf,     -inf,
        -76.1844, -82.6926, -71.6043], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.6925,     -inf,     -inf,     -inf,     -inf,
        -71.4782, -75.5225, -77.6521], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.5275,     -inf,     -inf,     -inf,     -inf,
            -inf, -64.1955, -87.7703], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.2259,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -92.5387], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.0073], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 618: Reward=-250.71, route=[0, 6, 5, 4, 3, 1, 7, 8, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.0412, -75.5054, -74.7855, -75.7258, -66.0864, -61.7167,
        -68.7046, -70.8157, -80.8637], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -76.5099, -75.5249, -79.4385, -79.4313, -60.6913,     -inf,
        -65.6548, -65.4453, -86.5122], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -71.4238, -79.5456, -67.4316, -71.2252,     -inf,     -inf,
        -76.8012, -84.0353,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -70.7808, -76.8914,     -inf, -69.8403,     -inf,     -inf,
        -76.2731, -82.7990,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf, -71.0530, -73.6522,     -inf,     -inf,     -inf,     -inf,
        -75.9742, -81.1444,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.6639,     -inf,     -inf,     -inf,     -inf,
        -71.5370, -75.6008,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.4989,     -inf,     -inf,     -inf,     -inf,
            -inf, -64.2738,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.1989,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 619: Reward=-230.68, route=[0, 6, 5, 9, 3, 4, 1, 7, 8, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.0412, -75.5054, -74.7855, -75.7258, -66.0864, -61.7167,
        -68.7046, -70.8157, -80.8637], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.7558, -75.9570, -79.5235, -79.1390, -60.0896,     -inf,
        -66.1770, -66.7732, -86.2520], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -77.8347, -76.4082, -83.5291, -82.6156,     -inf,     -inf,
        -63.1666, -61.9265, -90.9174], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -70.6098, -80.1161, -67.3942, -70.8646,     -inf,     -inf,
        -77.4317,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.3017,     -inf, -74.3943,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.2551,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 620: Reward=-225.02, route=[0, 6, 5, 8, 9, 3, 7, 1, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False  True False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True False  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.2560, -83.3606,     -inf,     -inf, -55.4541,
            -inf, -61.7938, -90.6992], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.4061,     -inf,     -inf,     -inf,     -inf,
            -inf, -84.1522, -71.2717], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -71.7648,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 621: Reward=-267.12, route=[0, 4, 1, 7, 5, 6, 3, 9, 2, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.2535, -75.9494, -74.8034, -75.3838, -65.5253, -61.9930,
        -69.2585, -72.1964, -80.5280], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.7558, -75.9570, -79.5235, -79.1390, -60.0896,     -inf,
        -66.1770, -66.7732, -86.2520], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.9663, -72.0963, -73.6126,     -inf,     -inf,
        -72.3286, -78.1539, -76.5238], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1181,     -inf, -68.6726,     -inf,     -inf,
        -77.1699, -85.5445, -70.2311], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -70.0066, -72.9340, -81.7233], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -86.8412,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 622: Reward=-260.17, route=[0, 6, 5, 1, 3, 4, 2, 7, 9, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.7664, -71.7704, -73.3403, -70.3215, -65.8831,
        -72.1758, -78.0381, -76.1481], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.6425, -79.3076, -78.4847, -59.3221,     -inf,
        -66.4121, -67.9288, -85.5188], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.0891, -83.3704, -82.0083,     -inf,     -inf,
        -63.3741, -63.0410, -90.2502], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.3667, -85.1928, -84.5770,     -inf,     -inf,
        -62.1528,     -inf, -92.0400], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.8330, -81.0635, -81.4568,     -inf,     -inf,
            -inf,     -inf, -86.9742], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.2324, -74.9395,     -inf,     -inf,
            -inf,     -inf, -82.1186], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -68.3027,     -inf,     -inf,     -inf,
            -inf,     -inf, -72.6621], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 623: Reward=-204.69, route=[0, 1, 6, 5, 8, 7, 2, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.9862, -75.6218, -74.4804, -74.6639, -64.7486, -61.8982,
        -69.4786, -73.3396, -79.6943], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -68.9632, -73.8577, -67.9302,     -inf, -72.6096,     -inf,
        -76.7657, -83.6741, -72.3098], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf, -68.4487, -76.9906,     -inf,     -inf, -76.5147,     -inf,
        -77.0605, -85.4085, -70.0407], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.7948,     -inf,     -inf, -70.3374,     -inf,
        -72.2729, -78.1157, -76.2348], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.7556,     -inf,     -inf,     -inf,     -inf,
        -61.9804,     -inf, -91.3694], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.2396,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.1651], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -81.2984], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 624: Reward=-256.39, route=[0, 6, 4, 3, 1, 5, 8, 7, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.7983, -75.1651, -74.4683, -74.4856, -63.7883, -61.4078,
        -69.4085, -73.8906, -79.0359], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.3720, -75.1520, -79.3216, -78.3381, -58.2860,     -inf,
        -66.2806, -68.3890, -84.9056], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.5078, -75.5935, -83.4352, -81.8999,     -inf,     -inf,
        -63.2271, -63.4734, -89.6916], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -67.4146, -76.7070,     -inf, -68.5413,     -inf,     -inf,
            -inf, -85.9892, -69.5583], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.4867,     -inf, -73.3977,     -inf,     -inf,
            -inf, -78.6823, -75.7892], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.4732,     -inf,     -inf,     -inf,     -inf,
            -inf, -84.2965, -71.7326], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.2333,     -inf,     -inf,     -inf,     -inf,
            -inf, -87.4683,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 625: Reward=-273.66, route=[0, 6, 5, 7, 3, 1, 4, 9, 2, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.7983, -75.1651, -74.4683, -74.4856, -63.7883, -61.4078,
        -69.4085, -73.8906, -79.0359], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.4032,     -inf, -73.2101, -69.4089,     -inf,
        -72.2462, -78.7351, -75.5748], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.5491,     -inf, -81.7938,     -inf,     -inf,
        -63.2816, -63.5728, -89.5901], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.2244,     -inf, -81.1139,     -inf,     -inf,
            -inf, -67.1845, -86.1656], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.8566,     -inf, -84.5036,     -inf,     -inf,
            -inf,     -inf, -91.5305], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -71.1452], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 626: Reward=-252.61, route=[0, 6, 3, 1, 5, 7, 8, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -66.4509, -79.2587, -66.2450, -69.4722, -77.9273, -71.5664,
        -78.0090, -88.2928,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -65.9956, -76.5966,     -inf, -68.1801, -75.2887, -69.5230,
        -77.4494, -86.9253,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -71.3970, -66.7114,
        -77.1806, -85.2263,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -57.9587,     -inf,
        -66.7800, -69.3334,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -63.7139, -64.3897,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 627: Reward=-215.05, route=[0, 9, 3, 1, 2, 4, 6, 5, 7, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.8210, -75.2803, -74.5060, -74.6552, -63.3685, -61.2894,
        -69.8315, -74.6921, -78.3982], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.4281, -75.2534, -79.4195, -78.5451, -57.8352,     -inf,
        -66.6876, -69.1537, -84.3338], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.5895, -75.6870, -83.5808, -82.1386,     -inf,     -inf,
        -63.6215, -64.2099, -89.1705], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.7211, -68.1056,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.8725,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 628: Reward=-267.49, route=[0, 6, 5, 7, 9, 8, 1, 4, 3, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -65.1696, -79.4641, -65.8631, -69.4083, -77.7133, -71.1023,
        -78.2731, -89.2403,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.5963, -71.2906, -73.1461, -68.8109, -64.8746,
        -72.8588, -80.4443,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.7591, -83.3096,     -inf,     -inf,     -inf,
        -63.8916, -65.1118,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.4705, -80.7459,     -inf,     -inf,     -inf,
            -inf, -68.7824,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 629: Reward=-277.79, route=[0, 9, 1, 6, 4, 5, 7, 8, 3, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.6441, -75.4372, -74.2584, -74.6519, -63.0955, -60.7838,
        -70.0579, -75.5452, -77.7237], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.2854, -75.3986, -79.2342, -78.5774, -57.5337,     -inf,
        -66.8974, -69.9722, -83.7235], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.8288, -71.7107, -73.5135,     -inf,     -inf,
        -72.9600, -80.4934, -74.3390], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.0432,     -inf, -68.4944,     -inf,     -inf,
        -77.8623, -87.9709, -67.9023], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.6200,     -inf, -69.5716,     -inf,     -inf,
        -78.4902, -89.4731,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.9356,     -inf,     -inf,     -inf,     -inf,
        -62.6400,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.4748,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 630: Reward=-239.94, route=[0, 6, 5, 1, 3, 9, 4, 8, 7, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.2854, -75.3986, -79.2342, -78.5774, -57.5337,     -inf,
        -66.8974, -69.9722, -83.7235], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.7891, -75.7955, -83.5696, -82.6657,     -inf,     -inf,
        -63.5840, -65.2469, -88.5792], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.6515, -78.5229, -80.9552, -81.9250,     -inf,     -inf,
            -inf, -68.9330, -84.9609], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -64.7613, -79.8103, -66.2976, -70.2695,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.9090, -67.7561,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 631: Reward=-229.52, route=[0, 6, 5, 7, 8, 9, 1, 4, 3, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9028, -75.4253, -74.2762, -75.0611, -62.6243, -59.9136,
        -69.8496, -75.8373, -77.5929], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.8203, -83.6046, -82.6771,     -inf,     -inf,
        -63.6298, -65.3086, -88.6000], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.5478, -80.9902, -81.9364,     -inf,     -inf,
            -inf, -68.9946, -84.9817], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.0687, -85.5336, -85.3303,     -inf,     -inf,
            -inf,     -inf, -90.6531], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.1502, -75.3817,     -inf,     -inf,
            -inf,     -inf, -80.1542], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -67.8915,     -inf,     -inf,     -inf,
            -inf,     -inf, -70.3389], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.8285], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 632: Reward=-229.35, route=[0, 6, 1, 5, 7, 8, 2, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -71.3626, -78.3209, -80.6242, -81.6483, -57.7490, -56.8385,
            -inf, -68.8015, -84.5859], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -70.6354, -75.4139, -79.4327, -79.1351, -56.9734,     -inf,
            -inf, -70.1353, -83.7715], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -63.9983,     -inf,     -inf, -69.5780,     -inf,     -inf,
            -inf, -88.0566, -67.5910], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.5056,     -inf,     -inf,
            -inf, -80.6588, -73.9806], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.6653,     -inf,     -inf,
            -inf, -89.6392,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 633: Reward=-259.24, route=[0, 7, 6, 5, 2, 3, 1, 9, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.5909, -75.6882, -74.1296, -75.6713, -62.5311, -59.0121,
        -69.4756, -75.6827, -77.4745], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.2919, -75.6237, -79.2272, -79.6525, -56.9175,     -inf,
        -66.2895, -70.0614, -83.5850], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5275, -76.0376, -83.5379, -83.3282,     -inf,     -inf,
        -63.1869, -65.0520, -88.5594], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.3567, -78.7865, -80.8670, -82.5796,     -inf,     -inf,
            -inf, -68.7466, -84.8865], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.8862, -78.2710, -85.4263, -85.9507,     -inf,     -inf,
            -inf,     -inf, -90.6131], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.2337, -71.6801, -74.7210,     -inf,     -inf,
            -inf,     -inf, -74.1723], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.4787,     -inf, -69.6465,     -inf,     -inf,
            -inf,     -inf, -67.6341], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.0810,     -inf, -70.7346,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.1256,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 634: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
greedy_action q_values = tensor([    -inf, -64.2311, -73.8228,     -inf,     -inf, -70.5450, -64.4748,
        -76.8362, -86.2177, -69.4357], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.7843,     -inf,     -inf, -68.2212, -63.0452,
        -72.2125, -80.5677, -73.3943], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.5164,     -inf,     -inf, -56.9664,     -inf,
        -66.3200, -70.1409, -83.3948], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.9194,     -inf,     -inf,     -inf,     -inf,
        -76.9856, -88.2849,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.0464,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 635: Reward=-267.08, route=[0, 3, 4, 1, 6, 5, 9, 7, 8, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True False False False False]
greedy_action q_values = tensor([    -inf, -64.1370, -73.9206, -66.9078,     -inf,     -inf, -63.2389,
        -75.9800, -84.8693, -69.6764], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.1242, -75.5600, -79.1398,     -inf,     -inf,     -inf,
        -65.3697, -68.6504, -83.7432], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.0883, -71.3082,     -inf,     -inf,     -inf,
            -inf, -79.1198, -74.0736], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.0738,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -90.5775], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 636: Reward=-310.22, route=[0, 5, 4, 6, 7, 1, 3, 8, 2, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.9775,     -inf, -71.2664,     -inf,     -inf,
        -77.0182, -88.3226,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -69.2274, -73.9923,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -65.4297,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 637: Reward=-272.38, route=[0, 6, 3, 5, 1, 9, 4, 2, 7, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.2253, -75.3300, -73.9493, -77.1162, -61.4356, -56.1393,
        -67.5606, -72.2528, -77.7910], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.9712, -75.2275, -79.1711, -81.1445, -55.7753,     -inf,
        -64.3596, -66.5991, -84.0035], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.2634, -75.5651, -83.4733, -84.7488,     -inf,     -inf,
        -61.3798, -61.6252, -89.0305], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.0106, -78.3921, -80.7925, -84.0910,     -inf,     -inf,
            -inf, -65.2346, -85.2811], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.3262, -77.7827, -85.0129, -87.0695,     -inf,     -inf,
            -inf,     -inf, -90.6683], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.9141, -71.3854, -76.1576,     -inf,     -inf,
            -inf,     -inf, -74.3941], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.1783,     -inf, -70.9880,     -inf,     -inf,
            -inf,     -inf, -67.7080], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.8081,     -inf, -72.1126,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 638: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -63.1177, -76.8430,     -inf, -70.4945, -73.5527, -64.4896,
        -75.2497, -84.6685, -67.1343], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.5273,     -inf, -75.5341, -67.1823, -60.2037,
        -70.3116, -77.1511, -73.6903], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.1825,     -inf, -81.0273, -55.8388,     -inf,
        -64.4197, -66.7085, -83.8879], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.5262,     -inf, -84.6463,     -inf,     -inf,
        -61.4227, -61.7214, -88.9261], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.3447,     -inf, -83.9694,     -inf,     -inf,
            -inf, -65.3487, -85.1626], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.7399,     -inf, -86.9902,     -inf,     -inf,
            -inf,     -inf, -90.6015], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.1118,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 639: Reward=-253.08, route=[0, 3, 1, 6, 5, 7, 8, 2, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -72.0441, -74.8278, -83.2600, -84.8433,     -inf, -47.9222,
        -60.5536, -59.5606, -89.1982], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.4241,     -inf, -75.8215, -77.7109,     -inf,     -inf,
        -67.2421, -69.6775, -80.8278], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.1508,     -inf, -80.9864, -84.5921,     -inf,     -inf,
            -inf, -63.0354, -85.9059], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -63.9691,     -inf, -65.5342, -72.6937,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.3910, -76.5396,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.3322,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 640: Reward=-225.94, route=[0, 5, 6, 2, 7, 8, 9, 1, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3585, -74.7701, -74.0842, -77.6041, -60.9272, -54.3828,
        -66.6097, -70.0576, -78.3709], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.1208, -74.6526, -79.3622, -81.6522, -55.2417,     -inf,
        -63.4026, -64.3872, -84.6347], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.2262, -74.9841, -83.4697, -85.0232,     -inf,     -inf,
        -60.7008, -59.6648, -89.4428], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.0893, -77.1436, -84.7072, -87.0677,     -inf,     -inf,
        -59.9944,     -inf, -90.7521], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.2176, -77.8803, -81.0543, -84.6852,     -inf,     -inf,
            -inf,     -inf, -85.9674], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.3640, -71.4722, -76.6402,     -inf,     -inf,
            -inf,     -inf, -74.9354], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.6272,     -inf, -71.4155,     -inf,     -inf,
            -inf,     -inf, -68.1635], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.2747,     -inf, -72.5768,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.2325,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 641: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3585, -74.7701, -74.0842, -77.6041, -60.9272, -54.3828,
        -66.6097, -70.0576, -78.3709], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.1208, -74.6526, -79.3622, -81.6522, -55.2417,     -inf,
        -63.4026, -64.3872, -84.6347], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.2262, -74.9841, -83.4697, -85.0232,     -inf,     -inf,
        -60.7008, -59.6648, -89.4428], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.6130, -76.2623, -84.5119, -86.9018,     -inf,     -inf,
        -59.8435,     -inf, -90.7740], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.0241, -77.9528,     -inf,     -inf,
            -inf,     -inf, -81.2823], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.3784,     -inf,     -inf,
            -inf,     -inf, -68.2800], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.5436,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 642: Reward=-215.31, route=[0, 6, 5, 8, 7, 1, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.0773, -73.8981, -74.0207, -77.6220, -61.0303, -53.0224,
        -66.2405, -68.0844, -78.5890], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.8611, -73.7706, -79.3581, -81.6958, -55.3190,     -inf,
        -63.0233, -62.3919, -84.9082], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.7550, -74.1498, -83.3154, -84.8974,     -inf,     -inf,
        -60.5128, -57.8975, -89.4669], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.6130, -76.2623, -84.5119, -86.9018,     -inf,     -inf,
        -59.8435,     -inf, -90.7740], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.9454, -76.9938, -81.0432, -84.7329,     -inf,     -inf,
            -inf,     -inf, -86.2333], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.4934, -71.3565, -76.6418,     -inf,     -inf,
            -inf,     -inf, -75.1075], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.7617,     -inf, -71.3808,     -inf,     -inf,
            -inf,     -inf, -68.2744], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.4088,     -inf, -72.5459,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.3519,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 643: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.0773, -73.8981, -74.0207, -77.6220, -61.0303, -53.0224,
        -66.2405, -68.0844, -78.5890], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.8611, -73.7706, -79.3581, -81.6958, -55.3190,     -inf,
        -63.0233, -62.3919, -84.9082], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -63.1367, -75.6257,     -inf, -71.1600,     -inf,     -inf,
        -74.1516, -80.7146, -68.0664], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.3124,     -inf, -76.3009,     -inf,     -inf,
        -69.1504, -73.0863, -74.7798], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.0635,     -inf, -71.6963,     -inf,     -inf,
            -inf, -80.9602,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 644: Reward=-258.43, route=[0, 6, 5, 3, 1, 7, 9, 4, 2, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.4735, -72.4851, -78.9674, -81.0575, -56.0122,     -inf,
        -63.1274, -61.2767, -84.9377], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.3041, -72.9152, -83.0129, -84.3046,     -inf,     -inf,
        -60.5911, -56.7799, -89.4827], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.1671, -75.0097, -84.2094, -86.3260,     -inf,     -inf,
        -59.9081,     -inf, -90.8243], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.8961,     -inf, -75.5700, -77.2776,     -inf,     -inf,
            -inf,     -inf, -81.2645], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -70.8630, -75.9308,     -inf,     -inf,
            -inf,     -inf, -75.0251], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 645: Reward=-210.68, route=[0, 6, 5, 8, 7, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.6654, -72.6261, -73.5705, -76.9501, -61.7549, -52.2211,
        -66.3574, -67.0008, -78.5569], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.4735, -72.4851, -78.9674, -81.0575, -56.0122,     -inf,
        -63.1274, -61.2767, -84.9377], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.3041, -72.9152, -83.0129, -84.3046,     -inf,     -inf,
        -60.5911, -56.7799, -89.4827], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -62.7438, -74.4318,     -inf, -70.5005,     -inf,     -inf,
        -74.3023,     -inf, -67.9833], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.0761,     -inf,     -inf,     -inf,     -inf,
        -74.1758,     -inf, -70.5384], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.1366,     -inf,     -inf,     -inf,     -inf,
        -75.3027,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.6276,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 646: Reward=-257.57, route=[0, 6, 5, 8, 3, 1, 4, 9, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2349, -71.7018, -72.7367, -76.0676, -62.9126, -51.9990,
        -66.7650, -67.3765, -77.9479], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.0654, -71.5383, -78.1917, -80.2057, -57.1307,     -inf,
        -63.5151, -61.6048, -84.3900], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.0239, -71.9768, -82.5442, -83.6771,     -inf,     -inf,
        -60.7419, -56.8401, -89.2000], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.9100, -74.0985, -83.8099, -85.7892,     -inf,     -inf,
        -59.9963,     -inf, -90.6242], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.1406, -74.7706, -79.8817, -83.2824,     -inf,     -inf,
            -inf,     -inf, -85.7197], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.3007, -69.9487, -75.0151,     -inf,     -inf,
            -inf,     -inf, -74.3469], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.6026,     -inf, -69.6757,     -inf,     -inf,
            -inf,     -inf, -67.3893], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.2388,     -inf, -70.8131,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 647: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2349, -71.7018, -72.7367, -76.0676, -62.9126, -51.9990,
        -66.7650, -67.3765, -77.9479], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -67.2287,     -inf, -74.3792, -76.0234, -60.6479,     -inf,
        -67.4556, -67.0421,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -63.0672,     -inf, -65.5044,     -inf,     -inf,     -inf,
            -inf, -78.4484,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.6919,     -inf,     -inf,     -inf,
            -inf, -72.3804,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -80.2200,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 648: Reward=-309.65, route=[0, 6, 9, 2, 5, 7, 4, 1, 3, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.1833, -71.0831, -72.3660, -75.4749, -63.4851, -51.7927,
        -66.7888, -67.4032, -77.8254], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -74.1680, -75.5486, -61.1945,     -inf,
        -67.4863, -67.0581, -80.3340], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.3722, -83.1775,     -inf,     -inf,
        -60.7377, -56.8133, -89.2709], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.7241, -85.3900,     -inf,     -inf,
        -59.9053,     -inf, -90.7564], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -79.5950, -82.7159,     -inf,     -inf,
            -inf,     -inf, -85.6623], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.0187,     -inf,     -inf,
            -inf,     -inf, -67.1581], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.1470,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 649: Reward=-233.92, route=[0, 6, 1, 2, 5, 8, 7, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -70.8522, -71.1611, -82.0834, -82.9596,     -inf, -45.2410,
        -60.5543, -56.6398, -88.9725], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.1198, -70.9389, -77.9491, -79.7062,     -inf,     -inf,
        -63.5729, -61.6580, -84.4158], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.9283, -73.4694, -83.6681, -85.3665,     -inf,     -inf,
        -59.8651,     -inf, -90.7152], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.1024, -74.1250, -79.5530, -82.7142,     -inf,     -inf,
            -inf,     -inf, -85.6456], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.6991, -69.5273, -74.3954,     -inf,     -inf,
            -inf,     -inf, -74.1722], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.0277,     -inf, -69.0247,     -inf,     -inf,
            -inf,     -inf, -67.1563], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.6682,     -inf, -70.1529,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.5938,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 650: Reward=-191.48, route=[0, 5, 6, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.1833, -71.0831, -72.3660, -75.4749, -63.4851, -51.7927,
        -66.7888, -67.4032, -77.8254], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.0344, -70.8933, -77.8722, -79.6377, -57.6680,     -inf,
        -63.5223, -61.5917, -84.3248], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5561, -70.8921, -81.8753, -82.5038,     -inf,     -inf,
        -61.1059, -57.5394, -89.1265], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.4917, -73.0982, -83.4390, -84.9004,     -inf,     -inf,
        -60.0640,     -inf, -90.7272], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.4716, -73.7352, -78.9267, -81.9116,     -inf,     -inf,
            -inf,     -inf, -85.2961], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.3461, -68.7953, -73.5325,     -inf,     -inf,
            -inf,     -inf, -73.7173], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.6966,     -inf, -68.1254,     -inf,     -inf,
            -inf,     -inf, -66.6408], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.7589,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 651: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.5346, -70.7113, -71.6952, -74.6466, -64.6089, -52.5220,
        -67.3795, -68.4620, -77.4299], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -72.3758, -73.0195, -83.2883, -84.7548, -54.1936,     -inf,
        -60.0353,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -71.5844, -70.9163, -81.8429, -82.4814,     -inf,     -inf,
        -61.1627,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -70.4259, -73.7006, -78.8182, -81.8044,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.3115, -68.6868, -73.4253,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.7589,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 652: Reward=-251.47, route=[0, 6, 9, 8, 5, 7, 1, 3, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.5346, -70.7113, -71.6952, -74.6466, -64.6089, -52.5220,
        -67.3795, -68.4620, -77.4299], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.4065, -70.4992, -77.2600, -78.8394, -58.7514,     -inf,
        -64.0911, -62.6041, -83.9901], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5561, -70.8921, -81.8753, -82.5038,     -inf,     -inf,
        -61.1059, -57.5394, -89.1265], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.4917, -73.0982, -83.4390, -84.9004,     -inf,     -inf,
        -60.0640,     -inf, -90.7272], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.8191, -73.3280, -78.1824, -81.2087,     -inf,     -inf,
            -inf,     -inf, -84.9505], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.9702, -67.9426, -72.7709,     -inf,     -inf,
            -inf,     -inf, -73.2630], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.3391,     -inf, -67.3281,     -inf,     -inf,
            -inf,     -inf, -66.1236], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.9798,     -inf, -68.4477,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 653: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False False False False False]
greedy_action q_values = tensor([    -inf, -62.4446,     -inf,     -inf, -66.8399, -78.4551, -61.9484,
        -75.7588, -82.3870, -65.5496], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.6684,     -inf,     -inf, -77.9955, -59.8568,     -inf,
        -64.4952, -63.5756, -83.5116], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.8904,     -inf,     -inf, -81.7327,     -inf,     -inf,
        -61.4467, -58.4430, -88.7443], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.7304,     -inf,     -inf, -81.0645,     -inf,     -inf,
            -inf,     -inf, -84.8023], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.6267,     -inf,     -inf,
            -inf,     -inf, -73.1148], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 654: Reward=-247.33, route=[0, 2, 3, 6, 5, 8, 7, 1, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.8606, -70.3195, -70.9066, -73.9173, -65.7199, -53.2681,
        -67.7683, -69.3830, -77.0364], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.9530,     -inf, -72.7416, -74.0023, -63.3471,     -inf,
        -68.4378, -68.9669, -79.6014], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.9738,     -inf, -81.2168, -81.8627,     -inf,     -inf,
        -61.4365, -58.3923, -88.8857], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.0195,     -inf, -83.0292, -84.4277,     -inf,     -inf,
        -60.1751,     -inf, -90.6814], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.8200,     -inf, -78.1929, -81.2000,     -inf,     -inf,
            -inf,     -inf, -84.9493], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -67.4559, -72.4723,     -inf,     -inf,
            -inf,     -inf, -73.1956], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -67.0017,     -inf,     -inf,
            -inf,     -inf, -65.9973], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 655: Reward=-193.15, route=[0, 6, 2, 5, 8, 7, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3080, -69.8476, -70.4679, -73.6474, -66.7123, -54.1754,
        -68.1479, -70.4730, -77.0237], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.2250, -69.5992, -76.1523, -77.8938, -60.7822,     -inf,
        -64.8265, -64.5249, -83.7079], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.4043, -67.2448, -72.2793,     -inf,     -inf,
        -71.1527, -75.6835, -73.0137], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7883,     -inf, -66.8087,     -inf,     -inf,
        -76.4029, -83.7735, -65.8154], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.1102,     -inf, -84.1702,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.7666,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 656: Reward=-212.84, route=[0, 6, 5, 1, 3, 9, 7, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3080, -69.8476, -70.4679, -73.6474, -66.7123, -54.1754,
        -68.1479, -70.4730, -77.0237], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.3976, -67.2936, -72.3328, -72.7917,     -inf,
            -inf, -75.5132, -73.0470], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7816,     -inf, -66.8622, -79.5733,     -inf,
            -inf, -83.6032, -65.8487], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.4244,     -inf, -67.9822, -82.4538,     -inf,
            -inf, -84.9757,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.3044,     -inf,     -inf, -75.4035,     -inf,
            -inf, -81.9557,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -64.4146,     -inf,
            -inf, -70.1510,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -60.1646,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 657: Reward=-206.63, route=[0, 6, 7, 1, 3, 9, 4, 2, 5, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -71.6604, -72.1729, -77.3389, -80.5233, -62.3711, -51.8160,
            -inf, -63.6238, -84.7181], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.0374, -69.2260, -76.2519, -77.9353, -61.5010,     -inf,
            -inf, -65.1655, -84.0296], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.3410, -69.5340, -81.0233, -81.7540,     -inf,     -inf,
            -inf, -59.9340, -89.4031], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.4290, -71.7646, -82.9138, -84.3700,     -inf,     -inf,
            -inf,     -inf, -91.2511], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.3930,     -inf, -72.5657, -73.9186,     -inf,     -inf,
            -inf,     -inf, -80.0806], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -67.3304, -72.3580,     -inf,     -inf,
            -inf,     -inf, -73.2927], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.8665,     -inf,     -inf,
            -inf,     -inf, -66.0473], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.0509,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 658: Reward=-228.94, route=[0, 7, 6, 5, 8, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.0460, -69.4502, -70.3918, -73.5497, -67.5147, -55.2256,
        -68.4159, -71.2524, -77.1693], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9765, -69.1866, -76.1282, -77.8157, -61.5504,     -inf,
        -65.0742, -65.2590, -83.9064], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.2880, -69.4958, -80.9052, -81.6446,     -inf,     -inf,
        -61.9409, -60.0202, -89.2845], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.0862, -67.1977, -72.2486,     -inf,     -inf,
        -71.4360,     -inf, -73.1724], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.4831,     -inf, -66.7571,     -inf,     -inf,
        -76.7187,     -inf, -65.9270], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.1263,     -inf, -67.9451,     -inf,     -inf,
        -77.1487,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.2934,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 659: Reward=-236.59, route=[0, 6, 5, 8, 1, 3, 9, 4, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.0460, -69.4502, -70.3918, -73.5497, -67.5147, -55.2256,
        -68.4159, -71.2524, -77.1693], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.9688, -68.8285, -76.6316, -78.2447, -61.2317,     -inf,
        -65.0585, -65.2120, -84.7876], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.2818, -69.1489, -81.4491, -82.0929,     -inf,     -inf,
        -61.8966, -59.9360, -90.1845], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -75.3769, -71.3639, -83.3343, -84.7112,     -inf,     -inf,
        -60.5460,     -inf, -92.0505], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.0246, -72.0830, -78.2518, -81.3236,     -inf,     -inf,
            -inf,     -inf, -86.0449], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.3971,     -inf, -73.0532, -74.3392,     -inf,     -inf,
            -inf,     -inf, -80.9511], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 660: Reward=-210.68, route=[0, 6, 5, 8, 7, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -72.0364, -68.8953, -76.7084, -78.3264, -61.2389,     -inf,
        -65.0557,     -inf, -84.8475], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.3490, -69.2137, -81.5243, -82.1726,     -inf,     -inf,
        -61.8968,     -inf, -90.2455], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.0246, -72.0830, -78.2518, -81.3236,     -inf,     -inf,
            -inf,     -inf, -86.0449], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.3971,     -inf, -73.0532, -74.3392,     -inf,     -inf,
            -inf,     -inf, -80.9511], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -67.7557, -72.7707,     -inf,     -inf,
            -inf,     -inf, -74.1011], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 661: Reward=-257.1, route=[0, 8, 6, 5, 7, 2, 1, 3, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.0306, -69.1004, -70.8510, -73.9652, -67.2258, -56.1687,
        -68.4169, -71.2466, -78.0068], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.9688, -68.8285, -76.6316, -78.2447, -61.2317,     -inf,
        -65.0585, -65.2120, -84.7876], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.2818, -69.1489, -81.4491, -82.0929,     -inf,     -inf,
        -61.8966, -59.9360, -90.1845], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -76.1693, -71.4667, -84.0030, -85.5095,     -inf,     -inf,
        -60.5254,     -inf, -93.2573], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -61.6189, -69.2935,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -67.9361,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 662: Reward=-198.93, route=[0, 6, 5, 8, 7, 2, 1, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.8125, -69.2170, -71.4471, -74.7446, -66.9016, -57.1572,
        -68.4426, -71.1658, -79.1445], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.7597, -68.9328, -77.2695, -79.0308, -60.8756,     -inf,
        -65.0659, -65.0909, -85.9654], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -66.6709, -67.8260, -63.8835,     -inf,     -inf,     -inf,
            -inf, -82.7505, -70.9095], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -65.6646, -71.1765,     -inf,     -inf,     -inf,     -inf,
            -inf, -84.5601, -67.7549], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7220,     -inf,     -inf,     -inf,     -inf,
            -inf, -76.4372, -74.9243], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -70.8497, -81.8356], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 663: Reward=-276.2, route=[0, 6, 5, 7, 4, 3, 1, 2, 8, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -75.8602, -71.2706, -83.6616, -85.2275, -55.7556, -50.0167,
        -60.3303,     -inf, -92.8597], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -72.8276, -68.9997, -77.3463, -79.1125, -60.8830,     -inf,
        -65.0633,     -inf, -86.0255], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -75.1414, -69.3161, -82.1925, -82.9635,     -inf,     -inf,
        -61.8883,     -inf, -91.4446], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.2729, -68.8581, -65.7223,     -inf,     -inf,     -inf,
            -inf,     -inf, -73.0189], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.2657, -72.2408,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -69.8520], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.7651,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -77.0359], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.9646], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 664: Reward=-274.37, route=[0, 8, 6, 5, 7, 4, 3, 1, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.3140, -70.1515, -73.2147, -76.6418, -66.2255, -57.8677,
        -68.0927, -70.4691, -81.1895], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.2612, -69.8462, -79.0617, -80.9169, -60.1710,     -inf,
        -64.7029, -64.3632, -88.0340], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -76.5103, -70.1538, -83.8883, -84.6883,     -inf,     -inf,
        -61.5991, -59.0872, -93.4222], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -77.4142, -72.4378, -85.5356, -87.2052,     -inf,     -inf,
        -60.3821,     -inf, -94.9996], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.8960, -70.0842, -75.5107,     -inf,     -inf,
            -inf,     -inf, -77.2724], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.3301,     -inf, -70.0161,     -inf,     -inf,
            -inf,     -inf, -69.9470], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.7653,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 665: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.3140, -70.1515, -73.2147, -76.6418, -66.2255, -57.8677,
        -68.0927, -70.4691, -81.1895], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.7389, -69.8022, -75.2372, -72.4761,     -inf,
        -71.0812, -75.7347, -76.9909], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.1730,     -inf, -69.7426, -79.3954,     -inf,
        -76.4496, -84.0353, -69.6655], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.3019,     -inf, -86.9265, -55.4631,     -inf,
        -60.4076,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.1287,     -inf, -84.5336,     -inf,     -inf,
        -61.7230,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.6429,     -inf, -84.8254,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.7839,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 666: Reward=-229.7, route=[0, 6, 1, 3, 9, 8, 5, 7, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.2007, -70.7306, -74.1630, -77.6655, -65.9592, -58.5205,
        -68.0038, -70.0116, -81.9299], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -68.9484, -69.2982, -66.3637,     -inf, -74.7491,     -inf,
        -76.2028, -81.7246, -73.4575], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf, -67.9289, -72.7081,     -inf,     -inf, -79.0996,     -inf,
        -76.3028, -83.5324, -70.2549], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.2173,     -inf,     -inf, -72.2341,     -inf,
        -70.9885, -75.3290, -77.4673], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.9123,     -inf,     -inf, -55.2055,     -inf,
            -inf,     -inf, -95.4267], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.6899,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -94.1522], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.7315], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 667: Reward=-232.82, route=[0, 6, 4, 3, 1, 7, 8, 5, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.2007, -70.7306, -74.1630, -77.6655, -65.9592, -58.5205,
        -68.0038, -70.0116, -81.9299], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -77.3777, -70.6904, -84.8403, -85.6617,     -inf,     -inf,
        -61.5547, -58.6394, -94.1909], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -78.2063, -73.0274, -86.4139, -88.1493,     -inf,     -inf,
        -60.3631,     -inf, -95.6333], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -76.2166, -73.7214, -81.6755, -85.0746,     -inf,     -inf,
            -inf,     -inf, -90.0671], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.6186,     -inf, -76.4344, -78.0331,     -inf,     -inf,
            -inf,     -inf, -84.9577], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.0245, -76.5471,     -inf,     -inf,
            -inf,     -inf, -77.9848], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.0571,     -inf,     -inf,
            -inf,     -inf, -70.6300], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 668: Reward=-210.68, route=[0, 6, 5, 8, 7, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.0582, -71.5092, -74.9635, -78.5554, -65.7234, -59.2381,
        -67.8202, -69.6933, -82.3682], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -76.0197, -71.1742, -80.8778, -82.8255, -59.6104,     -inf,
        -64.4066, -63.5291, -89.2806], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.9532, -73.6448,     -inf, -71.7666,     -inf,     -inf,
        -76.2433, -83.3868, -70.8159], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.1422,     -inf, -77.1210,     -inf,     -inf,
        -70.9036, -75.1411, -78.0546], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.4027,     -inf, -85.7638,     -inf,     -inf,
            -inf, -62.1147, -90.3229], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.8143,     -inf, -88.9635,     -inf,     -inf,
            -inf,     -inf, -95.9761], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.1440,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 669: Reward=-260.18, route=[0, 6, 5, 3, 1, 7, 8, 2, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.0582, -71.5092, -74.9635, -78.5554, -65.7234, -59.2381,
        -67.8202, -69.6933, -82.3682], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -76.0197, -71.1742, -80.8778, -82.8255, -59.6104,     -inf,
        -64.4066, -63.5291, -89.2806], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -87.1152, -88.8922,     -inf,     -inf,
        -60.3108,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.4228, -85.8599,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.8521,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 670: Reward=-241.06, route=[0, 6, 5, 2, 1, 9, 8, 7, 3, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -69.5932, -69.9362, -66.8602,     -inf, -74.5182, -65.3937,
        -75.9336, -81.3992, -73.5567], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False  True]
greedy_action q_values = tensor([    -inf, -69.5898, -77.1604, -65.5458,     -inf, -81.6386,     -inf,
        -75.7405, -84.1745,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.7635,     -inf,     -inf, -71.8417,     -inf,
        -70.0115, -74.6577,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.9981,     -inf,     -inf, -60.3096,     -inf,
            -inf, -61.5683,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.0936,     -inf,     -inf,     -inf,     -inf,
            -inf, -58.0594,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.4260,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 671: Reward=-238.25, route=[0, 4, 6, 9, 3, 1, 7, 5, 8, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -74.5104,     -inf, -77.6674, -79.3639, -62.9585, -58.1728,
        -67.6194, -68.7653, -85.1969], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -76.4966,     -inf, -81.8821, -83.7757, -59.3182,     -inf,
        -63.5632, -63.0745, -89.6649], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -78.5598,     -inf, -86.5198, -87.3766,     -inf,     -inf,
        -60.6514, -58.0277, -94.8498], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -79.3857,     -inf, -87.9692, -89.7615,     -inf,     -inf,
        -59.5208,     -inf, -96.2115], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.3006,     -inf,     -inf,
            -inf,     -inf, -78.5750], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -74.3559], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 672: Reward=-224.67, route=[0, 2, 6, 5, 8, 7, 3, 1, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.5252, -72.2503, -75.9250, -79.5169, -65.4337, -59.8084,
        -66.9668, -69.2162, -82.7277], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -76.4937, -71.8998, -81.8730, -83.7860, -59.2933,     -inf,
        -63.5387, -63.0227, -89.6674], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -73.1522, -78.8683,     -inf,     -inf,
        -69.5602, -74.6488, -78.5296], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -84.1227, -87.5058,     -inf,     -inf,
            -inf, -61.4978, -90.8727], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -88.7142, -90.4362,     -inf,     -inf,
            -inf,     -inf, -96.3604], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.5879,     -inf,     -inf,
            -inf,     -inf, -71.2933], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.7995,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 673: Reward=-235.87, route=[0, 6, 5, 2, 1, 7, 8, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -76.8845, -75.7085, -83.7265, -87.2062, -60.1827, -56.9205,
            -inf, -61.2019, -90.4509], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf, -69.0984, -75.1992,     -inf, -73.4401, -78.8006,     -inf,
            -inf, -82.8046, -71.1349], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.6664,     -inf, -78.7923, -71.8434,     -inf,
            -inf, -74.4766, -78.4122], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.8959,     -inf, -88.0076,     -inf,     -inf,
            -inf, -57.9258, -94.8939], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.2004,     -inf, -90.3243,     -inf,     -inf,
            -inf,     -inf, -96.2379], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 674: Reward=-284.55, route=[0, 7, 6, 3, 1, 5, 8, 2, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -73.2636, -72.9701, -76.5500, -80.1351, -65.5115, -60.4547,
        -66.4757, -69.1660, -82.7447], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True  True False False]
greedy_action q_values = tensor([    -inf, -70.1135,     -inf, -68.8186,     -inf, -74.4024,     -inf,
            -inf, -81.0305, -74.3588], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf, -68.0429,     -inf,     -inf,     -inf, -82.2318,     -inf,
            -inf, -84.6406,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 675: Reward=-233.85, route=[0, 6, 2, 7, 4, 3, 9, 1, 8, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -72.1324, -73.0177, -76.2729, -79.8386, -65.8700, -61.0273,
        -66.6625, -69.5159, -81.6154], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -68.1979, -78.1499, -65.9639, -74.4655, -82.2065,     -inf,
            -inf, -84.5499,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -67.8610, -75.2326,     -inf, -72.9932, -79.3189,     -inf,
            -inf, -83.3252,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.7877, -63.5501,     -inf,
            -inf, -69.2990,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -87.8031,     -inf,     -inf,
            -inf, -58.0715,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -90.2307,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 676: Reward=-243.63, route=[0, 6, 7, 9, 3, 1, 2, 5, 8, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -75.1344, -72.6421, -82.2954, -84.1244, -59.6705,     -inf,
        -63.2014, -63.2597, -88.6171], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -77.4266, -72.8879, -87.1931, -87.9219,     -inf,     -inf,
        -60.0398, -57.9122, -94.0940], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -78.2595, -75.2171, -88.6467, -90.3094,     -inf,     -inf,
        -58.9238,     -inf, -95.4906], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -76.1366, -76.0401, -83.9135, -87.3140,     -inf,     -inf,
            -inf,     -inf, -89.7923], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.6204,     -inf, -78.6298, -80.1931,     -inf,     -inf,
            -inf,     -inf, -84.7386], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -73.0399, -78.7642,     -inf,     -inf,
            -inf,     -inf, -77.5273], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.2352,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 677: Reward=-210.68, route=[0, 6, 5, 8, 7, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.1178, -73.0339, -76.0632, -79.6396, -65.9102, -61.2946,
        -66.9595, -69.9937, -80.5344], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -67.1122, -78.2124, -65.6141, -74.1926, -82.3756,     -inf,
        -75.8444,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf, -66.8020, -75.2828,     -inf, -72.7166, -79.4809,     -inf,
        -75.5098,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.7444,     -inf, -78.1088, -72.4512,     -inf,
        -70.0577,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.9344,     -inf, -86.8090, -60.7530,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.9184,     -inf, -87.8149,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -79.7391,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 678: Reward=-219.41, route=[0, 6, 8, 9, 3, 1, 7, 5, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.1178, -73.0339, -76.0632, -79.6396, -65.9102, -61.2946,
        -66.9595, -69.9937, -80.5344], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -74.1350, -72.6553, -82.1229, -83.9426, -59.6797,     -inf,
        -63.4837, -63.7117, -87.5645], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -76.5504, -72.8829, -87.1491, -87.8607,     -inf,     -inf,
        -60.1827, -58.2180, -93.1842], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -77.4109, -75.2187, -88.6648, -90.3008,     -inf,     -inf,
        -59.0081,     -inf, -94.6463], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -75.1069, -76.0682, -83.7256, -87.1355,     -inf,     -inf,
            -inf,     -inf, -88.7014], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.4524,     -inf, -73.0349,     -inf,     -inf,
            -inf,     -inf, -68.9204], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.7545,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 679: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -65.9001, -78.6504, -64.5906, -73.2943, -82.8522, -73.5675,
        -76.7474, -86.2588,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.1769,     -inf, -77.2124, -72.9108, -66.5006,
        -70.9171, -76.5722,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.2079,     -inf, -83.1464, -60.2905,     -inf,
        -64.5729, -64.9812,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.4327,     -inf, -87.1226,     -inf,     -inf,
        -61.2120, -59.4368,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.7454,     -inf, -89.8594,     -inf,     -inf,
        -59.6780,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.6473,     -inf, -86.3371,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 680: Reward=-204.02, route=[0, 9, 3, 1, 6, 5, 8, 7, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.2411, -73.6727, -75.4660, -79.0800, -66.3801, -61.8113,
        -67.9236, -71.0565, -79.2291], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.2762, -73.2886, -81.5723, -83.4062, -60.1141,     -inf,
        -64.4296, -64.7437, -86.2972], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.7370, -73.5134, -86.6517, -87.3823,     -inf,     -inf,
        -61.0687, -59.1993, -91.9665], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -76.8139, -75.8299, -88.4631, -90.0577,     -inf,     -inf,
        -59.6106,     -inf, -93.7344], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.2198, -76.7280, -83.1528, -86.5968,     -inf,     -inf,
            -inf,     -inf, -87.3920], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.6235, -72.1359, -77.9830,     -inf,     -inf,
            -inf,     -inf, -75.0292], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.1235,     -inf, -72.4239,     -inf,     -inf,
            -inf,     -inf, -67.5177], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 681: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False  True  True]
greedy_action q_values = tensor([    -inf, -65.6985, -72.3913, -65.9156,     -inf, -75.6915, -68.4272,
        -76.5731,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False False False  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  0.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.6111,     -inf,     -inf, -61.2908, -58.3950,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.4887,     -inf,     -inf, -60.3796,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.7212,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 682: Reward=-268.94, route=[0, 8, 9, 4, 1, 3, 7, 6, 5, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.1681, -73.9014, -74.2863, -78.1501, -66.5435, -61.9447,
        -68.1138, -71.5993, -77.2903], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.2282, -73.5208, -80.4491, -82.5065, -60.2426,     -inf,
        -64.6068, -65.2581, -84.4114], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.7052, -73.7533, -85.5694, -86.5067,     -inf,     -inf,
        -61.2363, -59.6942, -90.1156], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -75.8586, -76.0741, -87.4865, -89.2919,     -inf,     -inf,
        -59.6362,     -inf, -91.9724], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.1426, -76.9821, -82.0007, -85.6898,     -inf,     -inf,
            -inf,     -inf, -85.4568], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.3749,     -inf,     -inf,
            -inf,     -inf, -80.3446], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -68.7616], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 683: Reward=-209.55, route=[0, 6, 5, 8, 7, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.1681, -73.9014, -74.2863, -78.1501, -66.5435, -61.9447,
        -68.1138, -71.5993, -77.2903], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.2282, -73.5208, -80.4491, -82.5065, -60.2426,     -inf,
        -64.6068, -65.2581, -84.4114], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -63.6852, -76.1259,     -inf,     -inf,     -inf,     -inf,
            -inf, -86.1410,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.6079,     -inf,     -inf,     -inf,     -inf,
            -inf, -77.6140,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 684: Reward=-252.63, route=[0, 6, 5, 7, 9, 4, 3, 1, 2, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -71.7356, -76.7035, -80.2201, -84.2927, -61.2012, -58.1263,
            -inf, -63.8290, -83.3186], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.2957, -73.5650, -79.2572, -81.6194, -60.2773,     -inf,
            -inf, -65.5075, -82.8873], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.7906, -73.8097, -84.4222, -85.6471,     -inf,     -inf,
            -inf, -59.9265, -88.6280], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.7209,     -inf, -75.3787, -77.4853,     -inf,     -inf,
            -inf,     -inf, -78.8375], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.4219, -75.9102,     -inf,     -inf,
            -inf,     -inf, -71.2032], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.2733,     -inf,     -inf,
            -inf,     -inf, -63.5874], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.5731,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 685: Reward=-228.94, route=[0, 7, 6, 5, 8, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.1462, -73.8876, -72.9063, -77.1058, -66.6541, -61.7787,
        -68.2552, -71.9563, -75.5911], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.2333, -73.5159, -79.1309, -81.4969, -60.3140,     -inf,
        -64.7371, -65.5887, -82.7667], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -69.6590,     -inf, -75.3105, -77.4099,     -inf,     -inf,
            -inf, -71.6323, -78.7914], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.3537, -75.8349,     -inf,     -inf,
            -inf, -77.5487, -71.1570], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.1980,     -inf,     -inf,
            -inf, -86.2292, -63.5412], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.4041,     -inf,     -inf,
            -inf, -88.0368,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 686: Reward=-256.95, route=[0, 6, 5, 7, 2, 1, 3, 9, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.4891, -73.7625, -71.4515, -75.8643, -66.9077, -61.5507,
        -68.8672, -72.6126, -73.8178], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.6053, -73.4075, -77.7409, -80.2947, -60.5310,     -inf,
        -65.3378, -66.2169, -81.0493], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.1209, -73.6709, -82.9538, -84.3540,     -inf,     -inf,
        -61.9518, -60.6172, -86.8285], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.2167, -76.0511, -84.9209, -87.2062,     -inf,     -inf,
        -60.2538,     -inf, -88.6245], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -63.5002, -78.9673, -61.0218, -70.6186,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -63.1322, -76.0845,     -inf, -69.0006,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -75.9868,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 687: Reward=-191.06, route=[0, 6, 5, 8, 7, 9, 3, 1, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.4891, -73.7625, -71.4515, -75.8643, -66.9077, -61.5507,
        -68.8672, -72.6126, -73.8178], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -64.2066, -72.3356, -63.2842,     -inf, -76.0947,     -inf,
        -77.4795, -84.8741, -65.0951], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf, -62.9151, -75.8778,     -inf,     -inf, -80.5640,     -inf,
        -77.3550, -86.5666, -61.4805], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf, -63.1117, -78.6579,     -inf,     -inf, -83.4251,     -inf,
        -77.7000, -87.8305,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.3719,     -inf,     -inf, -73.5916,     -inf,
        -72.0106, -78.2872,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.5653,     -inf,     -inf,     -inf,     -inf,
            -inf, -60.7586,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.9455,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 688: Reward=-210.24, route=[0, 6, 4, 3, 9, 1, 7, 5, 8, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3122, -72.9849, -70.2278, -74.8972, -66.4760, -60.9536,
        -69.1950, -72.5680, -72.7770], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4513, -72.6618, -76.5775, -79.3634, -60.0699,     -inf,
        -65.6590, -66.1507, -80.0566], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.2365, -76.1037, -77.9436,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.8884], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.8621, -66.4919,     -inf,     -inf,     -inf,
            -inf,     -inf, -68.1629], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -75.8416], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 689: Reward=-281.18, route=[0, 6, 5, 8, 4, 7, 1, 3, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3122, -72.9849, -70.2278, -74.8972, -66.4760, -60.9536,
        -69.1950, -72.5680, -72.7770], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4513, -72.6618, -76.5775, -79.3634, -60.0699,     -inf,
        -65.6590, -66.1507, -80.0566], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.9834, -72.9576, -81.8358, -83.4529,     -inf,     -inf,
        -62.2694, -60.5376, -85.8691], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.0734, -75.3517, -83.7946, -86.3082,     -inf,     -inf,
        -60.5641,     -inf, -87.6508], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.2986, -76.1747, -78.0316, -82.5148,     -inf,     -inf,
            -inf,     -inf, -80.9700], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.9331, -66.5799, -73.6266,     -inf,     -inf,
            -inf,     -inf, -68.2445], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.2866,     -inf, -68.2022,     -inf,     -inf,
            -inf,     -inf, -60.7399], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.5933,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 690: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3122, -72.9849, -70.2278, -74.8972, -66.4760, -60.9536,
        -69.1950, -72.5680, -72.7770], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4513, -72.6618, -76.5775, -79.3634, -60.0699,     -inf,
        -65.6590, -66.1507, -80.0566], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.3068, -72.5311, -81.1519, -82.9185,     -inf,     -inf,
        -62.7430, -60.3483, -86.1241], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.3924, -74.9397, -83.1020, -85.7772,     -inf,     -inf,
        -61.0306,     -inf, -87.8961], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.6017, -75.7375, -77.2864, -81.9540,     -inf,     -inf,
            -inf,     -inf, -81.1833], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.4359, -65.7478, -73.0088,     -inf,     -inf,
            -inf,     -inf, -68.4188], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.7455,     -inf, -67.6299,     -inf,     -inf,
            -inf,     -inf, -60.9583], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.5016,     -inf, -68.9731,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.0530,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 691: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.6119, -72.5043, -69.4615, -74.3128, -65.9718, -60.4904,
        -69.6865, -72.4121, -72.9870], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.7653, -72.2077, -75.8591, -78.8063, -59.5375,     -inf,
        -66.1395, -65.9736, -80.2948], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.3068, -72.5311, -81.1519, -82.9185,     -inf,     -inf,
        -62.7430, -60.3483, -86.1241], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.3924, -74.9397, -83.1020, -85.7772,     -inf,     -inf,
        -61.0306,     -inf, -87.8961], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.6017, -75.7375, -77.2864, -81.9540,     -inf,     -inf,
            -inf,     -inf, -81.1833], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.7455,     -inf, -67.6299,     -inf,     -inf,
            -inf,     -inf, -60.9583], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.0530,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 692: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -74.0701, -74.7168, -82.7519, -85.4844, -54.1158, -52.4688,
        -60.8046,     -inf, -87.5046], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -70.8249, -72.2778, -75.9212, -78.8768, -59.5597,     -inf,
        -66.1468,     -inf, -80.3345], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.3664, -72.6012, -81.2141, -82.9890,     -inf,     -inf,
        -62.7503,     -inf, -86.1638], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.9284, -75.0235, -76.7360, -81.5056,     -inf,     -inf,
            -inf,     -inf, -81.4790], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.7535, -58.2814, -68.6157,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.8743,     -inf, -67.0601,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.2319,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 693: Reward=-193.77, route=[0, 8, 6, 5, 7, 1, 9, 3, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False False False False]
greedy_action q_values = tensor([    -inf, -69.0880,     -inf, -70.8523,     -inf, -62.9274, -58.1166,
        -70.6571, -71.8321, -76.0105], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0342,     -inf, -75.2367,     -inf, -59.0910,     -inf,
        -66.3537, -65.8495, -80.5088], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.5823,     -inf, -80.5578,     -inf,     -inf,     -inf,
        -62.9578, -60.2116, -86.3532], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -63.7589,     -inf, -58.0492,     -inf,     -inf,     -inf,
        -78.6870,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True False  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -73.1985,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 694: Reward=-205.45, route=[0, 4, 2, 6, 5, 8, 9, 3, 1, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9385, -71.7498, -68.8958, -73.8455, -65.5285, -59.8305,
        -69.8925, -72.2615, -73.2800], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1030, -71.4811, -75.3340, -78.3605, -59.0690,     -inf,
        -66.3443, -65.8022, -80.6140], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.6511, -71.8326, -80.6550, -82.4908,     -inf,     -inf,
        -62.9484, -60.1643, -86.4583], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.7322, -74.2531, -82.5971, -85.3532,     -inf,     -inf,
        -61.2270,     -inf, -88.2221], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.9284, -75.0235, -76.7360, -81.5056,     -inf,     -inf,
            -inf,     -inf, -81.4790], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.6577, -65.1248, -72.5142,     -inf,     -inf,
            -inf,     -inf, -68.6786], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.3356,     -inf, -68.5421,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.8527,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 695: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.9689, -64.8751, -72.2110, -71.3443, -63.4568,
        -72.5139, -77.1648, -69.2831], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.1993, -75.6789, -78.5539, -58.2997,     -inf,
        -66.0779, -65.2644, -81.7797], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.5757, -81.0191, -82.6976,     -inf,     -inf,
        -62.6882, -59.6199, -87.6306], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.0111, -82.9596, -85.5688,     -inf,     -inf,
        -60.9544,     -inf, -89.3918], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.5502,     -inf, -67.2448,     -inf,     -inf,
            -inf,     -inf, -62.3406], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.3356,     -inf, -68.5421,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.8527,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 696: Reward=-204.79, route=[0, 1, 6, 5, 8, 7, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.5211, -71.4158, -69.2034, -74.0289, -64.6942, -58.7237,
        -69.5491, -71.6379, -74.4369], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.6945, -71.1702, -75.6682, -78.5577, -58.2160,     -inf,
        -66.0081, -65.1674, -81.7839], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.2487, -71.5465, -81.0084, -82.7013,     -inf,     -inf,
        -62.6184, -59.5229, -87.6348], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.5146, -74.7310, -77.0592, -81.7106,     -inf,     -inf,
            -inf,     -inf, -82.6389], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.3121, -65.4021, -72.6878,     -inf,     -inf,
            -inf,     -inf, -69.8279], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.5502,     -inf, -67.2448,     -inf,     -inf,
            -inf,     -inf, -62.3406], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.8711,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 697: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.1703, -71.4902, -69.7830, -74.5633, -63.4425, -57.2955,
        -68.6143, -70.1999, -75.8338], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.3532, -71.2686, -76.2752, -79.1002, -56.9485,     -inf,
        -65.0880, -63.7278, -83.1925], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.9140, -71.6709, -81.6353, -83.2529,     -inf,     -inf,
        -61.7107, -58.0843, -89.0489], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -64.7412, -73.5212,     -inf, -67.4855,     -inf,     -inf,
        -77.2506,     -inf, -63.5025], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -64.8236, -76.3533,     -inf, -68.7669,     -inf,     -inf,
        -77.5283,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.2065,     -inf, -72.8252,     -inf,     -inf,
        -71.8776,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.8711,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 698: Reward=-218.3, route=[0, 6, 5, 8, 3, 9, 1, 7, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.1703, -71.4902, -69.7830, -74.5633, -63.4425, -57.2955,
        -68.6143, -70.1999, -75.8338], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.3532, -71.2686, -76.2752, -79.1002, -56.9485,     -inf,
        -65.0880, -63.7278, -83.1925], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.9140, -71.6709, -81.6353, -83.2529,     -inf,     -inf,
        -61.7107, -58.0843, -89.0489], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -75.8881, -74.1526, -83.4360, -86.0650,     -inf,     -inf,
        -60.0506,     -inf, -90.6399], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.1685, -74.8536, -77.6578, -82.2645,     -inf,     -inf,
            -inf,     -inf, -84.0390], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.3821, -65.9542, -73.2223,     -inf,     -inf,
            -inf,     -inf, -71.2209], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.4276,     -inf, -68.8828,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.8711,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 699: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.1703, -71.4902, -69.7830, -74.5633, -63.4425, -57.2955,
        -68.6143, -70.1999, -75.8338], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False  True]
greedy_action q_values = tensor([    -inf, -66.8004, -69.9608, -62.4799,     -inf, -71.3137,     -inf,
        -76.1319, -80.9669,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf, -65.3400, -73.5465,     -inf,     -inf, -75.9913,     -inf,
        -76.0255, -82.8051,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.8498,     -inf,     -inf,     -inf,     -inf,
        -60.7365, -56.7983,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.3641,     -inf,     -inf,     -inf,     -inf,
        -59.4204,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.0037,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 700: Reward=-245.75, route=[0, 6, 9, 4, 3, 1, 5, 8, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.1068, -71.7649, -71.0139, -75.6723, -61.8929, -55.6996,
        -67.3307, -68.4126, -77.8194], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.2954, -71.5624, -77.5227, -80.2050, -55.3870,     -inf,
        -63.8227, -61.9469, -85.1821], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.6401, -72.0258, -82.6071, -84.1842,     -inf,     -inf,
        -60.6774, -56.6578, -90.6674], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.4925,     -inf,     -inf,
            -inf,     -inf, -65.4442], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 701: Reward=-215.31, route=[0, 6, 5, 8, 7, 1, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.1068, -71.7649, -71.0139, -75.6723, -61.8929, -55.6996,
        -67.3307, -68.4126, -77.8194], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.2954, -71.5624, -77.5227, -80.2050, -55.3870,     -inf,
        -63.8227, -61.9469, -85.1821], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.6401, -72.0258, -82.6071, -84.1842,     -inf,     -inf,
        -60.6774, -56.6578, -90.6674], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -76.1918, -74.8645, -84.2238, -87.1798,     -inf,     -inf,
        -58.5718,     -inf, -92.6847], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.1931, -75.4869, -79.5250, -84.2543,     -inf,     -inf,
            -inf,     -inf, -87.1784], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.9446, -67.7746, -75.2239,     -inf,     -inf,
            -inf,     -inf, -74.3693], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.1438,     -inf, -69.3989,     -inf,     -inf,
            -inf,     -inf, -66.6262], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.6238,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 702: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -71.4755,     -inf, -73.7378, -76.4254, -58.4763, -52.7547,
        -66.9763, -66.7488, -81.8611], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.3924,     -inf, -78.1474, -81.0322, -54.5772,     -inf,
        -62.6152, -60.6782, -86.3262], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.4119,     -inf, -82.9006, -84.7510,     -inf,     -inf,
        -59.7889, -55.7996, -91.3641], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -76.1942,     -inf, -84.2264, -87.1647,     -inf,     -inf,
        -58.5942,     -inf, -92.6817], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.1099,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -70.3510], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -74.0935], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 703: Reward=-212.91, route=[0, 2, 6, 5, 8, 7, 3, 4, 1, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False False False False]
greedy_action q_values = tensor([    -inf, -66.7405,     -inf, -62.9426,     -inf, -70.4193, -60.9619,
        -74.7152, -79.5380, -69.9440], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -73.3288,     -inf, -78.0598,     -inf, -54.5590,     -inf,
        -62.5893, -60.6555, -86.2420], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.3456,     -inf, -82.8108,     -inf,     -inf,     -inf,
        -59.7681, -55.7828, -91.2727], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -75.6389,     -inf, -84.2153,     -inf,     -inf,     -inf,
        -57.9315,     -inf, -92.9573], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.8278,     -inf, -79.7772,     -inf,     -inf,     -inf,
            -inf,     -inf, -87.7166], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.1725], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 704: Reward=-188.58, route=[0, 2, 4, 6, 5, 8, 7, 1, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.9371, -72.1370, -71.9889, -76.8785, -60.6082, -53.4047,
        -65.1359, -66.2121, -79.6447], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8531, -67.8602, -75.3256, -67.3530,     -inf,
        -68.1302, -71.7724, -74.7881], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.5930, -83.0442, -84.9169,     -inf,     -inf,
        -59.1566, -55.2576, -91.7643], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.0292, -84.3241, -87.2908,     -inf,     -inf,
        -57.9964,     -inf, -93.0744], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.6432, -79.8891, -84.6005,     -inf,     -inf,
            -inf,     -inf, -87.8240], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -60.3969, -71.0440,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 705: Reward=-243.03, route=[0, 6, 1, 5, 8, 7, 2, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.9371, -72.1370, -71.9889, -76.8785, -60.6082, -53.4047,
        -65.1359, -66.2121, -79.6447], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.1292, -71.9624, -78.5334, -81.4084, -54.0670,     -inf,
        -61.6520, -59.7429, -87.0246], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -65.4764, -77.0458, -60.2262, -70.8941,     -inf,     -inf,
        -74.0802, -81.9014,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -65.3167, -74.0096,     -inf, -69.4356,     -inf,     -inf,
        -73.8827, -80.7471,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.7856,     -inf, -75.1073,     -inf,     -inf,
        -68.3035, -72.0523,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.4453,     -inf, -84.2522,     -inf,     -inf,
            -inf, -58.3437,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.1730,     -inf, -86.9518,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.8357,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 706: Reward=-215.26, route=[0, 6, 5, 9, 3, 1, 7, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -64.5723, -76.9508, -59.7213, -70.4421, -77.7530, -64.4580,
        -73.2928, -81.5198,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False  True False  True]
greedy_action q_values = tensor([    -inf, -72.8001, -75.3892,     -inf, -83.8423, -55.0990, -48.8604,
            -inf, -57.8421,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf, -72.5058, -72.0730,     -inf, -81.1274, -54.1268,     -inf,
            -inf, -59.6441,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -74.2669, -72.6775,     -inf, -84.5574,     -inf,     -inf,
            -inf, -55.1547,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -75.0257, -75.1433,     -inf, -86.9378,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.0699,     -inf, -75.1491,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.8357,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 707: Reward=-236.27, route=[0, 9, 3, 7, 6, 5, 8, 1, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.4084, -72.2973, -71.9086, -76.7504, -60.5900, -52.5542,
        -64.6258, -66.0210, -79.7305], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.6084, -72.1451, -78.4793, -81.2928, -54.0337,     -inf,
        -61.1541, -59.5474, -87.1291], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -66.3094, -70.4972, -63.5690,     -inf,     -inf,     -inf,
        -73.4676, -78.6632, -71.1638], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -64.7644, -74.1091,     -inf,     -inf,     -inf,     -inf,
        -73.2649, -80.4614, -67.1076], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.9175,     -inf,     -inf,     -inf,     -inf,
        -67.6901, -71.7543, -74.6794], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.6265,     -inf,     -inf,     -inf,     -inf,
            -inf, -58.0295, -87.6115], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.1396,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -92.9030], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.9607], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 708: Reward=-250.71, route=[0, 6, 5, 4, 3, 1, 7, 8, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.5832, -71.9757, -71.4384, -75.9065, -61.1712, -51.9813,
        -64.5169, -66.6879, -79.0299], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.7975, -71.8459, -78.0411, -80.4675, -54.5948,     -inf,
        -61.0550, -60.2019, -86.4621], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.6202, -72.4612, -82.5555, -83.9543,     -inf,     -inf,
        -58.5580, -55.6230, -91.2458], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.3635, -74.9409, -83.8224, -86.3390,     -inf,     -inf,
        -57.3533,     -inf, -92.5203], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.5069, -75.5355, -79.3311, -83.6489,     -inf,     -inf,
            -inf,     -inf, -87.1918], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8645, -67.4708, -74.5570,     -inf,     -inf,
            -inf,     -inf, -74.3185], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.1255,     -inf,     -inf,
            -inf,     -inf, -82.3738], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -70.4560], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 709: Reward=-209.55, route=[0, 6, 5, 8, 7, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.5832, -71.9757, -71.4384, -75.9065, -61.1712, -51.9813,
        -64.5169, -66.6879, -79.0299], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.7975, -71.8459, -78.0411, -80.4675, -54.5948,     -inf,
        -61.0550, -60.2019, -86.4621], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.6202, -72.4612, -82.5555, -83.9543,     -inf,     -inf,
        -58.5580, -55.6230, -91.2458], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.3635, -74.9409, -83.8224, -86.3390,     -inf,     -inf,
        -57.3533,     -inf, -92.5203], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8645, -67.4708, -74.5570,     -inf,     -inf,
            -inf,     -inf, -74.3185], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 710: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.5832, -71.9757, -71.4384, -75.9065, -61.1712, -51.9813,
        -64.5169, -66.6879, -79.0299], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.7975, -71.8459, -78.0411, -80.4675, -54.5948,     -inf,
        -61.0550, -60.2019, -86.4621], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.2173, -72.4465, -82.3844, -83.1745,     -inf,     -inf,
        -58.6272, -56.8183, -90.4961], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -63.3838, -73.8098,     -inf,     -inf,     -inf,     -inf,
        -73.3656,     -inf, -65.2685], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -66.1923,     -inf, -81.0264], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 711: Reward=-262.43, route=[0, 6, 5, 8, 4, 3, 1, 2, 7, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1501, -71.8612, -77.5055, -79.4375, -56.0856,     -inf,
        -61.4068, -61.7766, -85.3102], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.7735, -75.4965, -78.7104, -82.5402,     -inf,     -inf,
            -inf, -60.1316, -85.9610], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.9791, -75.0207, -83.7391, -85.6616,     -inf,     -inf,
            -inf,     -inf, -91.8143], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8686, -66.8511, -73.4729,     -inf,     -inf,
            -inf,     -inf, -73.0644], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.9664,     -inf, -67.7654,     -inf,     -inf,
            -inf,     -inf, -65.4209], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.8344,     -inf, -69.0242,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.1714,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 712: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9248, -71.9780, -70.8677, -74.8571, -62.6899, -52.0329,
        -64.8661, -68.2885, -77.8418], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1501, -71.8612, -77.5055, -79.4375, -56.0856,     -inf,
        -61.4068, -61.7766, -85.3102], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.7937, -66.1304, -72.3040,     -inf,     -inf,
            -inf, -75.3353, -71.3609], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.8604,     -inf, -66.8255,     -inf,     -inf,
            -inf, -83.8404, -63.8778], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.7131,     -inf, -68.0937,     -inf,     -inf,
            -inf, -85.0875,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.0827,     -inf,     -inf,     -inf,     -inf,
            -inf, -82.4925,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -69.7312,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 713: Reward=-214.92, route=[0, 6, 5, 7, 1, 3, 9, 4, 2, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.0177, -71.9725, -70.2501, -73.7832, -64.0602, -52.2195,
        -64.8823, -69.5775, -76.2433], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.2553, -71.8682, -76.9261, -78.3808, -57.4271,     -inf,
        -61.4285, -63.0372, -83.7514], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -64.0532, -70.1230, -61.9815,     -inf,     -inf,     -inf,
        -73.7213, -82.2853, -67.7427], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -62.4824, -73.7028,     -inf,     -inf,     -inf,     -inf,
        -73.1721, -83.7344, -63.7295], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.5802,     -inf,     -inf,     -inf,     -inf,
        -67.9354, -75.4436, -71.0049], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.3972,     -inf,     -inf,     -inf,     -inf,
            -inf, -61.5631, -84.0891], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.9062,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -90.4146], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -79.5625], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 714: Reward=-250.71, route=[0, 6, 5, 4, 3, 1, 7, 8, 2, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -63.7288, -69.8890, -61.6341,     -inf, -73.4817, -58.7632,
        -73.4774, -82.0569, -67.3465], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -70.1940, -71.7917, -76.8383,     -inf, -57.4064,     -inf,
        -61.4043, -63.0136, -83.6684], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5195, -72.3429, -82.0491,     -inf,     -inf,     -inf,
        -58.3839, -57.6783, -89.2497], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.2049, -74.8971, -83.3588,     -inf,     -inf,     -inf,
        -57.0768,     -inf, -90.4589], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.8402, -75.5182, -78.0638,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.2963], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8526, -65.3787,     -inf,     -inf,     -inf,
            -inf,     -inf, -69.6121], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -77.9759], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 715: Reward=-242.19, route=[0, 4, 6, 5, 8, 7, 1, 3, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2712, -72.0296, -69.5886, -72.7932, -65.6640, -52.7366,
        -65.1736, -70.9829, -74.6265], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.5200, -71.9323, -76.3018, -77.4035, -59.0047,     -inf,
        -61.7279, -64.4217, -82.1738], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.0292, -72.4735, -81.7371, -81.5260,     -inf,     -inf,
        -58.5183, -58.8232, -88.0351], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.0819, -75.6047, -77.4446, -80.4792,     -inf,     -inf,
            -inf, -62.8075, -82.7218], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.8315, -75.0878, -83.3173, -84.1665,     -inf,     -inf,
            -inf,     -inf, -89.4602], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.9296, -65.4669, -71.3472,     -inf,     -inf,
            -inf,     -inf, -69.6947], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.9702,     -inf, -66.1467,     -inf,     -inf,
            -inf,     -inf, -62.4056], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.7996,     -inf, -67.4454,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.1808,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 716: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2712, -72.0296, -69.5886, -72.7932, -65.6640, -52.7366,
        -65.1736, -70.9829, -74.6265], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.5200, -71.9323, -76.3018, -77.4035, -59.0047,     -inf,
        -61.7279, -64.4217, -82.1738], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.5577, -77.3603,     -inf,     -inf,     -inf,
            -inf, -62.8926, -82.6278], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.0460, -83.2658,     -inf,     -inf,     -inf,
            -inf,     -inf, -89.3877], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -72.2931,     -inf,     -inf,     -inf,
            -inf,     -inf, -78.1462], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -60.5044], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 717: Reward=-261.38, route=[0, 6, 5, 1, 4, 7, 8, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.2556, -71.8315, -68.6854, -71.5723, -67.2886, -53.4796,
        -65.9212, -72.6079, -72.6636], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.1189, -72.3047, -80.9670, -80.4233,     -inf,     -inf,
        -59.1656, -60.3105, -86.2406], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -69.0529, -75.4331, -76.5462, -79.2564,     -inf,     -inf,
            -inf, -64.4266, -80.7481], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.0430, -74.9304, -82.8083, -83.2594,     -inf,     -inf,
            -inf,     -inf, -87.8641], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.7294, -64.5023, -70.0911,     -inf,     -inf,
            -inf,     -inf, -67.6418], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.9978,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -64.4950], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 718: Reward=-230.56, route=[0, 6, 5, 7, 8, 1, 3, 4, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False  True False False]
greedy_action q_values = tensor([    -inf, -62.2517, -69.7425, -60.7361,     -inf, -76.4221, -59.8874,
            -inf, -84.5146, -64.2469], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True  True False False]
greedy_action q_values = tensor([    -inf, -68.5172, -71.7276, -75.4609,     -inf, -60.5667,     -inf,
            -inf, -65.9441, -80.2740], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -60.9854, -76.4577, -57.7877,     -inf,     -inf,     -inf,
            -inf, -87.4222,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True False  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -78.7129,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 719: Reward=-298.72, route=[0, 7, 4, 6, 5, 9, 3, 2, 1, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.2556, -71.8315, -68.6854, -71.5723, -67.2886, -53.4796,
        -65.9212, -72.6079, -72.6636], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.0600,     -inf, -71.0978, -70.9294, -65.6506,     -inf,
        -67.7562, -73.1299, -74.8327], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -61.7187,     -inf, -60.9431,     -inf,     -inf,     -inf,
        -74.8710, -85.3502, -63.3537], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -67.9910,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -65.2296, -79.1265], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.0628,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.3464], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -65.9534], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 720: Reward=-246.62, route=[0, 6, 2, 5, 4, 3, 7, 8, 1, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.3736, -71.7277, -68.4600, -70.7625, -68.2552, -53.8946,
        -66.5312, -73.2786, -71.3427], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.6620, -71.6484, -75.2552, -75.3986, -61.5332,     -inf,
        -63.0939, -66.6691, -78.9770], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.2695, -72.2176, -80.8086, -79.6316,     -inf,     -inf,
        -59.7887, -60.9448, -84.9842], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -68.1636, -75.3541, -76.3364, -78.4481,     -inf,     -inf,
            -inf, -65.0816, -79.4217], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.2347, -74.8694, -82.7229, -82.5762,     -inf,     -inf,
            -inf,     -inf, -86.6390], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.6316, -64.2308, -69.2591,     -inf,     -inf,
            -inf,     -inf, -66.2486], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.6205,     -inf, -64.5520,     -inf,     -inf,
            -inf,     -inf, -59.2925], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.4183,     -inf, -65.8859,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.8478,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 721: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.3736, -71.7277, -68.4600, -70.7625, -68.2552, -53.8946,
        -66.5312, -73.2786, -71.3427], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.6620, -71.6484, -75.2552, -75.3986, -61.5332,     -inf,
        -63.0939, -66.6691, -78.9770], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8446, -63.7277, -68.3350,     -inf,     -inf,
        -70.3518, -79.7087, -65.0076], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.1039,     -inf,     -inf,     -inf,     -inf,
        -75.5511, -85.7328,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -58.8898,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 722: Reward=-212.66, route=[0, 6, 5, 1, 3, 9, 4, 2, 8, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.4933, -72.0511, -68.1587, -70.0228, -68.8371, -54.6782,
        -67.2806, -73.7262, -70.2791], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.8024, -71.9678, -74.9974, -74.6696, -62.0854,     -inf,
        -63.8498, -67.0946, -77.9504], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.4232, -72.5402, -80.5805, -78.9115,     -inf,     -inf,
        -60.5515, -61.3567, -83.9797], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8244,     -inf, -68.2879,     -inf,     -inf,
            -inf, -79.7381, -64.9302], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.6953,     -inf, -65.2254,     -inf,     -inf,
            -inf, -88.4510,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.1621,     -inf,     -inf,     -inf,     -inf,
            -inf, -85.7050,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -73.9433,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 723: Reward=-232.06, route=[0, 6, 5, 7, 3, 1, 9, 4, 2, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False  True]
greedy_action q_values = tensor([    -inf, -60.5205, -69.8947, -60.2959,     -inf, -77.7991, -61.0732,
        -75.2185, -85.3416,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False  True]
greedy_action q_values = tensor([    -inf, -58.7711, -73.4297,     -inf,     -inf, -82.6080, -64.2553,
        -74.6322, -86.8821,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.9289,     -inf,     -inf,     -inf, -47.6759,
        -59.4320,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.7447,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 724: Reward=-252.42, route=[0, 9, 4, 3, 1, 5, 8, 6, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.4990, -73.1851, -68.6552, -70.3038, -69.1220, -55.7441,
        -68.0250, -74.0105, -70.3142], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -60.8099, -71.2575, -61.2144,     -inf, -78.1011,     -inf,
        -76.0950, -85.7016, -62.4535], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -71.1102,     -inf, -66.6652,     -inf,
        -69.4082, -74.0637,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -80.8569,     -inf,     -inf,     -inf,
        -61.4772, -61.8965,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.3013,     -inf,     -inf,     -inf,
            -inf, -66.0653,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.7897,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 725: Reward=-264.31, route=[0, 6, 4, 1, 9, 2, 5, 7, 8, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.4990, -73.1851, -68.6552, -70.3038, -69.1220, -55.7441,
        -68.0250, -74.0105, -70.3142], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.8194, -73.0880, -75.5238, -74.9433, -62.3456,     -inf,
        -64.6003, -67.3580, -78.0056], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.4466, -73.6571, -81.1266, -79.1808,     -inf,     -inf,
        -61.3087, -61.6079, -84.0442], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -67.2827, -76.8563, -76.5710, -77.9983,     -inf,     -inf,
            -inf, -65.7766, -78.3851], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.3969, -76.3572, -83.0594, -82.1657,     -inf,     -inf,
            -inf,     -inf, -85.6697], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.1592, -64.3502, -68.7930,     -inf,     -inf,
            -inf,     -inf, -65.1253], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.1560,     -inf, -64.2971,     -inf,     -inf,
            -inf,     -inf, -58.3028], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.6102,     -inf, -66.6566,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.8670,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 726: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -70.6752, -77.5168, -83.4701, -82.6992, -56.7530, -48.7385,
        -59.8596,     -inf, -86.1748], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -67.5237, -74.6276, -76.4317, -75.9314, -62.3604,     -inf,
        -65.2914,     -inf, -79.0187], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -70.1516, -75.1849, -82.0468, -80.1545,     -inf,     -inf,
        -62.0094,     -inf, -85.0542], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.9814, -78.4368, -77.4710, -79.0043,     -inf,     -inf,
            -inf,     -inf, -79.3820], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.7361,     -inf, -65.2645,     -inf,     -inf,
            -inf,     -inf, -59.2703], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.6102,     -inf, -66.6566,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.8670,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 727: Reward=-205.52, route=[0, 8, 6, 5, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.1489, -74.6738, -69.4974, -71.2559, -69.1097, -56.9792,
        -68.6837, -73.8536, -71.3041], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.4735, -74.5523, -76.3880, -75.8757, -62.3105,     -inf,
        -65.2678, -67.1860, -79.0014], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.1015, -75.1096, -82.0031, -80.0988,     -inf,     -inf,
        -61.9859, -61.4289, -85.0368], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -61.6056, -72.8813, -62.1581,     -inf,     -inf,     -inf,
        -76.9536,     -inf, -63.4977], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.5647, -64.9805,     -inf,     -inf,     -inf,
        -71.7662,     -inf, -65.9364], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.5907,     -inf,     -inf,     -inf,     -inf,
        -76.3708,     -inf, -59.1192], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.4821,     -inf,     -inf,     -inf,     -inf,
        -76.5302,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 728: Reward=-238.06, route=[0, 6, 5, 8, 4, 1, 3, 9, 7, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.6994, -75.8819, -77.5808, -76.9461,     -inf,     -inf,
        -65.8222, -66.8875, -80.5383], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -69.0677, -79.6636, -78.5565, -79.9883,     -inf,     -inf,
            -inf, -65.1469, -80.8237], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.1963, -79.0872, -85.0148, -84.0466,     -inf,     -inf,
            -inf,     -inf, -88.1031], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.0444, -66.2800, -70.8572,     -inf,     -inf,
            -inf,     -inf, -67.5726], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.0209,     -inf, -67.6736,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 729: Reward=-202.8, route=[0, 5, 6, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False  True False]
greedy_action q_values = tensor([    -inf, -71.7935,     -inf, -84.5418, -83.6281, -56.5200, -49.8334,
        -60.3985,     -inf, -87.5716], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -68.6423,     -inf, -77.5272, -76.8992, -62.0877,     -inf,
        -65.7910,     -inf, -80.4346], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.2685,     -inf, -83.1524, -81.1057,     -inf,     -inf,
        -62.5197,     -inf, -86.4689], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.1031,     -inf, -78.5666, -79.9958,     -inf,     -inf,
            -inf,     -inf, -80.7933], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -66.2469, -70.8092,     -inf,     -inf,
            -inf,     -inf, -67.5253], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.2614,     -inf,     -inf,
            -inf,     -inf, -60.6606], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -67.6646,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 730: Reward=-220.12, route=[0, 2, 8, 6, 5, 7, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.2823, -75.9543, -70.6088, -72.2954, -68.7899, -58.0197,
        -69.1141, -73.4164, -72.7615], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.6070, -75.8130, -77.5172, -76.8917, -61.9684,     -inf,
        -65.7094, -66.7370, -80.4650], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5524, -77.5480, -84.3326, -82.6149,     -inf,     -inf,
        -62.6969, -60.1889, -88.1129], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.4895, -80.2093, -86.0555, -85.4284,     -inf,     -inf,
        -60.9500,     -inf, -89.6408], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -64.0365, -75.4179, -64.1471,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.1824, -67.2250,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 731: Reward=-222.89, route=[0, 6, 5, 8, 7, 9, 4, 1, 3, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.6290, -77.1766, -71.7985, -73.8851, -68.1094, -58.6618,
        -69.3303, -72.5966, -74.4281], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -62.1783, -79.1489,     -inf, -67.5458, -82.2619,     -inf,
        -77.0752, -86.2712, -62.0486], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -68.2964,     -inf,     -inf,     -inf,     -inf,     -inf,
        -70.8673,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -72.5597,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 732: Reward=-269.21, route=[0, 6, 3, 9, 5, 8, 4, 2, 1, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.6290, -77.1766, -71.7985, -73.8851, -68.1094, -58.6618,
        -69.3303, -72.5966, -74.4281], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.9494, -77.0144, -78.7250, -78.4535, -61.2690,     -inf,
        -65.9318, -65.9075, -82.1344], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5524, -77.5480, -84.3326, -82.6149,     -inf,     -inf,
        -62.6969, -60.1889, -88.1129], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.4895, -80.2093, -86.0555, -85.4284,     -inf,     -inf,
        -60.9500,     -inf, -89.6408], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.6244, -81.5790, -80.5108, -82.6783,     -inf,     -inf,
            -inf,     -inf, -84.0143], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.9279, -68.1155, -73.5647,     -inf,     -inf,
            -inf,     -inf, -70.7571], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.0161,     -inf, -68.7150,     -inf,     -inf,
            -inf,     -inf, -63.6449], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -83.0476,     -inf, -70.1522,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.9417,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 733: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.7778, -77.7473, -72.4730, -74.9115, -67.4204, -59.0849,
        -69.6156, -71.3616, -75.9258], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0974, -77.5741, -79.4268, -79.4636, -60.5602,     -inf,
        -66.2237, -64.6621, -83.6379], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.6799, -78.0996, -85.0226, -83.5887,     -inf,     -inf,
        -63.0267, -58.9876, -89.5617], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.5534, -80.7927, -86.6111, -86.3438,     -inf,     -inf,
        -61.3712,     -inf, -90.9693], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.9279, -68.1155, -73.5647,     -inf,     -inf,
            -inf,     -inf, -70.7571], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.0161,     -inf, -68.7150,     -inf,     -inf,
            -inf,     -inf, -63.6449], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -83.0476,     -inf, -70.1522,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.9417,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 734: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -64.7794, -75.6394, -64.2749,     -inf, -76.7589, -65.6751,
        -77.9670, -83.5878, -67.4445], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
greedy_action q_values = tensor([    -inf, -63.0381, -79.4964,     -inf,     -inf, -81.5792, -68.9660,
        -77.2461, -85.0053, -63.1010], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -80.3510,     -inf,     -inf, -74.6291, -64.0650,
        -72.4171, -77.1853, -69.9935], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.4417,     -inf,     -inf, -60.6801,     -inf,
        -66.3063, -64.8381, -83.3658], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.9688,     -inf,     -inf,     -inf,     -inf,
        -63.1020, -59.1522, -89.3021], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.1578,     -inf,     -inf,     -inf,     -inf,
        -61.7819,     -inf, -91.4092], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.9034,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.7032], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.4136], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 735: Reward=-241.22, route=[0, 4, 3, 1, 6, 5, 8, 7, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.7848, -77.1923, -72.4864, -75.1597, -66.4107, -59.2693,
        -69.8282, -70.0856, -76.8867], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -65.9988, -75.2527, -64.4188,     -inf, -75.9061,     -inf,
        -78.4571, -82.5760, -68.6509], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf, -64.2554, -79.1308,     -inf,     -inf, -80.7381,     -inf,
        -77.7200, -83.9794, -64.2888], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.4059,     -inf,     -inf,     -inf,     -inf,
        -63.3579, -57.9079, -90.2246], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.1578,     -inf,     -inf,     -inf,     -inf,
        -61.7819,     -inf, -91.4092], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.9034,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.7032], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -80.4136], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 736: Reward=-256.39, route=[0, 6, 4, 3, 1, 5, 8, 7, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.7848, -77.1923, -72.4864, -75.1597, -66.4107, -59.2693,
        -69.8282, -70.0856, -76.8867], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.1070, -77.0150, -79.4720, -79.7030, -59.5314,     -inf,
        -66.4435, -63.3751, -84.6097], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.6467, -77.5450, -85.0242, -83.7831,     -inf,     -inf,
        -63.3039, -57.7809, -90.4440], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -75.3899, -80.2861, -86.4213, -86.4646,     -inf,     -inf,
        -61.7539,     -inf, -91.6336], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -80.3781, -68.0891, -73.8273,     -inf,     -inf,
            -inf,     -inf, -71.7117], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.4639,     -inf, -68.8958,     -inf,     -inf,
            -inf,     -inf, -64.5397], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -82.5269,     -inf, -70.3257,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 737: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -65.0285, -78.3132,     -inf, -68.3910, -79.7403, -69.2158,
        -77.8046, -83.1112, -64.7601], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -64.9334, -81.4068,     -inf, -69.8079, -82.8956, -71.5133,
        -77.9111, -84.3226,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.1212,     -inf, -73.0545, -72.7574, -64.3131,
        -72.9062, -75.2005,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.1944,     -inf, -79.3622, -58.7388,     -inf,
        -66.8104, -62.8354,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.4863,     -inf,     -inf,     -inf,     -inf,
        -78.9390, -82.1772,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -71.6871, -69.6201,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -62.1532,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 738: Reward=-220.95, route=[0, 3, 9, 1, 6, 5, 4, 2, 8, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -65.0218, -81.4784, -60.1595, -69.9350, -82.8677, -71.4960,
        -77.9101, -84.2791,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -64.9654, -78.2526,     -inf, -68.2749, -79.8156, -69.2661,
        -77.8450, -83.1851,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.3003,     -inf,     -inf, -75.1036, -66.0211,
        -78.6603,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.1862,     -inf,     -inf, -58.7694,     -inf,
        -66.8117,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.7456,     -inf,     -inf,     -inf,     -inf,
        -63.7348,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.1435,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 739: Reward=-260.18, route=[0, 9, 3, 1, 8, 4, 6, 5, 7, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.9727,     -inf,     -inf, -71.8556, -64.1343,
        -73.1895, -74.9478, -71.6990], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.0614,     -inf,     -inf, -57.7998,     -inf,
        -67.0939, -62.5548, -85.1764], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.5058,     -inf,     -inf,     -inf,     -inf,
        -78.5635, -84.4900,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.9697,     -inf,     -inf,     -inf,     -inf,
            -inf, -60.9971,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.4335,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 740: Reward=-252.08, route=[0, 4, 3, 1, 6, 5, 9, 7, 8, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False  True False]
greedy_action q_values = tensor([    -inf, -71.7541,     -inf, -74.0110, -74.3003, -61.9160, -57.4424,
        -71.6718,     -inf, -81.0289], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -73.5323,     -inf, -78.5373, -78.9990, -57.8057,     -inf,
        -67.1029,     -inf, -85.4125], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -75.8940,     -inf, -83.8745, -82.9624,     -inf,     -inf,
        -64.1255,     -inf, -90.9600], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -66.9375, -73.0665,     -inf,     -inf,
            -inf,     -inf, -72.4076], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.1930,     -inf,     -inf,
            -inf,     -inf, -65.2886], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.5950,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 741: Reward=-224.92, route=[0, 8, 2, 6, 5, 7, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True False False False  True]
greedy_action q_values = tensor([    -inf, -65.3904, -78.4153,     -inf, -68.1307,     -inf, -71.0494,
        -78.0592, -84.1475,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.1360,     -inf, -71.2586,     -inf, -63.8413,
        -73.1933, -75.1916,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.2485,     -inf, -77.5885,     -inf,     -inf,
        -67.1048, -62.7728,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.5665,     -inf, -84.2672,     -inf,     -inf,
        -62.3541,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.2184,     -inf, -80.7782,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.2050,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 742: Reward=-271.25, route=[0, 3, 5, 9, 1, 6, 8, 7, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.0790, -73.4593, -70.4362, -73.3016, -63.5154, -58.6496,
        -70.1914, -69.0593, -77.0305], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.4309, -73.2907, -77.5388, -77.8498, -56.5684,     -inf,
        -66.8109, -62.3062, -84.8322], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.7353, -73.8982, -82.8044, -81.7643,     -inf,     -inf,
        -63.9044, -57.1011, -90.2685], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -76.4568, -76.6699, -84.2228, -84.5065,     -inf,     -inf,
        -62.2730,     -inf, -91.4203], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.9444, -77.3273, -78.5324, -81.0903,     -inf,     -inf,
            -inf,     -inf, -85.1262], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.6004, -65.8640, -71.9392,     -inf,     -inf,
            -inf,     -inf, -71.7472], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.6416,     -inf, -67.0947,     -inf,     -inf,
            -inf,     -inf, -64.6353], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.7515,     -inf, -68.4813,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 743: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -70.0790, -73.4593, -70.4362, -73.3016, -63.5154, -58.6496,
        -70.1914, -69.0593, -77.0305], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.3942, -65.6731, -71.7344, -70.8323,     -inf,
        -73.1613, -74.9587, -71.5766], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.1402, -60.9811,     -inf,
        -71.7497, -69.2244, -80.5147], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -67.3328,     -inf,     -inf,
        -77.9692, -84.4213,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -62.0272,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 744: Reward=-282.8, route=[0, 6, 1, 3, 2, 5, 9, 4, 8, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.6318, -71.6054, -69.5447, -72.2840, -62.7924, -58.1788,
        -69.8780, -69.0604, -76.2555], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.9988, -71.4446, -76.6916, -76.8349, -55.8203,     -inf,
        -66.4991, -62.2893, -84.0957], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -65.2904, -73.4901,     -inf,     -inf,     -inf,     -inf,
        -77.7685, -82.9795, -63.7077], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf, -65.0962, -76.6109,     -inf,     -inf,     -inf,     -inf,
        -77.8181, -84.1957,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.3526,     -inf,     -inf,     -inf,     -inf,
        -73.0205, -75.2996,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.2109,     -inf,     -inf,     -inf,     -inf,
            -inf, -60.9089,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.7174,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 745: Reward=-207.52, route=[0, 6, 5, 4, 3, 9, 1, 7, 8, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.6318, -71.6054, -69.5447, -72.2840, -62.7924, -58.1788,
        -69.8780, -69.0604, -76.2555], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4557,     -inf, -72.3785, -72.2853, -60.0960,     -inf,
        -71.3438, -69.0288, -79.9689], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -75.2932,     -inf, -81.9407, -80.7002,     -inf,     -inf,
        -63.6506, -57.1803, -89.5049], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -75.9967,     -inf, -83.3703, -83.4628,     -inf,     -inf,
        -61.9812,     -inf, -90.6376], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.4726,     -inf, -77.6080, -80.0116,     -inf,     -inf,
            -inf,     -inf, -84.2942], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -64.8604, -70.8446,     -inf,     -inf,
            -inf,     -inf, -70.8519], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -65.3708,     -inf,     -inf,
            -inf,     -inf, -63.1115], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.7364,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 746: Reward=-193.15, route=[0, 6, 2, 5, 8, 7, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.0216, -70.0391, -68.8420, -71.5037, -62.1073, -57.6880,
        -69.2667, -69.3957, -75.5756], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.4049, -69.8805, -76.0312, -76.0580, -55.1088,     -inf,
        -65.8904, -62.6048, -83.4528], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -64.7263, -71.9744,     -inf, -65.2471,     -inf,     -inf,
        -77.1489, -83.3540, -63.0625], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -64.5154, -75.0905,     -inf, -66.6128,     -inf,     -inf,
        -77.1777, -84.5729,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.8543,     -inf, -69.6625,     -inf,     -inf,
        -72.4237, -75.6887,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.8652,     -inf,     -inf,     -inf,     -inf,
        -78.0730, -82.1659,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -71.0218, -69.8270,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -61.4021,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 747: Reward=-218.62, route=[0, 6, 5, 3, 9, 1, 4, 2, 8, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.0216, -70.0391, -68.8420, -71.5037, -62.1073, -57.6880,
        -69.2667, -69.3957, -75.5756], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.4049, -69.8805, -76.0312, -76.0580, -55.1088,     -inf,
        -65.8904, -62.6048, -83.4528], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.7122, -70.5086, -81.3266, -79.9700,     -inf,     -inf,
        -63.0032, -57.4091, -88.9035], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -75.4062, -73.2879, -82.7450, -82.7334,     -inf,     -inf,
        -61.3173,     -inf, -90.0224], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.8779, -73.9179, -76.9664, -79.2928,     -inf,     -inf,
            -inf,     -inf, -83.6749], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.1295, -64.1441, -70.1091,     -inf,     -inf,
            -inf,     -inf, -70.1722], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.1331,     -inf, -65.3857,     -inf,     -inf,
            -inf,     -inf, -63.1290], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.2484,     -inf, -66.7521,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.0022,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 748: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.3788, -68.6786, -68.1551, -70.6718, -61.7628, -57.0347,
        -68.6893, -69.8235, -74.6961], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.7817, -68.5337, -75.3889, -75.2379, -54.7400,     -inf,
        -65.3181, -63.0132, -82.6153], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.1238, -69.1755, -80.7470, -79.1780,     -inf,     -inf,
        -62.4127, -57.7701, -88.1295], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.8066, -71.9609, -82.1633, -81.9502,     -inf,     -inf,
        -60.7044,     -inf, -89.2348], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.2333, -72.5794, -76.2964, -78.4713,     -inf,     -inf,
            -inf,     -inf, -82.7992], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7447, -63.3959, -69.2554,     -inf,     -inf,
            -inf,     -inf, -69.2261], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7192,     -inf, -64.5890,     -inf,     -inf,
            -inf,     -inf, -62.2146], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.8316,     -inf, -65.9545,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -66.5865,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 749: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.3788, -68.6786, -68.1551, -70.6718, -61.7628, -57.0347,
        -68.6893, -69.8235, -74.6961], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.7817, -68.5337, -75.3889, -75.2379, -54.7400,     -inf,
        -65.3181, -63.0132, -82.6153], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -65.9457, -66.6323, -60.3066,     -inf,     -inf,     -inf,
        -77.3562,     -inf, -66.7356], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -64.0729, -70.5490,     -inf,     -inf,     -inf,     -inf,
        -76.4855,     -inf, -62.0974], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -63.8444, -73.6615,     -inf,     -inf,     -inf,     -inf,
        -76.4943,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.4548,     -inf,     -inf,     -inf,     -inf,
        -71.8365,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 750: Reward=-233.47, route=[0, 6, 5, 8, 4, 3, 9, 1, 2, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.3788, -68.6786, -68.1551, -70.6718, -61.7628, -57.0347,
        -68.6893, -69.8235, -74.6961], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.7817, -68.5337, -75.3889, -75.2379, -54.7400,     -inf,
        -65.3181, -63.0132, -82.6153], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -63.3559, -69.2188,     -inf, -63.7994,     -inf,     -inf,
        -75.6472, -84.3501, -61.2583], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -69.4243,     -inf,     -inf,     -inf,     -inf,     -inf,
        -69.6231,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -71.0935,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 751: Reward=-280.3, route=[0, 6, 5, 3, 9, 4, 8, 2, 1, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.6612, -67.3704, -67.6080, -69.9706, -61.4222, -56.4522,
        -67.8935, -70.4435, -73.8195], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0830, -67.2346, -74.8792, -74.5452, -54.3751,     -inf,
        -64.5199, -63.6144, -81.7758], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4456, -67.9158, -80.3033, -78.5210,     -inf,     -inf,
        -61.5701, -58.3169, -87.3217], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.1330, -70.6684, -81.6927, -81.2772,     -inf,     -inf,
        -59.8684,     -inf, -88.4401], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -63.4547, -69.3519,     -inf, -63.9435,     -inf,     -inf,
            -inf,     -inf, -61.3430], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -63.2058, -72.4605,     -inf, -65.3090,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -65.2979,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 752: Reward=-185.9, route=[0, 6, 5, 8, 7, 3, 9, 1, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False False False False]
greedy_action q_values = tensor([    -inf, -69.2175,     -inf, -70.1538,     -inf, -58.6319, -54.7259,
        -69.1966, -70.2974, -77.1982], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9944,     -inf, -74.7360,     -inf, -54.4302,     -inf,
        -64.5573, -63.7079, -81.6259], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.8480,     -inf, -80.0393,     -inf,     -inf,     -inf,
        -60.5426, -58.6341, -86.8233], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -70.8303,     -inf, -75.3113,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -62.3028,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 753: Reward=-228.0, route=[0, 4, 2, 6, 5, 8, 9, 7, 1, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1512, -66.5958, -67.4658, -69.9343, -61.1008, -55.9151,
        -66.8207, -70.6624, -73.4698], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.5892, -66.4622, -74.7666, -74.5087, -54.0334,     -inf,
        -63.4478, -63.8183, -81.4539], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -62.6378, -71.6274, -55.3681, -65.2662,     -inf,     -inf,
        -74.5155, -85.8101,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -62.7533, -68.3734,     -inf, -63.6444,     -inf,     -inf,
        -74.6007, -84.6924,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.3460,     -inf, -77.3811,     -inf,     -inf,
            -inf, -62.4875,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.8531,     -inf, -81.0259,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.7727,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 754: Reward=-215.26, route=[0, 6, 5, 9, 3, 1, 7, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.5892, -66.4622, -74.7666, -74.5087, -54.0334,     -inf,
        -63.4478, -63.8183, -81.4539], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.6001, -69.9017, -81.4884, -81.1716,     -inf,     -inf,
        -58.8698,     -inf, -88.0504], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.9940, -70.5272, -75.6193, -77.7459,     -inf,     -inf,
            -inf,     -inf, -81.5592], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -64.3948,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 755: Reward=-218.42, route=[0, 6, 5, 8, 7, 2, 9, 3, 4, 1] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.9050, -66.5104, -67.7026, -70.4423, -60.7702, -55.1507,
        -65.5118, -70.3591, -73.4528], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.3602, -66.3683, -75.0362, -75.0157, -53.6836,     -inf,
        -62.1372, -63.5004, -81.4627], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.6477, -67.0606, -80.3442, -78.9226,     -inf,     -inf,
        -59.2857, -58.3626, -86.8755], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.2581, -69.8130, -81.5605, -81.5127,     -inf,     -inf,
        -57.7505,     -inf, -87.8974], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.7482, -70.4588, -75.8720, -78.2703,     -inf,     -inf,
            -inf,     -inf, -81.5397], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.9970,     -inf, -70.8280, -70.5914,     -inf,     -inf,
            -inf,     -inf, -77.4451], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -64.2818,     -inf,     -inf,
            -inf,     -inf, -60.7277], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -65.6758,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 756: Reward=-210.68, route=[0, 6, 5, 8, 7, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.9050, -66.5104, -67.7026, -70.4423, -60.7702, -55.1507,
        -65.5118, -70.3591, -73.4528], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -69.3832, -62.6490, -68.8421, -68.2418,     -inf,
        -68.3846, -76.4034, -67.6925], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -68.3369,     -inf, -64.0904, -75.4030,     -inf,
        -73.2927, -84.4727, -60.5838], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.4711,     -inf, -65.4844, -78.6974,     -inf,
        -73.2269, -85.7065,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -64.2171,     -inf,     -inf, -70.3818,     -inf,
        -74.2057, -83.0760,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -58.2449,     -inf,
        -67.2185, -70.6791,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -59.4293, -58.6387,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -57.1638,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 757: Reward=-197.01, route=[0, 6, 1, 3, 9, 4, 2, 5, 8, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.7693, -66.9383, -68.2677, -71.3690, -60.5030, -54.4596,
        -64.6479, -69.9762, -73.6910], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.4214, -67.4716, -80.8051, -79.7411,     -inf,     -inf,
        -58.5572, -58.1289, -86.9957], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -62.1213, -72.1730, -55.7849, -66.5759,     -inf,     -inf,
        -72.4924,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -64.1262, -64.7124,     -inf,     -inf,     -inf,     -inf,
        -73.5706,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.7432,     -inf,     -inf,     -inf,     -inf,
        -67.7297,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.7034,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 758: Reward=-230.69, route=[0, 6, 5, 8, 9, 3, 4, 1, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.7693, -66.9383, -68.2677, -71.3690, -60.5030, -54.4596,
        -64.6479, -69.9762, -73.6910], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.2363, -66.7810, -75.6290, -75.9371, -53.3989,     -inf,
        -61.2759, -63.1048, -81.7231], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.0178, -70.2301, -81.9385, -82.2641,     -inf,     -inf,
        -57.0967,     -inf, -87.9861], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.6091, -70.9051, -76.4544, -79.2160,     -inf,     -inf,
            -inf,     -inf, -81.7767], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 759: Reward=-215.31, route=[0, 6, 5, 8, 7, 1, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.7693, -66.9383, -68.2677, -71.3690, -60.5030, -54.4596,
        -64.6479, -69.9762, -73.6910], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.1120, -67.3378, -76.2476, -76.8350, -53.6838,     -inf,
        -60.7339, -63.0685, -81.9060], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.2291, -68.0136, -81.2977, -80.5100,     -inf,     -inf,
        -58.1701, -58.2104, -87.0890], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -62.1589, -69.5715,     -inf, -65.9304,     -inf,     -inf,
            -inf, -84.4083, -60.9310], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -61.8518, -72.7676,     -inf, -67.3749,     -inf,     -inf,
            -inf, -85.6406,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.4412,     -inf, -70.5588,     -inf,     -inf,
            -inf, -76.3730,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.0252,     -inf,     -inf,
            -inf, -70.4846,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -82.8630,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 760: Reward=-254.12, route=[0, 6, 5, 7, 3, 9, 1, 2, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.6337, -67.5122, -68.8603, -72.2732, -60.8071, -53.8874,
        -64.1045, -69.9515, -73.8546], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.1120, -67.3378, -76.2476, -76.8350, -53.6838,     -inf,
        -60.7339, -63.0685, -81.9060], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.2291, -68.0136, -81.2977, -80.5100,     -inf,     -inf,
        -58.1701, -58.2104, -87.0890], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.4298, -71.4297, -77.0450, -80.1006,     -inf,     -inf,
            -inf, -61.4098, -81.9426], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.8597, -70.8548, -82.5058, -83.1365,     -inf,     -inf,
            -inf,     -inf, -88.1317], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.7545,     -inf, -72.0170, -72.3925,     -inf,     -inf,
            -inf,     -inf, -77.8946], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -63.8558, -70.8363,     -inf,     -inf,
            -inf,     -inf, -68.0926], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 761: Reward=-217.19, route=[0, 6, 5, 7, 8, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -61.7017, -69.2039,     -inf, -65.4482, -75.5938, -63.9526,
        -71.8207, -84.1890,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.6613,     -inf, -70.9110, -69.3435, -59.0620,
        -66.8358, -77.0596,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.6954,     -inf, -77.2073, -54.7974,     -inf,
        -60.8886, -64.3145,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.6193,     -inf,     -inf,
        -66.0020, -71.4598,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 762: Reward=-279.4, route=[0, 9, 3, 1, 6, 5, 2, 7, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.4527, -67.9976, -69.1411, -72.9782, -61.6802, -53.8903,
        -64.0738, -70.8863, -73.4315], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.9448, -67.8088, -76.5576, -77.5367, -54.5335,     -inf,
        -60.7048, -63.9869, -81.5108], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.1359, -68.4573, -81.6991, -81.2265,     -inf,     -inf,
        -58.1220, -59.0227, -86.8270], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.2478, -71.9343, -77.3439, -80.8258,     -inf,     -inf,
            -inf, -62.3374, -81.5188], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -63.9991, -65.9881, -61.0135,     -inf,     -inf,     -inf,
            -inf,     -inf, -65.3265], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -61.9637, -70.0845,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -60.4141], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -61.6442, -73.3104,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.9414,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 763: Reward=-212.9, route=[0, 6, 5, 7, 8, 4, 3, 9, 1, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.4527, -67.9976, -69.1411, -72.9782, -61.6802, -53.8903,
        -64.0738, -70.8863, -73.4315], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -61.8058, -69.9654,     -inf, -66.5395, -76.5174,     -inf,
        -71.9129, -85.2264, -60.3174], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf, -61.4864, -73.1913,     -inf, -68.0093, -79.8742,     -inf,
        -71.7953, -86.4696,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.8355,     -inf, -71.1408, -69.4099,     -inf,
        -67.0067, -77.1865,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.7914,     -inf, -81.2591, -57.6494,     -inf,
            -inf, -63.7557,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.3741,     -inf, -81.9520,     -inf,     -inf,
            -inf, -60.2527,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.1925,     -inf, -84.5269,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 764: Reward=-214.39, route=[0, 6, 3, 9, 1, 7, 5, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.8503, -63.8786, -72.0243, -70.6910, -59.4998,
        -66.9789, -78.1834, -66.8395], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -68.8311, -76.7604, -78.3001, -56.0617,     -inf,
        -61.0437, -65.3852, -81.1412], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.4439, -56.7169, -69.1169,     -inf,     -inf,
        -72.1596, -87.9823,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.3888,     -inf,     -inf,
        -66.2666, -72.7535,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.2333,     -inf,     -inf,
            -inf, -64.0715,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.4889,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 765: Reward=-273.47, route=[0, 1, 6, 5, 9, 3, 2, 7, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.4886, -69.0027, -69.3324, -73.7622, -63.1125, -54.3863,
        -64.3161, -72.1619, -73.0676], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.9916, -68.8003, -76.7802, -78.3199, -55.9380,     -inf,
        -60.9533, -65.2444, -81.1763], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.3184, -69.4191, -82.1293, -82.0995,     -inf,     -inf,
        -58.2646, -60.0641, -86.7307], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.1578, -64.3098, -72.4017,     -inf,     -inf,
            -inf, -78.4846, -67.2948], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.1855,     -inf, -67.5782,     -inf,     -inf,
            -inf, -86.7614, -60.0772], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 766: Reward=-214.92, route=[0, 6, 5, 7, 1, 3, 9, 4, 2, 8] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False  True False]
greedy_action q_values = tensor([    -inf, -72.7829,     -inf, -83.2654,     -inf, -53.0583,     -inf,
        -56.8941,     -inf, -87.2910], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.3846,     -inf, -82.2557,     -inf,     -inf,     -inf,
        -58.5229,     -inf, -86.4719], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -63.9349,     -inf,     -inf,     -inf,
            -inf,     -inf, -66.5326], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -59.4978], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 767: Reward=-206.84, route=[0, 2, 4, 6, 8, 5, 7, 1, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -69.7997, -73.7659, -77.0384, -81.6146, -59.0689, -51.4453,
            -inf, -64.9443, -80.2326], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -69.9087, -69.8684, -76.7062, -78.6558, -57.6843,     -inf,
            -inf, -66.8718, -80.7319], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.4520, -70.4496, -82.4074, -82.6278,     -inf,     -inf,
            -inf, -61.3359, -86.6423], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.0254, -73.2994, -83.5426, -85.2263,     -inf,     -inf,
            -inf,     -inf, -87.5945], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -56.8118, -69.6870,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 768: Reward=-242.31, route=[0, 7, 6, 5, 8, 1, 2, 9, 3, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.5694, -70.8982, -69.3159, -74.4308, -66.2635, -55.7896,
        -65.4284, -74.8613, -72.4483], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.0893, -70.6592, -76.8238, -78.9877, -59.0127,     -inf,
        -62.0616, -67.8858, -80.6080], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.7211, -71.2342, -82.7058, -83.0668,     -inf,     -inf,
        -59.0068, -62.1700, -86.6858], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.3578, -74.9136, -77.5762, -82.3482,     -inf,     -inf,
            -inf, -66.2831, -80.5373], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.6306, -57.0442, -70.2624,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.2062,     -inf, -68.4237,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.9194,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 769: Reward=-181.61, route=[0, 6, 5, 7, 8, 1, 9, 3, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.5694, -70.8982, -69.3159, -74.4308, -66.2635, -55.7896,
        -65.4284, -74.8613, -72.4483], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.0893, -70.6592, -76.8238, -78.9877, -59.0127,     -inf,
        -62.0616, -67.8858, -80.6080], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.7211, -71.2342, -82.7058, -83.0668,     -inf,     -inf,
        -59.0068, -62.1700, -86.6858], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.3578, -74.9136, -77.5762, -82.3482,     -inf,     -inf,
            -inf, -66.2831, -80.5373], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.3792, -74.1639, -83.9805, -85.7962,     -inf,     -inf,
            -inf,     -inf, -87.7623], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.2247, -64.2411, -73.1369,     -inf,     -inf,
            -inf,     -inf, -66.5824], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.2719,     -inf, -68.5487,     -inf,     -inf,
            -inf,     -inf, -59.5229], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.5596,     -inf, -70.1299,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 770: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.5694, -70.8982, -69.3159, -74.4308, -66.2635, -55.7896,
        -65.4284, -74.8613, -72.4483], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.0893, -70.6592, -76.8238, -78.9877, -59.0127,     -inf,
        -62.0616, -67.8858, -80.6080], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.1009, -72.1539, -83.2473, -83.7064,     -inf,     -inf,
        -59.5824, -62.4576, -87.2492], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.7333, -75.8774, -78.0919, -83.0113,     -inf,     -inf,
            -inf, -66.5881, -81.0754], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.7742, -75.1015, -84.5473, -86.4599,     -inf,     -inf,
            -inf,     -inf, -88.3486], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.2095, -64.7136, -73.7963,     -inf,     -inf,
            -inf,     -inf, -67.0959], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.9359,     -inf,     -inf,
            -inf,     -inf, -76.9036], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 771: Reward=-226.79, route=[0, 6, 5, 7, 8, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.9478, -71.8339, -69.8119, -75.0707, -67.0283, -56.1900,
        -66.0076, -75.1892, -72.9837], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.1009, -72.1539, -83.2473, -83.7064,     -inf,     -inf,
        -59.5824, -62.4576, -87.2492], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.7333, -75.8774, -78.0919, -83.0113,     -inf,     -inf,
            -inf, -66.5881, -81.0754], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -64.6660, -69.9293, -61.9082,     -inf,     -inf,     -inf,
            -inf,     -inf, -65.1580], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.0312,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -66.8255], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.5126,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 772: Reward=-227.33, route=[0, 6, 5, 7, 8, 4, 3, 1, 9, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.9478, -71.8339, -69.8119, -75.0707, -67.0283, -56.1900,
        -66.0076, -75.1892, -72.9837], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4728, -71.5791, -77.3452, -79.6249, -59.7513,     -inf,
        -62.6379, -68.1892, -81.1621], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.1009, -72.1539, -83.2473, -83.7064,     -inf,     -inf,
        -59.5824, -62.4576, -87.2492], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.7333, -75.8774, -78.0919, -83.0113,     -inf,     -inf,
            -inf, -66.5881, -81.0754], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.1142, -76.0229, -85.0185, -86.9845,     -inf,     -inf,
            -inf,     -inf, -88.7317], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.7026, -57.8772, -71.4900,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.7657,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 773: Reward=-181.61, route=[0, 6, 5, 7, 8, 1, 9, 3, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3249, -72.7631, -70.3207, -75.6461, -67.2295, -56.3891,
        -66.2622, -74.9902, -73.4060], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8534, -72.4894, -77.8783, -80.1950, -59.9292,     -inf,
        -62.8883, -67.9651, -81.6067], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.4429,     -inf, -73.4734, -75.5407,     -inf,     -inf,
        -68.0976, -75.2866, -77.5146], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -62.9009,     -inf,     -inf, -69.6641,     -inf,     -inf,
            -inf, -89.6852, -60.3654], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf, -62.6059,     -inf,     -inf, -71.2805,     -inf,     -inf,
            -inf, -90.9806,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.9601,     -inf,     -inf,
            -inf, -81.8306,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 774: Reward=-258.43, route=[0, 6, 5, 2, 7, 3, 9, 1, 4, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3249, -72.7631, -70.3207, -75.6461, -67.2295, -56.3891,
        -66.2622, -74.9902, -73.4060], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8534, -72.4894, -77.8783, -80.1950, -59.9292,     -inf,
        -62.8883, -67.9651, -81.6067], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4708, -73.0508, -83.7606, -84.2397,     -inf,     -inf,
        -59.8753, -62.2468, -87.6853], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.1176, -65.1852, -74.3535,     -inf,     -inf,
            -inf, -81.4937, -67.5039], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -75.1952,     -inf, -69.6799,     -inf,     -inf,
            -inf, -89.7457, -60.3638], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -75.5871,     -inf,     -inf,
            -inf, -75.2128,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -87.0040,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 775: Reward=-251.41, route=[0, 6, 5, 7, 1, 3, 9, 2, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.5255, -73.2312, -70.5290, -75.9486, -67.3478, -56.7937,
        -66.4546, -74.5631, -73.5599], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.5615,     -inf, -73.6491, -75.7762, -64.4549,     -inf,
        -68.1657, -74.6650, -77.6317], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.6593,     -inf, -83.9634, -84.4877,     -inf,     -inf,
        -60.1202, -61.8887, -87.8143], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.2714,     -inf, -78.7725, -83.8563,     -inf,     -inf,
            -inf, -66.0365, -81.5747], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.2895,     -inf, -85.2067, -87.2436,     -inf,     -inf,
            -inf,     -inf, -88.8374], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -62.4295,     -inf,     -inf,     -inf,
            -inf,     -inf, -65.5176], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -60.3082], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 776: Reward=-220.05, route=[0, 6, 2, 5, 7, 8, 1, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False False False  True False]
greedy_action q_values = tensor([    -inf, -73.7300, -76.0185,     -inf,     -inf, -55.1295, -49.1644,
        -58.1967,     -inf, -88.1504], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.3656,     -inf,     -inf, -75.3766,     -inf,
        -69.3893,     -inf, -67.2055], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.9229,     -inf,     -inf, -86.2215,     -inf,
        -74.2455,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.1245,     -inf,     -inf, -61.9701,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.5130,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 777: Reward=-256.41, route=[0, 4, 3, 8, 6, 1, 9, 7, 5, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.6318, -73.2935, -70.7026, -76.5846, -67.2510, -57.3722,
        -66.7579, -73.7704, -73.8648], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1733, -73.0002, -78.3188, -81.1288, -59.9031,     -inf,
        -63.3747, -66.6766, -82.1164], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.7552, -73.5719, -84.1799, -85.1484,     -inf,     -inf,
        -60.4003, -60.9785, -88.1535], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.4020, -77.4180, -79.0372, -84.5959,     -inf,     -inf,
            -inf, -65.0518, -81.9686], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.3553, -76.5869, -85.3801, -87.8993,     -inf,     -inf,
            -inf,     -inf, -89.1250], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.7838, -65.5125, -75.3660,     -inf,     -inf,
            -inf,     -inf, -67.8787], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.8614,     -inf, -70.5570,     -inf,     -inf,
            -inf,     -inf, -60.6084], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.2807,     -inf, -72.2300,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.2203,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 778: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.6318, -73.2935, -70.7026, -76.5846, -67.2510, -57.3722,
        -66.7579, -73.7704, -73.8648], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1733, -73.0002, -78.3188, -81.1288, -59.9031,     -inf,
        -63.3747, -66.6766, -82.1164], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.7552, -73.5719, -84.1799, -85.1484,     -inf,     -inf,
        -60.4003, -60.9785, -88.1535], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.3555,     -inf,     -inf,
            -inf, -74.3222, -77.8641], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -87.7325,     -inf,     -inf,
            -inf,     -inf, -88.9475], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 779: Reward=-270.41, route=[0, 6, 5, 7, 1, 3, 2, 8, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.6318, -73.2935, -70.7026, -76.5846, -67.2510, -57.3722,
        -66.7579, -73.7704, -73.8648], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -74.3107, -76.0170, -85.5101, -88.3835, -54.4558,     -inf,
        -59.3256,     -inf, -89.5441], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9424, -73.2070, -84.5171, -85.8391,     -inf,     -inf,
        -60.9651,     -inf, -88.7748], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -63.2082, -78.9139, -58.3003, -73.1023,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -70.0068,     -inf,     -inf, -77.0564,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -75.8225,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 780: Reward=-241.14, route=[0, 6, 8, 5, 7, 9, 3, 2, 1, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9447, -72.8305, -71.2694, -77.4040, -66.1595, -57.5385,
        -67.0850, -72.4726, -74.7492], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4877, -72.5303, -78.9063, -81.9344, -58.7954,     -inf,
        -63.7011, -65.3531, -83.0156], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.8865, -73.1345, -84.4809, -85.7844,     -inf,     -inf,
        -60.9446, -59.9439, -88.7571], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.0844, -79.6066, -85.4528,     -inf,     -inf,
            -inf,     -inf, -82.8003], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -61.2588], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 781: Reward=-216.2, route=[0, 6, 5, 8, 1, 7, 2, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9447, -72.8305, -71.2694, -77.4040, -66.1595, -57.5385,
        -67.0850, -72.4726, -74.7492], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4877, -72.5303, -78.9063, -81.9344, -58.7954,     -inf,
        -63.7011, -65.3531, -83.0156], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.8865, -73.1345, -84.4809, -85.7844,     -inf,     -inf,
        -60.9446, -59.9439, -88.7571], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.3682, -75.8657, -85.7428, -88.8852,     -inf,     -inf,
        -59.8093,     -inf, -90.2444], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.8189, -76.8259, -80.0112, -86.0495,     -inf,     -inf,
            -inf,     -inf, -83.6627], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.1224, -66.3963, -76.8005,     -inf,     -inf,
            -inf,     -inf, -69.5479], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.2115,     -inf, -71.7015,     -inf,     -inf,
            -inf,     -inf, -62.0463], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.7089,     -inf, -73.4042,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 782: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -73.5811, -72.7157, -84.3511, -85.9699,     -inf, -49.9169,
        -61.1053, -58.7447, -89.0325], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -65.5103, -70.4283, -62.9622,     -inf,     -inf,     -inf,
        -76.6789, -85.0469, -67.1960], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -63.3171, -74.9371,     -inf,     -inf,     -inf,     -inf,
        -75.5737, -86.5053, -61.9560], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -74.1629, -75.6313,     -inf,     -inf,     -inf,     -inf,
        -59.7819,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -71.5724, -76.5843,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.8755,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 783: Reward=-234.13, route=[0, 5, 6, 4, 3, 9, 8, 7, 1, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.0237, -72.5934, -71.6325, -77.9592, -65.0049, -57.5826,
        -67.2729, -71.2186, -75.5644], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.5713, -72.2792, -79.2936, -82.4836, -57.6179,     -inf,
        -63.8867, -64.0706, -83.8498], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.8235, -72.9039, -84.6251, -86.1978,     -inf,     -inf,
        -61.3118, -58.9019, -89.3438], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.3682, -75.8657, -85.7428, -88.8852,     -inf,     -inf,
        -59.8093,     -inf, -90.2444], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.8189, -76.8259, -80.0112, -86.0495,     -inf,     -inf,
            -inf,     -inf, -83.6627], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.5528, -66.6167, -77.3149,     -inf,     -inf,
            -inf,     -inf, -70.3847], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.6452,     -inf, -72.0893,     -inf,     -inf,
            -inf,     -inf, -62.7852], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.1804,     -inf, -73.8004,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.8631,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 784: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.0572, -72.0119, -71.8816, -78.4486, -63.7951, -57.4943,
        -67.4544, -70.0581, -76.4149], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.6088, -71.6904, -79.5683, -82.9649, -56.3852,     -inf,
        -64.0649, -62.8836, -84.7180], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.7066, -72.3410, -84.6524, -86.5383,     -inf,     -inf,
        -61.6773, -57.9642, -89.9573], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -63.0912, -78.1506, -58.3133, -73.8385,     -inf,     -inf,
        -75.8064,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -63.3278, -74.4702,     -inf, -71.8736,     -inf,     -inf,
        -75.9961,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.3308,     -inf, -76.8956,     -inf,     -inf,
        -70.6674,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.1499,     -inf, -86.2188,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.0407,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 785: Reward=-215.27, route=[0, 6, 5, 8, 9, 3, 1, 7, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.0572, -72.0119, -71.8816, -78.4486, -63.7951, -57.4943,
        -67.4544, -70.0581, -76.4149], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.6088, -71.6904, -79.5683, -82.9649, -56.3852,     -inf,
        -64.0649, -62.8836, -84.7180], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.7066, -72.3410, -84.6524, -86.5383,     -inf,     -inf,
        -61.6773, -57.9642, -89.9573], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.2407, -75.2988, -85.7452, -89.2122,     -inf,     -inf,
        -60.1918,     -inf, -90.8376], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.8437, -76.2631, -80.2786, -86.5604,     -inf,     -inf,
            -inf,     -inf, -84.5208], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.5528, -66.6167, -77.3149,     -inf,     -inf,
            -inf,     -inf, -70.3847], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.6452,     -inf, -72.0893,     -inf,     -inf,
            -inf,     -inf, -62.7852], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.5469,     -inf, -73.9589,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.1730,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 786: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9283, -71.3361, -71.9124, -78.6248, -62.7014, -57.4588,
        -67.7030, -69.5261, -77.1606], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4845, -71.0022, -79.6234, -83.1290, -55.2677,     -inf,
        -64.3098, -62.3199, -85.4823], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4882, -71.6644, -84.5486, -86.6138,     -inf,     -inf,
        -62.0372, -57.5549, -90.5585], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.0121, -74.6294, -85.6299, -89.2938,     -inf,     -inf,
        -60.5497,     -inf, -91.4296], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.2118,     -inf, -75.2369, -78.5342,     -inf,     -inf,
            -inf,     -inf, -81.4545], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -66.5382, -77.4307,     -inf,     -inf,
            -inf,     -inf, -71.0252], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.1967,     -inf,     -inf,
            -inf,     -inf, -63.4292], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 787: Reward=-210.68, route=[0, 6, 5, 8, 7, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9283, -71.3361, -71.9124, -78.6248, -62.7014, -57.4588,
        -67.7030, -69.5261, -77.1606], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4845, -71.0022, -79.6234, -83.1290, -55.2677,     -inf,
        -64.3098, -62.3199, -85.4823], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4882, -71.6644, -84.5486, -86.6138,     -inf,     -inf,
        -62.0372, -57.5549, -90.5585], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.0121, -74.6294, -85.6299, -89.2938,     -inf,     -inf,
        -60.5497,     -inf, -91.4296], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.7051, -75.6004, -80.3248, -86.7527,     -inf,     -inf,
            -inf,     -inf, -85.2742], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.5267, -58.2007,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.8320,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 788: Reward=-207.95, route=[0, 6, 5, 8, 7, 1, 4, 9, 3, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9193, -70.4083, -71.7287, -78.3072, -61.6245, -57.3266,
        -67.9263, -68.8962, -77.7911], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4822, -70.0675, -79.4660, -82.8030, -54.1681,     -inf,
        -64.5328, -61.6602, -86.1304], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.3897, -70.7524, -84.2537, -86.2199,     -inf,     -inf,
        -62.3548, -57.0441, -91.0419], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9061, -73.7330, -85.3303, -88.9151,     -inf,     -inf,
        -60.8526,     -inf, -91.9083], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -62.9499, -76.6844, -57.9730, -73.7456,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -63.2077, -72.9801,     -inf, -71.7489,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.8233,     -inf, -76.8878,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.8603,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 789: Reward=-191.06, route=[0, 6, 5, 8, 7, 9, 3, 1, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9193, -70.4083, -71.7287, -78.3072, -61.6245, -57.3266,
        -67.9263, -68.8962, -77.7911], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4822, -70.0675, -79.4660, -82.8030, -54.1681,     -inf,
        -64.5328, -61.6602, -86.1304], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.3897, -70.7524, -84.2537, -86.2199,     -inf,     -inf,
        -62.3548, -57.0441, -91.0419], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9061, -73.7330, -85.3303, -88.9151,     -inf,     -inf,
        -60.8526,     -inf, -91.9083], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -62.9499, -76.6844, -57.9730, -73.7456,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -63.2077, -72.9801,     -inf, -71.7489,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 790: Reward=-191.06, route=[0, 6, 5, 8, 7, 9, 3, 1, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9193, -70.4083, -71.7287, -78.3072, -61.6245, -57.3266,
        -67.9263, -68.8962, -77.7911], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4822, -70.0675, -79.4660, -82.8030, -54.1681,     -inf,
        -64.5328, -61.6602, -86.1304], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4608, -70.0922, -83.9397, -85.7433,     -inf,     -inf,
        -62.5743, -56.7099, -91.2374], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9720, -73.0949, -85.0149, -88.4579,     -inf,     -inf,
        -61.0553,     -inf, -92.0982], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -70.2367,     -inf, -74.5645,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -65.7599,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 791: Reward=-213.42, route=[0, 6, 5, 8, 7, 9, 4, 2, 1, 3] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.0653, -69.7310, -71.4829, -77.8917, -61.1746, -57.0508,
        -68.0690, -68.4819, -78.0938], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.6276, -69.3853, -79.2402, -82.3743, -53.7074,     -inf,
        -64.6843, -61.2263, -86.4406], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4608, -70.0922, -83.9397, -85.7433,     -inf,     -inf,
        -62.5743, -56.7099, -91.2374], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9720, -73.0949, -85.0149, -88.4579,     -inf,     -inf,
        -61.0553,     -inf, -92.0982], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.8244, -74.0314, -79.9084, -86.0304,     -inf,     -inf,
            -inf,     -inf, -86.1965], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.3003, -66.1128, -76.7982,     -inf,     -inf,
            -inf,     -inf, -72.0094], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.4043,     -inf, -71.4630,     -inf,     -inf,
            -inf,     -inf, -64.3420], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.9812,     -inf, -73.2189,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.5135,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 792: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.0653, -69.7310, -71.4829, -77.8917, -61.1746, -57.0508,
        -68.0690, -68.4819, -78.0938], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.6276, -69.3853, -79.2402, -82.3743, -53.7074,     -inf,
        -64.6843, -61.2263, -86.4406], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4608, -70.0922, -83.9397, -85.7433,     -inf,     -inf,
        -62.5743, -56.7099, -91.2374], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9720, -73.0949, -85.0149, -88.4579,     -inf,     -inf,
        -61.0553,     -inf, -92.0982], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.9859, -73.6729, -79.5839, -85.4650,     -inf,     -inf,
            -inf,     -inf, -85.8359], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.9380, -65.7477, -76.2261,     -inf,     -inf,
            -inf,     -inf, -71.6187], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.0431,     -inf, -70.9069,     -inf,     -inf,
            -inf,     -inf, -63.9650], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.6390,     -inf, -72.6693,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.1197,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 793: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -73.7426, -72.4793, -84.3253, -87.5670, -50.3197, -49.9883,
        -60.6945,     -inf, -91.2865], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -71.8448, -69.0721, -78.9536, -81.8422, -53.7939,     -inf,
        -64.6933,     -inf, -86.1085], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.6735, -69.7888, -83.6765, -85.2220,     -inf,     -inf,
        -62.5762,     -inf, -90.9153], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.9859, -73.6729, -79.5839, -85.4650,     -inf,     -inf,
            -inf,     -inf, -85.8359], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.9380, -65.7477, -76.2261,     -inf,     -inf,
            -inf,     -inf, -71.6187], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.1837,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -69.2845], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -81.8083], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 794: Reward=-236.96, route=[0, 8, 6, 5, 7, 1, 3, 4, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.2379, -69.3516, -71.1589, -77.3222, -61.2053, -56.6002,
        -68.0299, -68.0580, -77.7484], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.8045, -68.9991, -78.9422, -81.8024, -53.7168,     -inf,
        -64.6511, -60.7758, -86.1190], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.6172, -69.7175, -83.6425, -85.1681,     -inf,     -inf,
        -62.5523, -56.2653, -90.8983], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.1229, -72.7425, -84.7141, -87.8986,     -inf,     -inf,
        -61.0155,     -inf, -91.7462], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.9859, -73.6729, -79.5839, -85.4650,     -inf,     -inf,
            -inf,     -inf, -85.8359], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.9380, -65.7477, -76.2261,     -inf,     -inf,
            -inf,     -inf, -71.6187], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.6810,     -inf, -69.8131,     -inf,     -inf,
            -inf,     -inf, -63.3281], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.2959,     -inf, -71.5733,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -66.7317,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 795: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.2087, -68.9612, -70.5711, -76.1612, -61.3432, -55.8947,
        -67.7948, -67.8002, -77.0893], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.3806,     -inf, -73.8354, -75.8149, -58.3059,     -inf,
        -69.6818, -67.9655, -81.3881], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.5925,     -inf, -83.1000, -83.9726,     -inf,     -inf,
        -62.3235, -56.0282, -90.2543], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.0907,     -inf, -84.1877, -86.7485,     -inf,     -inf,
        -60.7320,     -inf, -91.1027], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.9052,     -inf, -78.9042, -84.2071,     -inf,     -inf,
            -inf,     -inf, -85.0582], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -65.0304, -74.9613,     -inf,     -inf,
            -inf,     -inf, -70.8147], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.7784,     -inf,     -inf,
            -inf,     -inf, -63.2829], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.5386,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 796: Reward=-193.15, route=[0, 6, 2, 5, 8, 7, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.2087, -68.9612, -70.5711, -76.1612, -61.3432, -55.8947,
        -67.7948, -67.8002, -77.0893], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.0873, -78.8126,     -inf, -55.6916,     -inf,
            -inf, -58.6774, -84.9801], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -69.3312, -83.1357,     -inf,     -inf,     -inf,
            -inf, -56.0305, -90.2648], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.3890, -84.2059,     -inf,     -inf,     -inf,
            -inf,     -inf, -91.1001], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -73.8358,     -inf,     -inf,     -inf,
            -inf,     -inf, -81.3623], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -62.4889], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 797: Reward=-266.36, route=[0, 6, 1, 4, 7, 5, 8, 2, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9857, -68.4927, -70.1215, -75.0096, -61.3667, -54.9492,
        -67.2251, -67.4274, -76.3566], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -62.8996, -74.6860, -56.1091, -70.3827, -81.0220,     -inf,
        -75.4038, -84.2286,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -73.2314, -68.7047,     -inf, -82.6017,     -inf,     -inf,
        -61.7626, -55.6572,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -65.5793, -66.1464,     -inf,     -inf,     -inf,     -inf,
        -76.9574,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.7919,     -inf,     -inf,     -inf,     -inf,
        -70.4261,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.6349,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 798: Reward=-283.27, route=[0, 6, 9, 3, 5, 8, 4, 1, 7, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9857, -68.4927, -70.1215, -75.0096, -61.3667, -54.9492,
        -67.2251, -67.4274, -76.3566], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.5613, -68.1231, -77.9568, -79.4885, -53.8162,     -inf,
        -63.8461, -60.0840, -84.7798], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.3602, -68.8485, -82.6918, -82.8480,     -inf,     -inf,
        -61.7493, -55.5417, -89.5716], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.8485, -71.9309, -83.7666, -85.6201,     -inf,     -inf,
        -60.1471,     -inf, -90.3994], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.0135, -64.5310,     -inf,     -inf,     -inf,
            -inf,     -inf, -70.0415], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.1344,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -62.5356], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 799: Reward=-220.6, route=[0, 6, 5, 8, 7, 4, 1, 3, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True False False False False]
greedy_action q_values = tensor([    -inf, -63.0892,     -inf,     -inf, -67.4589,     -inf, -64.9803,
        -74.9197, -82.5875, -61.4414], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True False False False  True]
greedy_action q_values = tensor([    -inf, -62.6406,     -inf,     -inf, -69.2242,     -inf, -67.6177,
        -74.7268, -83.8211,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True False False False  True]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -78.1629,     -inf,     -inf,
        -63.6836, -60.2777,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -84.3231,     -inf,     -inf,
        -59.7131,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 800: Reward=-245.37, route=[0, 2, 5, 3, 9, 1, 6, 8, 7, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.8816, -68.0424, -69.8210, -74.0824, -61.1089, -54.0105,
        -66.6039, -66.8759, -75.5589], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.4548, -67.6649, -77.6666, -78.5475, -53.5421,     -inf,
        -63.2285, -59.5138, -83.9938], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.2001, -68.3952, -82.3082, -81.8327,     -inf,     -inf,
        -61.2181, -55.0476, -88.7116], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.6801, -71.4938, -83.3737, -84.6096,     -inf,     -inf,
        -59.6007,     -inf, -89.5201], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.5749, -72.4161, -78.2216, -82.2069,     -inf,     -inf,
            -inf,     -inf, -83.5791], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.6828, -64.2963, -72.9545,     -inf,     -inf,
            -inf,     -inf, -69.2822], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.8052,     -inf, -67.8298,     -inf,     -inf,
            -inf,     -inf, -61.7986], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.4570,     -inf, -69.5951,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -65.7994,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 801: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.0923,     -inf, -73.1281, -73.7011, -58.0372,     -inf,
        -68.5250, -67.0522, -79.9151], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.8075,     -inf, -81.8196, -80.7886,     -inf,     -inf,
        -60.4484, -54.4687, -87.7622], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.2769,     -inf, -82.8776, -83.5776,     -inf,     -inf,
        -58.8060,     -inf, -88.5539], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.2179,     -inf, -77.8105, -81.2465,     -inf,     -inf,
            -inf,     -inf, -82.6621], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -63.9295, -72.0462,     -inf,     -inf,
            -inf,     -inf, -68.3961], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.9678,     -inf,     -inf,
            -inf,     -inf, -60.9470], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 802: Reward=-193.15, route=[0, 6, 2, 5, 8, 7, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.5514,     -inf, -72.5400, -72.5865, -57.4733, -51.0979,
        -67.3935, -66.1197, -78.8149], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -71.0794,     -inf, -77.7681, -81.1728, -55.0014,     -inf,
            -inf, -56.8845, -82.6289], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -72.8549,     -inf, -81.8921, -80.8786,     -inf,     -inf,
            -inf, -54.4822, -87.8193], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.3240,     -inf, -82.9509, -83.6703,     -inf,     -inf,
            -inf,     -inf, -88.6115], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -63.9295, -72.0462,     -inf,     -inf,
            -inf,     -inf, -68.3961], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.9678,     -inf,     -inf,
            -inf,     -inf, -60.9470], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.7416,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 803: Reward=-215.7, route=[0, 2, 6, 7, 5, 8, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.5827, -67.3760, -69.5153, -73.2223, -60.6394, -53.0632,
        -65.6507, -66.0691, -74.7675], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1497, -66.9917, -77.3643, -77.6691, -53.0696,     -inf,
        -62.2875, -58.7032, -83.2057], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -62.6886, -73.7227, -55.6057, -68.7765,     -inf,     -inf,
        -73.8677, -83.0085,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -69.2361,     -inf,     -inf, -70.9467,     -inf,     -inf,
        -67.3498, -66.5634,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -72.6965,     -inf,     -inf, -81.8392,     -inf,     -inf,
        -58.1678,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -70.5027,     -inf,     -inf, -79.3499,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.1951,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 804: Reward=-247.09, route=[0, 6, 5, 9, 3, 2, 8, 7, 1, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.0712, -67.0448, -68.5102, -71.6480, -60.7192, -52.5538,
        -65.1236, -65.9205, -73.2681], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.6454, -66.6713, -76.3881, -76.0974, -53.1073,     -inf,
        -61.7502, -58.5164, -81.7509], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.3771, -67.4155, -80.9957, -79.3411,     -inf,     -inf,
        -59.7814, -54.0633, -86.4577], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.8362, -70.5649, -82.0434, -82.1398,     -inf,     -inf,
        -58.1153,     -inf, -87.2300], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.7211, -71.4819, -76.8803, -79.7606,     -inf,     -inf,
            -inf,     -inf, -81.2422], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7335, -62.9919, -70.5646,     -inf,     -inf,
            -inf,     -inf, -66.9525], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.8167,     -inf, -65.5736,     -inf,     -inf,
            -inf,     -inf, -59.5570], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.4871,     -inf, -67.3585,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -64.7492,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 805: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.0712, -67.0448, -68.5102, -71.6480, -60.7192, -52.5538,
        -65.1236, -65.9205, -73.2681], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.6454, -66.6713, -76.3881, -76.0974, -53.1073,     -inf,
        -61.7502, -58.5164, -81.7509], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.3771, -67.4155, -80.9957, -79.3411,     -inf,     -inf,
        -59.7814, -54.0633, -86.4577], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.8362, -70.5649, -82.0434, -82.1398,     -inf,     -inf,
        -58.1153,     -inf, -87.2300], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.7211, -71.4819, -76.8803, -79.7606,     -inf,     -inf,
            -inf,     -inf, -81.2422], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7335, -62.9919, -70.5646,     -inf,     -inf,
            -inf,     -inf, -66.9525], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.8167,     -inf, -65.5736,     -inf,     -inf,
            -inf,     -inf, -59.5570], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.3814,     -inf, -66.3959,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -64.6867,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 806: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False False False False False]
greedy_action q_values = tensor([    -inf, -68.4137,     -inf, -70.3727,     -inf, -58.1242, -50.4929,
        -66.4375, -66.6238, -75.6811], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -69.9520,     -inf, -75.1096,     -inf, -53.8034,     -inf,
        -61.3753, -59.3018, -79.9815], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.8540,     -inf, -80.0212,     -inf,     -inf,     -inf,
        -59.1746, -54.5356, -84.9890], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.3037,     -inf, -81.0593,     -inf,     -inf,     -inf,
        -57.4864,     -inf, -85.7435], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.0071,     -inf, -75.5721,     -inf,     -inf,     -inf,
            -inf,     -inf, -79.4285], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -61.7744,     -inf,     -inf,     -inf,
            -inf,     -inf, -65.2044], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 807: Reward=-180.36, route=[0, 4, 2, 6, 5, 8, 7, 1, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.4806, -66.9416, -67.4077, -70.4202, -61.3611, -52.5282,
        -64.6829, -66.5799, -71.6667], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.0564, -66.5698, -75.3001, -74.8576, -53.7233,     -inf,
        -61.3113, -59.1576, -80.1731], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.9395, -67.3011, -80.1530, -78.2349,     -inf,     -inf,
        -59.1611, -54.4441, -85.1355], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.3892, -70.4796, -81.1911, -81.0461,     -inf,     -inf,
        -57.4730,     -inf, -85.8900], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.6754, -61.9180, -69.3882,     -inf,     -inf,
            -inf,     -inf, -65.3525], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.7223,     -inf, -64.5799,     -inf,     -inf,
            -inf,     -inf, -58.0739], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.3814,     -inf, -66.3959,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -64.6867,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 808: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.7569, -66.8396, -66.5938, -69.2703, -61.7706, -52.5462,
        -64.2881, -67.3016, -70.3094], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.3351, -66.4699, -74.5012, -73.7011, -54.1110,     -inf,
        -60.9115, -59.8588, -78.8382], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.3668, -67.1873, -79.5714, -77.2073,     -inf,     -inf,
        -58.5877, -54.9062, -84.0347], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.8061, -70.3908, -80.6008, -80.0277,     -inf,     -inf,
        -56.8814,     -inf, -84.7721], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.3684, -71.3576, -74.9384, -77.3840,     -inf,     -inf,
            -inf,     -inf, -78.2449], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.6162, -61.1333, -68.2825,     -inf,     -inf,
            -inf,     -inf, -63.9979], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.6308,     -inf, -63.6213,     -inf,     -inf,
            -inf,     -inf, -56.8167], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 809: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.7569, -66.8396, -66.5938, -69.2703, -61.7706, -52.5462,
        -64.2881, -67.3016, -70.3094], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -61.0462, -73.1175, -53.2872, -65.3937, -81.2093,     -inf,
        -71.8817, -83.4542,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf, -61.3023, -69.3050,     -inf, -63.3071, -77.6529,     -inf,
        -72.1826, -82.3987,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.2435,     -inf, -67.8052, -70.2563,     -inf,
        -67.1735, -73.9556,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.1031,     -inf, -76.9770, -56.3627,     -inf,
            -inf, -58.3027,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.1497,     -inf, -77.0557,     -inf,     -inf,
            -inf, -55.1603,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.3531,     -inf, -79.8761,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 810: Reward=-220.03, route=[0, 6, 9, 3, 1, 7, 5, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.7569, -66.8396, -66.5938, -69.2703, -61.7706, -52.5462,
        -64.2881, -67.3016, -70.3094], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.3351, -66.4699, -74.5012, -73.7011, -54.1110,     -inf,
        -60.9115, -59.8588, -78.8382], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.0750, -67.2681, -79.2880, -76.8421,     -inf,     -inf,
        -58.3262, -55.7047, -83.5191], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.5062, -70.4974, -80.3117, -79.6785,     -inf,     -inf,
        -56.6040,     -inf, -84.2444], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -61.2379, -69.7341,     -inf, -63.3731,     -inf,     -inf,
            -inf,     -inf, -56.2309], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -60.8550, -73.4006,     -inf, -65.2456,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.6268,     -inf, -67.5832,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -64.7437,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 811: Reward=-185.9, route=[0, 6, 5, 8, 7, 3, 9, 1, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.3470, -66.9515, -66.1183, -68.8248, -62.2525, -52.9185,
        -64.1855, -68.3335, -69.5832], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.9046, -66.5693, -74.0155, -73.2217, -54.5752,     -inf,
        -60.8120, -60.8883, -78.1037], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.0750, -67.2681, -79.2880, -76.8421,     -inf,     -inf,
        -58.3262, -55.7047, -83.5191], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.5062, -70.4974, -80.3117, -79.6785,     -inf,     -inf,
        -56.6040,     -inf, -84.2444], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.9217, -71.4987, -74.4342, -76.9279,     -inf,     -inf,
            -inf,     -inf, -77.4804], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.7612,     -inf, -63.3568,     -inf,     -inf,
            -inf,     -inf, -56.1791], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.4262,     -inf, -65.2302,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -64.7437,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 812: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.3470, -66.9515, -66.1183, -68.8248, -62.2525, -52.9185,
        -64.1855, -68.3335, -69.5832], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.9046, -66.5693, -74.0155, -73.2217, -54.5752,     -inf,
        -60.8120, -60.8883, -78.1037], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.0750, -67.2681, -79.2880, -76.8421,     -inf,     -inf,
        -58.3262, -55.7047, -83.5191], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.5062, -70.4974, -80.3117, -79.6785,     -inf,     -inf,
        -56.6040,     -inf, -84.2444], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.8806, -72.1575, -74.4222, -76.8670,     -inf,     -inf,
            -inf,     -inf, -77.5697], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -69.5926, -68.3559,     -inf,     -inf,
            -inf,     -inf, -74.2094], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -58.3752,     -inf,     -inf,     -inf,
            -inf,     -inf, -62.3124], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 813: Reward=-193.14, route=[0, 6, 5, 8, 7, 1, 2, 4, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.3593, -67.5899, -66.1502, -68.7851, -62.6311, -53.2937,
        -64.4611, -69.3466, -69.7266], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.8763, -67.1801, -74.0163, -73.1321, -54.9434,     -inf,
        -61.0967, -61.9209, -78.2135], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.1245, -67.8660, -79.4005, -76.8147,     -inf,     -inf,
        -58.5159, -56.6033, -83.7498], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.5488, -71.1243, -80.4209, -79.6697,     -inf,     -inf,
        -56.7806,     -inf, -84.4678], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.8806, -72.1575, -74.4222, -76.8670,     -inf,     -inf,
            -inf,     -inf, -77.5697], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.4529, -60.6846, -67.8725,     -inf,     -inf,
            -inf,     -inf, -63.4011], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.4404,     -inf, -63.4430,     -inf,     -inf,
            -inf,     -inf, -56.3872], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.0559,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 814: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.3593, -67.5899, -66.1502, -68.7851, -62.6311, -53.2937,
        -64.4611, -69.3466, -69.7266], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.8763, -67.1801, -74.0163, -73.1321, -54.9434,     -inf,
        -61.0967, -61.9209, -78.2135], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.1245, -67.8660, -79.4005, -76.8147,     -inf,     -inf,
        -58.5159, -56.6033, -83.7498], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.5488, -71.1243, -80.4209, -79.6697,     -inf,     -inf,
        -56.7806,     -inf, -84.4678], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.8806, -72.1575, -74.4222, -76.8670,     -inf,     -inf,
            -inf,     -inf, -77.5697], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.4529, -60.6846, -67.8725,     -inf,     -inf,
            -inf,     -inf, -63.4011], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.1342,     -inf, -63.8826,     -inf,     -inf,
            -inf,     -inf, -57.3582], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -65.9915,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 815: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.4813, -68.2283, -66.6577, -69.1821, -62.5894, -53.4297,
        -64.7729, -69.7565, -70.6685], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.9001, -61.0642, -68.1303, -71.0165,     -inf,
        -67.5466, -76.2615, -64.2578], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -70.8971,     -inf, -63.6785, -78.5249,     -inf,
        -72.5873, -84.8345, -57.2416], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.6661,     -inf, -65.5967, -82.2503,     -inf,
        -72.3195, -86.0605,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -65.7515,     -inf,     -inf, -72.4676,     -inf,
        -73.8803, -83.2745,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -59.7096,     -inf,
        -67.0294, -70.4155,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -58.9967, -57.4199,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -57.2514,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 816: Reward=-197.01, route=[0, 6, 1, 3, 9, 4, 2, 5, 8, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.4813, -68.2283, -66.6577, -69.1821, -62.5894, -53.4297,
        -64.7729, -69.7565, -70.6685], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.9719, -67.7939, -74.5022, -73.4930, -54.8910,     -inf,
        -61.4187, -62.3429, -79.1306], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.1930, -68.4785, -79.8111, -77.1295,     -inf,     -inf,
        -58.8929, -57.0823, -84.6118], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.6110, -71.7670, -80.8322, -80.0079,     -inf,     -inf,
        -57.1476,     -inf, -85.3308], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.9665, -72.8223, -74.9062, -77.2660,     -inf,     -inf,
            -inf,     -inf, -78.4829], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.1403, -61.1925, -68.3066,     -inf,     -inf,
            -inf,     -inf, -64.3541], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.5715,     -inf,     -inf,
            -inf,     -inf, -74.9944], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -64.5430], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 817: Reward=-209.55, route=[0, 6, 5, 8, 7, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.6398, -69.0184, -67.3832, -69.7850, -62.4125, -53.6057,
        -65.1831, -70.1157, -72.1135], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.1158, -68.5680, -75.2157, -74.0708, -54.7025,     -inf,
        -61.8319, -62.7010, -80.5638], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -61.5064, -71.7900,     -inf, -64.3987,     -inf,     -inf,
        -73.0846, -85.2885, -58.8565], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -61.0516, -75.6283,     -inf, -66.3403,     -inf,     -inf,
        -72.7991, -86.5194,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.6742,     -inf, -68.5287,     -inf,     -inf,
        -68.2272, -77.0660,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.4618,     -inf, -77.5178,     -inf,     -inf,
            -inf, -61.3926,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.5452,     -inf, -80.3924,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.9849,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 818: Reward=-211.23, route=[0, 6, 5, 3, 9, 1, 7, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -61.1424, -71.5281,     -inf, -64.1319, -78.1406, -64.5268,
        -72.7111, -84.8981, -58.4658], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -60.7105, -75.3465,     -inf, -66.0831, -81.8840, -67.1850,
        -72.4339, -86.1237,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.4119,     -inf, -68.2652, -70.9248, -59.4326,
        -67.8512, -76.6717,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.4526,     -inf, -73.7246, -55.0317,     -inf,
        -62.0564, -63.1162,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.1434,     -inf, -77.3978,     -inf,     -inf,
        -59.4813, -57.7922,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.4648,     -inf, -80.3031,     -inf,     -inf,
        -57.7268,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.5354,     -inf, -77.5428,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.9849,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 819: Reward=-197.61, route=[0, 3, 9, 1, 6, 5, 8, 7, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -68.8636, -74.1618, -75.9904, -78.3263, -56.3852, -49.9187,
            -inf, -60.6812, -81.0907], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -69.3239, -69.4496, -75.9739, -74.8440, -54.5202,     -inf,
            -inf, -62.8471, -82.1260], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -62.5658, -69.6224,     -inf,     -inf,
            -inf,     -inf, -67.2851], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -65.2123,     -inf,     -inf,
            -inf,     -inf, -60.3315], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -67.1972,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 820: Reward=-228.94, route=[0, 7, 6, 5, 8, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.8081, -69.8191, -68.0772, -70.4859, -62.1682, -53.6933,
        -65.5398, -70.2374, -73.6281], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.2802, -69.3639, -75.9067, -74.7520, -54.4485,     -inf,
        -62.1877, -62.8165, -82.0755], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.3698, -70.0683, -80.9174, -78.2232,     -inf,     -inf,
        -59.8694, -57.8144, -87.3175], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.7755, -73.4242, -81.9449, -81.1556,     -inf,     -inf,
        -58.1058,     -inf, -88.0541], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.2596, -74.5020, -76.3227, -78.6164,     -inf,     -inf,
            -inf,     -inf, -81.4492], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.8263, -62.6342, -69.7008,     -inf,     -inf,
            -inf,     -inf, -67.3667], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.8245,     -inf, -65.2581,     -inf,     -inf,
            -inf,     -inf, -60.3892], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.6898,     -inf, -67.2449,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.4428,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 821: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.8081, -69.8191, -68.0772, -70.4859, -62.1682, -53.6933,
        -65.5398, -70.2374, -73.6281], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.0927,     -inf, -71.4412, -69.8090, -59.0000,     -inf,
        -67.6574, -70.5818, -78.1059], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -61.9387,     -inf,     -inf,     -inf,     -inf,     -inf,
        -73.8991, -85.5940, -61.8488], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf, -61.4203,     -inf,     -inf,     -inf,     -inf,     -inf,
        -73.5783, -86.8224,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -58.7223,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 822: Reward=-215.47, route=[0, 6, 2, 5, 4, 3, 9, 1, 8, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.1143, -70.5903, -69.2488, -71.4942, -62.0718, -53.8029,
        -65.8855, -70.2405, -75.1843], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.5853, -70.1345, -77.0788, -75.7434, -54.3423,     -inf,
        -62.5359, -62.8160, -83.6330], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5729, -70.8563, -81.8774, -79.0881,     -inf,     -inf,
        -60.3824, -58.0091, -88.7043], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.9740, -74.2478, -82.9112, -82.0509,     -inf,     -inf,
        -58.6114,     -inf, -89.4493], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.5613, -75.3257, -77.4966, -79.6508,     -inf,     -inf,
            -inf,     -inf, -83.0174], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.6392, -63.8249, -70.7617,     -inf,     -inf,
            -inf,     -inf, -68.9472], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.6332,     -inf, -66.2828,     -inf,     -inf,
            -inf,     -inf, -61.9552], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.5602,     -inf, -68.3020,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.1484,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 823: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False False]
greedy_action q_values = tensor([    -inf, -61.6210, -73.1666,     -inf, -65.8831, -77.8958, -64.8011,
        -73.4934, -85.1375, -61.5639], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -61.1442, -77.1012,     -inf, -67.8989, -81.7025, -67.5138,
        -73.1880, -86.3565,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.0556,     -inf, -70.0657, -70.6173, -59.6697,
        -68.5504, -76.7996,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.0548,     -inf,     -inf, -72.2298,     -inf,
        -75.5138, -84.0960,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -60.8591, -58.4133,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -59.0809,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 824: Reward=-203.05, route=[0, 3, 9, 1, 6, 4, 2, 5, 8, 7] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.3617, -71.7584, -70.6182, -72.6999, -62.0529, -53.9372,
        -66.0476, -70.0816, -76.7253], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.8362, -71.3009, -78.4504, -76.9389, -54.3124,     -inf,
        -62.7030, -62.6548, -85.1788], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.7168, -72.0343, -83.0083, -80.1357,     -inf,     -inf,
        -60.7460, -58.0657, -90.0681], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.1135, -75.4650, -84.0499, -83.1309,     -inf,     -inf,
        -58.9678,     -inf, -90.8204], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.8349, -76.5220, -78.8094, -80.8354,     -inf,     -inf,
            -inf,     -inf, -84.5836], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.8606, -65.2196, -72.0208,     -inf,     -inf,
            -inf,     -inf, -70.5116], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8582,     -inf, -67.4795,     -inf,     -inf,
            -inf,     -inf, -63.4879], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.8491,     -inf, -69.5350,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.3098,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 825: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.3617, -71.7584, -70.6182, -72.6999, -62.0529, -53.9372,
        -66.0476, -70.0816, -76.7253], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.8362, -71.3009, -78.4504, -76.9389, -54.3124,     -inf,
        -62.7030, -62.6548, -85.1788], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.7168, -72.0343, -83.0083, -80.1357,     -inf,     -inf,
        -60.7460, -58.0657, -90.0681], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.1135, -75.4650, -84.0499, -83.1309,     -inf,     -inf,
        -58.9678,     -inf, -90.8204], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.8349, -76.5220, -78.8094, -80.8354,     -inf,     -inf,
            -inf,     -inf, -84.5836], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.8606, -65.2196, -72.0208,     -inf,     -inf,
            -inf,     -inf, -70.5116], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8582,     -inf, -67.4795,     -inf,     -inf,
            -inf,     -inf, -63.4879], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.3923,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 826: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.6171, -72.8439, -71.7772, -74.0826, -62.5219, -54.3828,
        -66.3191, -70.0783, -78.1968], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.0959, -72.3805, -79.6143, -78.3085, -54.7648,     -inf,
        -62.9781, -62.6434, -86.6537], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.8944, -73.1200, -83.9981, -81.3927,     -inf,     -inf,
        -61.1685, -58.2089, -91.4135], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.2866, -76.5856, -85.0450, -84.4213,     -inf,     -inf,
        -59.3834,     -inf, -92.1713], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.1095, -77.6357, -79.9293, -82.2133,     -inf,     -inf,
            -inf,     -inf, -86.0732], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.9996, -66.3993, -73.4655,     -inf,     -inf,
            -inf,     -inf, -72.0086], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.0025,     -inf, -68.9071,     -inf,     -inf,
            -inf,     -inf, -64.9860], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.1480,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 827: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -61.6867, -79.6420, -58.3169, -70.7136, -82.3232, -68.1960,
        -73.6530, -86.2407,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -62.0450, -75.4416,     -inf, -68.3615, -78.5781, -65.5207,
        -74.0478, -85.1851,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.9407,     -inf,     -inf, -72.6274, -61.4499,
        -75.6036, -83.9515,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.1494,     -inf,     -inf, -55.0588,     -inf,
        -63.1844, -63.0371,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.8934,     -inf,     -inf,     -inf,     -inf,
        -61.2336, -58.4387,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.3590,     -inf,     -inf,     -inf,     -inf,
        -59.4485,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.4258,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 828: Reward=-215.79, route=[0, 9, 3, 1, 4, 6, 5, 8, 7, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.3705, -67.0892, -74.3665, -71.5658, -60.6408,
        -69.3529, -76.6011, -73.1071], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.2099, -80.6913, -79.5244, -55.4917,     -inf,
        -63.5886, -62.9990, -88.1304], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.1384, -65.0377,     -inf,     -inf,     -inf,
        -76.4442, -84.4062, -72.2866], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.5424,     -inf,     -inf,     -inf,     -inf,
        -74.9651, -85.8232, -66.4552], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.6545,     -inf,     -inf,     -inf,     -inf,
        -74.6210, -87.0363,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.1682,     -inf,     -inf,     -inf,     -inf,
            -inf, -61.4918,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 829: Reward=-233.98, route=[0, 1, 6, 5, 4, 3, 9, 7, 8, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.9447, -73.6302, -72.8808, -75.3361, -63.0964, -54.8057,
        -66.8091, -70.2591, -79.7165], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -77.5632, -67.3810, -74.5882, -71.6711,     -inf,
        -69.5741, -76.7851, -73.4380], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -76.5634,     -inf, -70.0126, -79.3789,     -inf,
        -74.8371, -85.6650, -66.4138], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -80.6756,     -inf, -72.1501, -83.3050,     -inf,
        -74.4930, -86.8782,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.0842,     -inf,     -inf, -57.9136,     -inf,
            -inf, -61.2395,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.7820,     -inf,     -inf,     -inf,     -inf,
            -inf, -58.8014,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.2816,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 830: Reward=-240.29, route=[0, 6, 1, 3, 9, 4, 7, 5, 8, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.9447, -73.6302, -72.8808, -75.3361, -63.0964, -54.8057,
        -66.8091, -70.2591, -79.7165], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4361, -73.1673, -80.7303, -79.5490, -55.3256,     -inf,
        -63.4705, -62.8115, -88.1816], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5536, -74.6474, -85.2599, -83.9849,     -inf,     -inf,
        -61.9449, -58.8729, -93.8558], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.9410, -78.1437, -86.2778, -87.0291,     -inf,     -inf,
        -60.1880,     -inf, -94.6002], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.9420, -79.2203, -81.4129, -85.0451,     -inf,     -inf,
            -inf,     -inf, -88.7694], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.6024, -67.9429, -76.4156,     -inf,     -inf,
            -inf,     -inf, -74.7099], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.5971,     -inf, -71.9219,     -inf,     -inf,
            -inf,     -inf, -67.7497], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.7508,     -inf, -74.1171,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.8669,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 831: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.4007, -74.3553, -73.2980, -76.8908, -63.8182, -55.3604,
        -66.8489, -70.5081, -80.8488], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9049, -73.8886, -81.1610, -81.0871, -56.0303,     -inf,
        -63.5123, -63.0420, -89.3243], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.8416,     -inf, -76.7274, -76.0907,     -inf,     -inf,
        -69.2675, -71.1925, -85.4506], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.8677,     -inf, -81.3269, -84.9191,     -inf,     -inf,
            -inf, -61.5326, -88.6884], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -62.9322,     -inf, -60.2961, -74.2050,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -63.3179,     -inf,     -inf, -71.7556,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 832: Reward=-228.36, route=[0, 6, 5, 2, 7, 8, 9, 3, 1, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.4007, -74.3553, -73.2980, -76.8908, -63.8182, -55.3604,
        -66.8489, -70.5081, -80.8488], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9049, -73.8886, -81.1610, -81.0871, -56.0303,     -inf,
        -63.5123, -63.0420, -89.3243], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5536, -74.6474, -85.2599, -83.9849,     -inf,     -inf,
        -61.9449, -58.8729, -93.8558], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.9410, -78.1437, -86.2778, -87.0291,     -inf,     -inf,
        -60.1880,     -inf, -94.6002], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.2835, -79.8966, -81.3307, -85.9276,     -inf,     -inf,
            -inf,     -inf, -89.1369], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.2716, -67.8510, -77.3215,     -inf,     -inf,
            -inf,     -inf, -75.0723], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.2533,     -inf, -72.9473,     -inf,     -inf,
            -inf,     -inf, -68.2022], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -82.4348,     -inf, -75.1906,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.4705,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 833: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.7359, -74.9849, -73.2181, -77.7432, -64.6590, -55.9773,
        -66.8934, -70.9850, -81.2151], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.2506, -74.5183, -81.0975, -81.9287, -56.8545,     -inf,
        -63.5589, -63.5041, -89.7050], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.9156, -75.2769, -85.2173, -84.8291,     -inf,     -inf,
        -61.9836, -59.3043, -94.2721], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.3003, -78.8015, -86.2294, -87.9004,     -inf,     -inf,
        -60.2138,     -inf, -95.0112], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.2835, -79.8966, -81.3307, -85.9276,     -inf,     -inf,
            -inf,     -inf, -89.1369], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -79.2716, -67.8510, -77.3215,     -inf,     -inf,
            -inf,     -inf, -75.0723], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.2533,     -inf, -72.9473,     -inf,     -inf,
            -inf,     -inf, -68.2022], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -82.4348,     -inf, -75.1906,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.4705,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 834: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.7359, -74.9849, -73.2181, -77.7432, -64.6590, -55.9773,
        -66.8934, -70.9850, -81.2151], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -78.9200,     -inf, -76.9716, -73.3705,     -inf,
        -69.6784, -77.6283, -74.7838], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.3766,     -inf,     -inf, -74.8380,     -inf,
            -inf, -84.9459, -73.7602], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -61.9815,     -inf,
            -inf, -71.8761, -85.4636], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 835: Reward=-264.53, route=[0, 6, 3, 1, 7, 4, 2, 5, 8, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.7242, -74.6465, -72.7706, -78.2175, -64.9093, -56.2082,
        -66.6507, -71.0723, -81.1578], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.2583, -74.1924, -80.6775, -82.4025, -57.0906,     -inf,
        -63.3169, -63.5742, -89.6738], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.9093, -74.9617, -84.7723, -85.2873,     -inf,     -inf,
        -61.7667, -59.3988, -94.2253], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.2878, -78.5148, -85.7797, -88.3926,     -inf,     -inf,
        -59.9725,     -inf, -94.9584], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.2834, -79.6027, -80.8853, -86.4358,     -inf,     -inf,
            -inf,     -inf, -89.0875], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.9435, -67.3796, -77.8375,     -inf,     -inf,
            -inf,     -inf, -74.9973], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.8946,     -inf, -73.5630,     -inf,     -inf,
            -inf,     -inf, -68.1986], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -82.0921,     -inf, -75.8469,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 836: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.7242, -74.6465, -72.7706, -78.2175, -64.9093, -56.2082,
        -66.6507, -71.0723, -81.1578], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.2583, -74.1924, -80.6775, -82.4025, -57.0906,     -inf,
        -63.3169, -63.5742, -89.6738], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.9093, -74.9617, -84.7723, -85.2873,     -inf,     -inf,
        -61.7667, -59.3988, -94.2253], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.2878, -78.5148, -85.7797, -88.3926,     -inf,     -inf,
        -59.9725,     -inf, -94.9584], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.2834, -79.6027, -80.8853, -86.4358,     -inf,     -inf,
            -inf,     -inf, -89.0875], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -76.2204, -77.4596,     -inf,     -inf,
            -inf,     -inf, -85.7534], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.5185,     -inf,     -inf,
            -inf,     -inf, -68.1424], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.1572,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 837: Reward=-215.31, route=[0, 6, 5, 8, 7, 1, 2, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.6462, -74.1534, -72.3958, -78.4074, -65.3204, -56.3540,
        -66.4725, -70.9250, -80.7927], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.8516, -74.4889, -84.4345, -85.4750,     -inf,     -inf,
        -61.5816, -59.2169, -93.9154], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.2232, -78.0725, -85.4426, -88.6167,     -inf,     -inf,
        -59.7600,     -inf, -94.6431], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.1953, -79.1509, -80.4999, -86.6432,     -inf,     -inf,
            -inf,     -inf, -88.7114], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -78.4446, -66.9646, -78.0482,     -inf,     -inf,
            -inf,     -inf, -74.5850], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -77.3584,     -inf, -73.8827,     -inf,     -inf,
            -inf,     -inf, -67.8564], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -81.5617,     -inf, -76.2039,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.5043,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 838: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.6462, -74.1534, -72.3958, -78.4074, -65.3204, -56.3540,
        -66.4725, -70.9250, -80.7927], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1834, -73.7102, -80.3117, -82.5772, -57.4943,     -inf,
        -63.1467, -63.4269, -89.3237], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.1220,     -inf, -75.8353, -77.5122,     -inf,     -inf,
        -68.9793, -71.6915, -85.4365], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -71.1214,     -inf, -80.4150, -86.5154,     -inf,     -inf,
            -inf, -61.9066, -88.6312], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.2735,     -inf, -85.4901, -88.6763,     -inf,     -inf,
            -inf,     -inf, -94.6659], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -66.8932, -77.9681,     -inf,     -inf,
            -inf,     -inf, -74.5021], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.8376,     -inf,     -inf,
            -inf,     -inf, -67.7991], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.1572,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 839: Reward=-219.63, route=[0, 6, 5, 2, 7, 8, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -65.2939, -69.2477, -63.8779,     -inf, -74.9260, -63.2141,
        -75.3429, -83.9804, -72.4386], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -70.6059, -71.8064, -79.3643,     -inf, -57.5224,     -inf,
        -63.1335, -63.2958, -88.3158], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.3066, -72.6065, -83.5728,     -inf,     -inf,     -inf,
        -61.4927, -59.0069, -92.9735], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.6689, -76.2194, -84.5859,     -inf,     -inf,     -inf,
        -59.6360,     -inf, -93.6996], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.5848, -77.2762, -79.5566,     -inf,     -inf,     -inf,
            -inf,     -inf, -87.6639], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.4905, -65.9964,     -inf,     -inf,     -inf,
            -inf,     -inf, -73.5244], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.5512,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 840: Reward=-208.77, route=[0, 4, 6, 5, 8, 7, 1, 3, 9, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1204, -72.3490, -71.5315, -77.8407, -65.3967, -56.3964,
        -66.4700, -70.8252, -79.8444], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.6643, -71.9261, -79.4527, -82.0009, -57.5665,     -inf,
        -63.1533, -63.3214, -88.3952], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.3758, -72.7211, -83.6585, -84.9608,     -inf,     -inf,
        -61.5159, -59.0235, -93.0675], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.7383, -76.3376, -84.6753, -88.1524,     -inf,     -inf,
        -59.6547,     -inf, -93.7963], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.6479, -77.3905, -79.6339, -86.1071,     -inf,     -inf,
            -inf,     -inf, -87.7457], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.6044, -66.0708, -77.4955,     -inf,     -inf,
            -inf,     -inf, -73.5908], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.8622,     -inf,     -inf,
            -inf,     -inf, -84.2825], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -72.6511], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 841: Reward=-209.55, route=[0, 6, 5, 8, 7, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1204, -72.3490, -71.5315, -77.8407, -65.3967, -56.3964,
        -66.4700, -70.8252, -79.8444], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.6643, -71.9261, -79.4527, -82.0009, -57.5665,     -inf,
        -63.1533, -63.3214, -88.3952], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.3758, -72.7211, -83.6585, -84.9608,     -inf,     -inf,
        -61.5159, -59.0235, -93.0675], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.3183, -74.2314, -83.9140, -87.2749,     -inf,     -inf,
        -59.4117,     -inf, -92.8133], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.4545, -63.6302,     -inf,     -inf,     -inf,
            -inf,     -inf, -71.9064], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.0592,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -65.9083], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.2662,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 842: Reward=-205.97, route=[0, 6, 5, 8, 7, 1, 4, 3, 9, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.6850, -70.1890, -70.7521, -76.9228, -64.9797, -56.1689,
        -66.2637, -70.4061, -78.8382], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -69.0237,     -inf, -74.0846,     -inf, -61.7090,     -inf,
        -68.6110, -70.9174, -83.3752], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -83.7988,     -inf,     -inf,     -inf,
        -59.5186,     -inf, -92.6718], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -78.6398,     -inf,     -inf,     -inf,
            -inf,     -inf, -86.4636], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -65.8489], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 843: Reward=-245.24, route=[0, 6, 4, 2, 5, 1, 8, 7, 3, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.6850, -70.1890, -70.7521, -76.9228, -64.9797, -56.1689,
        -66.2637, -70.4061, -78.8382], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.2400, -69.7915, -78.6838, -81.0814, -57.1449,     -inf,
        -62.9538, -62.8959, -87.4107], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -65.2620, -67.2497, -63.5783,     -inf,     -inf,     -inf,
        -75.4794, -83.8895, -71.9226], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -62.6231, -72.8545,     -inf,     -inf,     -inf,     -inf,
        -73.8344, -85.2306, -65.9245], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.2077,     -inf,     -inf,     -inf,     -inf,
        -69.1627, -76.8263, -71.2853], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -73.3171,     -inf,     -inf,     -inf,     -inf,
            -inf, -60.9295, -85.4951], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.4636,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -91.7109], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -82.3031], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 844: Reward=-250.71, route=[0, 6, 5, 4, 3, 1, 7, 8, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2848, -68.4203, -70.0988, -75.6002, -64.5142, -55.8152,
        -66.2468, -69.9134, -77.9153], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.8545, -68.0512, -78.0429, -79.7626, -56.6784,     -inf,
        -62.9380, -62.3950, -86.5101], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5813, -68.9034, -82.2746, -82.7882,     -inf,     -inf,
        -61.2446, -58.0749, -91.1908], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.9279, -72.5373, -83.2641, -85.9934,     -inf,     -inf,
        -59.3568,     -inf, -91.8848], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.7902, -73.5441, -78.1902, -83.9028,     -inf,     -inf,
            -inf,     -inf, -85.7797], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.5700, -64.5400, -75.2065,     -inf,     -inf,
            -inf,     -inf, -71.5312], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.2855,     -inf, -71.4063,     -inf,     -inf,
            -inf,     -inf, -65.0553], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.4790,     -inf, -73.7548,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -65.3946,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 845: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.2848, -68.4203, -70.0988, -75.6002, -64.5142, -55.8152,
        -66.2468, -69.9134, -77.9153], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.8545, -68.0512, -78.0429, -79.7626, -56.6784,     -inf,
        -62.9380, -62.3950, -86.5101], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5813, -68.9034, -82.2746, -82.7882,     -inf,     -inf,
        -61.2446, -58.0749, -91.1908], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.9279, -72.5373, -83.2641, -85.9934,     -inf,     -inf,
        -59.3568,     -inf, -91.8848], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.7897,     -inf,     -inf, -74.5923,     -inf,     -inf,
            -inf,     -inf, -82.4383], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.5648,     -inf,     -inf,
            -inf,     -inf, -70.4888], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 846: Reward=-232.44, route=[0, 6, 5, 8, 7, 3, 2, 1, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.9463, -66.9703, -69.5613, -74.1264, -63.9235, -55.4660,
        -66.3547, -69.5540, -77.1151], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -64.4096, -63.7143, -62.5304,     -inf, -73.2933,     -inf,
        -75.2930, -82.6180, -70.2149], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True False  True False  True False]
greedy_action q_values = tensor([    -inf, -71.3230, -70.8867,     -inf,     -inf, -53.5357,     -inf,
        -59.2575,     -inf, -90.7112], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.1854, -67.3773,     -inf,     -inf,     -inf,     -inf,
        -61.3413,     -inf, -90.1749], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.2784, -71.9474,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -84.6920], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.8816,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -70.4920], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.8310,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 847: Reward=-251.64, route=[0, 6, 4, 3, 8, 5, 7, 1, 9, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.9463, -66.9703, -69.5613, -74.1264, -63.9235, -55.4660,
        -66.3547, -69.5540, -77.1151], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.5305, -66.6244, -77.5219, -78.2976, -56.0851,     -inf,
        -63.0449, -62.0275, -85.7320], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.2694, -67.5084, -81.7649, -81.3656,     -inf,     -inf,
        -61.3149, -57.7037, -90.4061], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.6091, -71.1579, -82.7427, -84.5740,     -inf,     -inf,
        -59.4160,     -inf, -91.0836], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.4430, -72.1431, -77.6544, -82.4486,     -inf,     -inf,
            -inf,     -inf, -84.9621], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.0769, -64.0053, -73.7395,     -inf,     -inf,
            -inf,     -inf, -70.7004], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.7379,     -inf, -69.9776,     -inf,     -inf,
            -inf,     -inf, -64.2607], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.9424,     -inf, -72.3182,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -63.8269,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 848: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.5034, -65.5420, -69.1249, -72.6381, -63.1757, -55.1853,
        -66.3137, -69.0381, -76.0472], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.1026, -65.2224, -77.1031, -76.8230, -55.3330,     -inf,
        -63.0020, -61.5051, -84.6874], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.8635, -66.1374, -81.3579, -79.9375,     -inf,     -inf,
        -61.2323, -57.1721, -89.3618], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.1950, -69.8037, -82.3234, -83.1474,     -inf,     -inf,
        -59.3209,     -inf, -90.0176], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.9910, -70.7644, -77.2112, -80.9743,     -inf,     -inf,
            -inf,     -inf, -83.8691], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5984, -63.6028, -72.2793,     -inf,     -inf,
            -inf,     -inf, -69.6101], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.2068,     -inf, -68.4886,     -inf,     -inf,
            -inf,     -inf, -63.1573], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.4164,     -inf, -70.8194,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -62.2758,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 849: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.5034, -65.5420, -69.1249, -72.6381, -63.1757, -55.1853,
        -66.3137, -69.0381, -76.0472], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.1026, -65.2224, -77.1031, -76.8230, -55.3330,     -inf,
        -63.0020, -61.5051, -84.6874], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.8635, -66.1374, -81.3579, -79.9375,     -inf,     -inf,
        -61.2323, -57.1721, -89.3618], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.1950, -69.8037, -82.3234, -83.1474,     -inf,     -inf,
        -59.3209,     -inf, -90.0176], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.9910, -70.7644, -77.2112, -80.9743,     -inf,     -inf,
            -inf,     -inf, -83.8691], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5984, -63.6028, -72.2793,     -inf,     -inf,
            -inf,     -inf, -69.6101], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.2068,     -inf, -68.4886,     -inf,     -inf,
            -inf,     -inf, -63.1573], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.4164,     -inf, -70.8194,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -62.2758,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 850: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -70.7895, -69.5514, -81.9364, -82.8484, -52.7208, -48.6365,
        -58.9340,     -inf, -89.5460], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -68.7949, -64.1473, -76.5711, -75.2951, -54.6175,     -inf,
        -63.0912,     -inf, -83.5380], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -70.6342, -65.0890, -80.9256, -78.5081,     -inf,     -inf,
        -61.2142,     -inf, -88.3051], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.6312, -69.6547, -76.6810, -79.4348,     -inf,     -inf,
            -inf,     -inf, -82.7205], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.3930, -63.0744, -70.7312,     -inf,     -inf,
            -inf,     -inf, -68.4442], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.9533,     -inf, -66.9080,     -inf,     -inf,
            -inf,     -inf, -61.9737], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.1690,     -inf, -69.2305,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 851: Reward=-205.52, route=[0, 8, 6, 5, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.1526, -64.3761, -68.5897, -71.0784, -62.3400, -55.0194,
        -66.3307, -68.5846, -74.9208], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.7670, -64.0786, -76.5953, -75.2787, -54.4898,     -inf,
        -63.0189, -61.0438, -83.5886], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.5789, -65.0213, -80.9055, -78.4658,     -inf,     -inf,
        -61.1776, -56.6608, -88.3036], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -60.5077, -71.1337, -56.0904, -69.2703,     -inf,     -inf,
        -73.2514,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -60.9923, -66.7493,     -inf, -66.6859,     -inf,     -inf,
        -73.8102,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -68.1331,     -inf, -70.3704,     -inf,     -inf,
        -69.2354,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.7649,     -inf,     -inf,
        -69.2349,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 852: Reward=-252.68, route=[0, 6, 5, 8, 9, 3, 1, 2, 7, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.1526, -64.3761, -68.5897, -71.0784, -62.3400, -55.0194,
        -66.3307, -68.5846, -74.9208], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.7670, -64.0786, -76.5953, -75.2787, -54.4898,     -inf,
        -63.0189, -61.0438, -83.5886], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.5789, -65.0213, -80.9055, -78.4658,     -inf,     -inf,
        -61.1776, -56.6608, -88.3036], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -70.9033, -68.7097, -81.8585, -81.6781,     -inf,     -inf,
        -59.2524,     -inf, -88.9378], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -64.2013,     -inf, -61.9380,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.7513], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -61.4215,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -61.4574], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.7264], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 853: Reward=-193.17, route=[0, 6, 5, 8, 7, 2, 4, 3, 1, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.5230, -64.0111, -68.7527, -70.3488, -61.6567, -54.9721,
        -66.4529, -68.2470, -74.5418], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.1426, -63.7195, -76.7723, -74.5555, -53.7953,     -inf,
        -63.1396, -60.7024, -83.2248], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.9207, -64.6982, -81.0009, -77.7320,     -inf,     -inf,
        -61.3310, -56.3995, -87.8432], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.2499, -68.3977, -81.9418, -80.9464,     -inf,     -inf,
        -59.4021,     -inf, -88.4727], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.0044, -69.3270, -76.8166, -78.7053,     -inf,     -inf,
            -inf,     -inf, -82.3219], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.0203, -63.1957, -69.9753,     -inf,     -inf,
            -inf,     -inf, -68.0005], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.5547,     -inf, -66.1315,     -inf,     -inf,
            -inf,     -inf, -61.5267], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.7980,     -inf, -68.4575,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 854: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.5230, -64.0111, -68.7527, -70.3488, -61.6567, -54.9721,
        -66.4529, -68.2470, -74.5418], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -60.6872, -70.6221, -56.1180, -68.3900, -81.3035,     -inf,
        -73.1550, -83.6100,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf, -61.1745, -66.2115,     -inf, -65.8000, -77.3829,     -inf,
        -73.7235, -82.6710,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.6201,     -inf, -69.5037, -70.4916,     -inf,
        -69.1323, -74.9181,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.9749, -58.8757,     -inf,
        -69.0921, -69.2627,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -76.9735,     -inf,     -inf,
        -61.6026, -56.6918,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -80.2065,     -inf,     -inf,
        -59.6541,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -77.8956,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 855: Reward=-236.81, route=[0, 6, 9, 3, 1, 2, 5, 8, 7, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.0852, -64.0819, -69.0189, -69.9856, -61.0683, -54.7412,
        -66.4557, -67.9953, -74.5161], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False False]
greedy_action q_values = tensor([    -inf, -61.7944, -66.3599,     -inf, -65.5220, -76.7443,     -inf,
        -73.7078, -82.3909, -61.3855], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf, -61.1545, -70.6355,     -inf, -67.8583, -80.7993,     -inf,
        -73.1968, -83.4866,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.6981,     -inf, -69.1021, -69.9391,     -inf,
        -69.1487, -74.7179,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.5946, -58.2968,     -inf,
        -69.1126, -69.0274,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -75.8065, -81.6425,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 856: Reward=-259.72, route=[0, 6, 3, 9, 1, 2, 5, 4, 7, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.0852, -64.0819, -69.0189, -69.9856, -61.0683, -54.7412,
        -66.4557, -67.9953, -74.5161], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.4244, -64.7978, -81.1504, -77.3185,     -inf,     -inf,
        -61.4299, -56.2792, -87.6881], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.7578, -68.5162, -82.0815, -80.5410,     -inf,     -inf,
        -59.4942,     -inf, -88.3119], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.5762, -69.4306, -77.0480, -78.3363,     -inf,     -inf,
            -inf,     -inf, -82.2778], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.6904,     -inf, -72.6608, -69.0973,     -inf,     -inf,
            -inf,     -inf, -79.1714], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -63.3535, -69.5161,     -inf,     -inf,
            -inf,     -inf, -67.8372], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -65.6561,     -inf,     -inf,
            -inf,     -inf, -61.3682], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -67.7385,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 857: Reward=-210.68, route=[0, 6, 5, 8, 7, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.8222, -64.6477, -69.4081, -69.8276, -60.3401, -54.3144,
        -65.9668, -67.5933, -74.6218], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4488, -64.3489, -77.4505, -74.0349, -52.4753,     -inf,
        -62.6782, -60.0472, -83.3229], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.0765, -65.3556, -81.3393, -77.0375,     -inf,     -inf,
        -61.1354, -56.0868, -87.6280], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.4021, -69.1218, -82.2640, -80.2797,     -inf,     -inf,
        -59.1745,     -inf, -88.2247], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.3321, -70.0176, -77.3761, -78.1487,     -inf,     -inf,
            -inf,     -inf, -82.3719], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.4508,     -inf, -73.0672, -68.9115,     -inf,     -inf,
            -inf,     -inf, -79.3007], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.4857,     -inf, -62.4623,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.7290], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -62.6768,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -61.3673], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 858: Reward=-176.82, route=[0, 6, 5, 8, 7, 2, 4, 3, 9, 1] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
greedy_action q_values = tensor([    -inf,     -inf, -68.2941, -63.2552, -68.9421, -69.0221, -60.4344,
        -68.3742, -74.0294, -67.5078], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -64.3856, -77.4088, -74.0085, -52.6438,     -inf,
        -62.7984, -60.2475, -83.2586], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf, -61.2206, -62.4726,     -inf,     -inf,     -inf,
            -inf, -81.2168, -67.7769], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -72.9573,     -inf,     -inf,     -inf,
            -inf, -68.7040, -79.2059], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -82.2057,     -inf,     -inf,     -inf,
            -inf,     -inf, -88.1249], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -61.3111], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 859: Reward=-265.14, route=[0, 1, 6, 5, 7, 4, 2, 8, 3, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False  True False]
greedy_action q_values = tensor([    -inf, -72.6508, -69.8932, -82.3629, -80.0802, -50.2552, -47.9275,
        -58.3492,     -inf, -87.6735], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5985, -64.1300, -69.3147, -68.9218,     -inf,
        -68.0958,     -inf, -67.8075], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.0638,     -inf, -65.3572, -76.0399,     -inf,
        -72.8664,     -inf, -61.2514], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.4272,     -inf, -67.7198, -80.1144,     -inf,
        -72.3138,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.9025,     -inf,     -inf, -69.6459,     -inf,
        -74.7241,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False  True  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -55.3684,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 860: Reward=-238.2, route=[0, 8, 6, 1, 3, 9, 4, 2, 7, 5] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.5881, -65.6437, -70.1099, -70.0334, -59.9210, -53.9714,
        -65.3451, -67.0565, -74.7215], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1541, -65.3302, -77.9754, -74.1434, -52.2755,     -inf,
        -62.2042, -59.6658, -83.3012], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.7538, -66.3300, -81.8343, -77.0992,     -inf,     -inf,
        -60.7317, -55.7631, -87.5703], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.0716, -70.1463, -82.7550, -80.3650,     -inf,     -inf,
        -58.7451,     -inf, -88.1399], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.1207, -71.0306, -78.0133, -78.3228,     -inf,     -inf,
            -inf,     -inf, -82.4651], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.2632,     -inf, -73.7813, -69.0660,     -inf,     -inf,
            -inf,     -inf, -79.4675], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.2186,     -inf, -63.0368,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.6880], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -63.4041,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -61.3240], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -62.7644,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 861: Reward=-176.82, route=[0, 6, 5, 8, 7, 2, 4, 3, 9, 1] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.5881, -65.6437, -70.1099, -70.0334, -59.9210, -53.9714,
        -65.3451, -67.0565, -74.7215], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.1541, -65.3302, -77.9754, -74.1434, -52.2755,     -inf,
        -62.2042, -59.6658, -83.3012], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.7538, -66.3300, -81.8343, -77.0992,     -inf,     -inf,
        -60.7317, -55.7631, -87.5703], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.5941, -71.0940, -83.3848, -81.0079,     -inf,     -inf,
        -58.3631,     -inf, -88.2026], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -63.4696, -73.6127, -57.9065, -68.6954,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -63.9220, -69.0600,     -inf, -66.0261,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.5386,     -inf, -69.8418,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -62.9259,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 862: Reward=-183.7, route=[0, 6, 5, 8, 7, 9, 3, 1, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True False False False False]
greedy_action q_values = tensor([    -inf, -73.0061, -67.0494, -82.1726, -77.4960,     -inf, -47.3462,
        -60.1264, -55.3546, -87.3102], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -63.3507, -73.4780, -57.7936, -68.5551,     -inf,     -inf,
        -71.7935, -82.7527,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -63.8355, -68.8947,     -inf, -65.8948,     -inf,     -inf,
        -72.4409, -81.8434,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.3777,     -inf, -69.7167,     -inf,     -inf,
        -67.8136, -73.9672,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.7735,     -inf, -78.6871,     -inf,     -inf,
            -inf, -57.8259,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.3529,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 863: Reward=-217.13, route=[0, 5, 6, 9, 3, 1, 7, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.1781, -66.5569, -70.8920, -70.7618, -59.9096, -53.9931,
        -64.8095, -66.6842, -74.9100], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -66.5574, -62.8314, -63.5896,     -inf, -69.3238,     -inf,
        -74.0523, -80.2235, -67.7571], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -64.6555,     -inf, -68.9460,     -inf,
        -67.6071, -73.6562, -67.7831], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -76.3287,     -inf,
        -71.9224, -81.6340, -60.7125], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -80.4183,     -inf,
        -71.3354, -82.7015,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -55.5886,     -inf,
            -inf, -57.4850,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -55.7652,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 864: Reward=-222.34, route=[0, 6, 4, 2, 1, 3, 9, 7, 5, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.2270, -67.3821, -71.2208, -71.2973, -60.1034, -54.0680,
        -64.3262, -66.4343, -74.4907], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -71.3610, -65.1673, -70.5506, -69.0689,     -inf,
        -67.0080, -73.2215, -67.5305], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -69.7883,     -inf, -66.4351, -76.2823,     -inf,
        -71.8756, -81.5488, -60.8381], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.5556,     -inf, -79.1908, -55.5213,     -inf,
            -inf, -57.2999,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.8420,     -inf,     -inf,
            -inf, -67.9290,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -81.2879,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 865: Reward=-258.06, route=[0, 6, 1, 3, 9, 7, 5, 2, 8, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.2270, -67.3821, -71.2208, -71.2973, -60.1034, -54.0680,
        -64.3262, -66.4343, -74.4907], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.7863, -67.0277, -78.9486, -75.3009, -52.6565,     -inf,
        -61.3427, -59.1543, -83.0216], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.6554, -71.9386, -83.6989, -81.5381,     -inf,     -inf,
        -57.9235,     -inf, -87.7824], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.9882,     -inf, -74.9118, -70.2261,     -inf,     -inf,
            -inf,     -inf, -79.3700], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.8098,     -inf, -63.9572,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.3115], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -64.1771,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -61.0449], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 866: Reward=-176.82, route=[0, 6, 5, 8, 7, 2, 4, 3, 9, 1] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.4871, -68.2627, -71.9072, -72.4508, -60.4007, -54.0739,
        -63.9515, -65.9884, -74.7709], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -72.2906, -65.8426, -71.7435, -69.3942,     -inf,
        -66.6175, -72.7742, -67.7929], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7102,     -inf, -67.5221, -76.6860,     -inf,
        -71.5674, -81.2432, -61.0164], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.1577,     -inf, -69.9943, -80.7501,     -inf,
        -70.9778, -82.2943,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -64.3313,     -inf,     -inf, -70.2238,     -inf,
        -73.5300, -80.1279,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  0.
  0.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf, -57.3663,     -inf,
        -66.8230, -67.1337,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -59.8592, -55.3904,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -57.8212,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 867: Reward=-197.01, route=[0, 6, 1, 3, 9, 4, 2, 5, 8, 7] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False False  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -67.9169, -79.5373, -76.3743, -53.2068,     -inf,
        -61.1551, -58.9472, -83.2255], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf, -68.9473, -83.3637, -79.2787,     -inf,     -inf,
        -59.7899, -55.1256, -87.4306], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True False  True False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.1497,     -inf,     -inf,
            -inf,     -inf, -79.4114], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.3124], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 868: Reward=-238.21, route=[0, 1, 6, 5, 8, 7, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.7893, -68.9866, -72.9199, -73.7732, -60.4302, -53.7506,
        -63.6760, -65.4400, -75.4761], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.2689, -68.5972, -80.3712, -77.6031, -53.3421,     -inf,
        -60.9200, -58.4048, -83.8102], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.7365, -69.6368, -84.1452, -80.4402,     -inf,     -inf,
        -59.6510, -54.6681, -87.9405], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.0365, -73.5916, -85.0542, -83.8155,     -inf,     -inf,
        -57.6052,     -inf, -88.4609], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.3847, -74.4730, -80.6456, -82.0472,     -inf,     -inf,
            -inf,     -inf, -83.1979], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.2562, -59.5804, -71.6155,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.6190,     -inf, -68.8191,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 869: Reward=-164.37, route=[0, 6, 5, 8, 7, 1, 9, 3, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.7893, -68.9866, -72.9199, -73.7732, -60.4302, -53.7506,
        -63.6760, -65.4400, -75.4761], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.2689, -68.5972, -80.3712, -77.6031, -53.3421,     -inf,
        -60.9200, -58.4048, -83.8102], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.7365, -69.6368, -84.1452, -80.4402,     -inf,     -inf,
        -59.6510, -54.6681, -87.9405], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.0365, -73.5916, -85.0542, -83.8155,     -inf,     -inf,
        -57.6052,     -inf, -88.4609], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.3847, -74.4730, -80.6456, -82.0472,     -inf,     -inf,
            -inf,     -inf, -83.1979], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.2949, -66.9138, -73.2444,     -inf,     -inf,
            -inf,     -inf, -68.5230], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7116,     -inf, -68.9638,     -inf,     -inf,
            -inf,     -inf, -61.7180], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.1796,     -inf, -71.4833,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -65.2700,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 870: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.7893, -68.9866, -72.9199, -73.7732, -60.4302, -53.7506,
        -63.6760, -65.4400, -75.4761], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.2689, -68.5972, -80.3712, -77.6031, -53.3421,     -inf,
        -60.9200, -58.4048, -83.8102], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.3018, -74.4439, -85.6131, -84.8567,     -inf,     -inf,
        -57.9985,     -inf, -88.8903], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.6396, -75.3626, -81.1831, -83.1269,     -inf,     -inf,
            -inf,     -inf, -83.5994], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.1926, -67.4480, -74.3414,     -inf,     -inf,
            -inf,     -inf, -68.9221], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.6072,     -inf, -70.0659,     -inf,     -inf,
            -inf,     -inf, -62.1265], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.1096,     -inf, -72.6298,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 871: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.0489, -69.8346, -73.4656, -74.8244, -61.1099, -53.9575,
        -64.0368, -65.7966, -75.8869], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False  True]
greedy_action q_values = tensor([    -inf, -63.9981, -76.9255, -59.9651, -72.5532, -81.4426,     -inf,
        -71.0227, -82.0198,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf, -64.4403, -72.2270,     -inf, -69.7181, -77.4836,     -inf,
        -71.6993, -81.1496,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.7607,     -inf, -73.8550, -70.3459,     -inf,
        -66.8220, -72.8504,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.0825,     -inf, -82.7268, -56.7621,     -inf,
            -inf, -56.6765,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.3393,     -inf, -84.6435, -52.4717,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -70.4884,     -inf, -81.3444,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.2953,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 872: Reward=-199.4, route=[0, 6, 9, 3, 1, 7, 8, 5, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.0489, -69.8346, -73.4656, -74.8244, -61.1099, -53.9575,
        -64.0368, -65.7966, -75.8869], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.5560, -69.4218, -80.9503, -78.6448, -53.9859,     -inf,
        -61.2778, -58.7226, -84.2691], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.0071, -70.4709, -84.7192, -81.4737,     -inf,     -inf,
        -60.0328, -55.0031, -88.3874], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.3018, -74.4439, -85.6131, -84.8567,     -inf,     -inf,
        -57.9985,     -inf, -88.8903], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.6694,     -inf, -77.3236, -74.4323,     -inf,     -inf,
            -inf,     -inf, -81.0059], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -67.4147, -75.0451,     -inf,     -inf,
            -inf,     -inf, -68.9470], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.9008,     -inf,     -inf,
            -inf,     -inf, -62.2723], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.5104,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 873: Reward=-210.68, route=[0, 6, 5, 8, 7, 2, 1, 3, 9, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.8601, -70.4803, -73.5813, -75.6150, -61.7047, -54.1988,
        -64.4092, -66.3173, -76.0608], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.4203, -70.0491, -81.1737, -79.4607, -54.4593,     -inf,
        -61.5988, -59.1434, -84.5482], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -74.2111, -75.2109, -85.9088, -85.8084,     -inf,     -inf,
            -inf,     -inf, -89.2129], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8791, -67.5400, -75.1742,     -inf,     -inf,
            -inf,     -inf, -69.0813], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.2884,     -inf, -70.9623,     -inf,     -inf,
            -inf,     -inf, -62.3456], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.8149,     -inf, -73.5730,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -66.7186,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 874: Reward=-193.36, route=[0, 6, 5, 7, 8, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.8601, -70.4803, -73.5813, -75.6150, -61.7047, -54.1988,
        -64.4092, -66.3173, -76.0608], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.4203, -70.0491, -81.1737, -79.4607, -54.4593,     -inf,
        -61.5988, -59.1434, -84.5482], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.8677, -71.1105, -84.9509, -82.2993,     -inf,     -inf,
        -60.3577, -55.4272, -88.6679], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.1527, -75.1135, -85.8369, -85.7069,     -inf,     -inf,
        -58.3212,     -inf, -89.1597], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.4291, -76.0645, -81.3067, -83.9631,     -inf,     -inf,
            -inf,     -inf, -83.7574], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.4755, -59.9493, -74.4128,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.7543,     -inf, -71.4730,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.2135,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 875: Reward=-164.37, route=[0, 6, 5, 8, 7, 1, 9, 3, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.5726, -70.9905, -73.1125, -76.1069, -62.3542, -54.3877,
        -64.8275, -66.9502, -76.0365], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.2260, -70.5302, -80.9070, -80.0166, -54.8794,     -inf,
        -61.9059, -59.5971, -84.7075], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.6879, -71.6034, -84.7077, -82.8840,     -inf,     -inf,
        -60.6430, -55.8577, -88.8577], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9635, -75.6446, -85.5883, -86.3298,     -inf,     -inf,
        -58.5916,     -inf, -89.3442], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.1123, -76.6360, -80.8601, -84.5178,     -inf,     -inf,
            -inf,     -inf, -83.7167], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.4338, -67.0304, -75.7053,     -inf,     -inf,
            -inf,     -inf, -69.0318], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.8496,     -inf, -71.6209,     -inf,     -inf,
            -inf,     -inf, -62.4022], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.3976,     -inf, -74.2794,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 876: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.5726, -70.9905, -73.1125, -76.1069, -62.3542, -54.3877,
        -64.8275, -66.9502, -76.0365], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.2260, -70.5302, -80.9070, -80.0166, -54.8794,     -inf,
        -61.9059, -59.5971, -84.7075], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9635, -75.6446, -85.5883, -86.3298,     -inf,     -inf,
        -58.5916,     -inf, -89.3442], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.1123, -76.6360, -80.8601, -84.5178,     -inf,     -inf,
            -inf,     -inf, -83.7167], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.4338, -67.0304, -75.7053,     -inf,     -inf,
            -inf,     -inf, -69.0318], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.8496,     -inf, -71.6209,     -inf,     -inf,
            -inf,     -inf, -62.4022], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.3976,     -inf, -74.2794,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 877: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.3140, -71.4514, -72.5215, -76.6355, -63.5507, -55.0532,
        -65.9799, -68.4789, -75.7672], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.0305, -70.9898, -80.5354, -80.6332, -55.8169,     -inf,
        -62.9205, -60.9480, -84.5947], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.6465, -72.0471, -84.5508, -83.6224,     -inf,     -inf,
        -61.5051, -56.9652, -88.9989], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -64.0935, -74.2045,     -inf, -72.2921,     -inf,     -inf,
        -73.6627,     -inf, -62.2561], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -63.5160, -78.8000,     -inf, -74.9975,     -inf,     -inf,
        -73.0776,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.6329,     -inf, -75.9434,     -inf,     -inf,
        -69.0044,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.0552,     -inf, -84.8016,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.9932,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 878: Reward=-215.45, route=[0, 6, 5, 8, 3, 9, 1, 7, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.3140, -71.4514, -72.5215, -76.6355, -63.5507, -55.0532,
        -65.9799, -68.4789, -75.7672], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.0305, -70.9898, -80.5354, -80.6332, -55.8169,     -inf,
        -62.9205, -60.9480, -84.5947], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.6465, -72.0471, -84.5508, -83.6224,     -inf,     -inf,
        -61.5051, -56.9652, -88.9989], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9165, -76.1534, -85.4485, -87.1441,     -inf,     -inf,
        -59.4213,     -inf, -89.4950], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.8137, -77.1879, -80.3340, -85.1498,     -inf,     -inf,
            -inf,     -inf, -83.4311], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.9316, -66.4605, -76.3356,     -inf,     -inf,
            -inf,     -inf, -68.7672], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.3449,     -inf, -72.3859,     -inf,     -inf,
            -inf,     -inf, -62.2390], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.9165,     -inf, -75.0975,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.6392,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 879: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.3140, -71.4514, -72.5215, -76.6355, -63.5507, -55.0532,
        -65.9799, -68.4789, -75.7672], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.8898, -71.2470, -80.0487, -81.1160, -56.8141,     -inf,
        -64.1006, -62.2887, -84.5437], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.7123, -72.2687, -84.3617, -84.2434,     -inf,     -inf,
        -62.4980, -57.9755, -89.2936], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9772, -76.4135, -85.2531, -87.8020,     -inf,     -inf,
        -60.4117,     -inf, -89.7847], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -63.6238, -79.2404, -59.1209, -75.9172,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -66.8671, -67.7825,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 880: Reward=-206.48, route=[0, 6, 5, 8, 7, 9, 3, 4, 1, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.2025, -71.6723, -71.9384, -77.0580, -64.6748, -55.5145,
        -67.2434, -69.8585, -75.7118], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.8898, -71.2470, -80.0487, -81.1160, -56.8141,     -inf,
        -64.1006, -62.2887, -84.5437], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.7123, -72.2687, -84.3617, -84.2434,     -inf,     -inf,
        -62.4980, -57.9755, -89.2936], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9772, -76.4135, -85.2531, -87.8020,     -inf,     -inf,
        -60.4117,     -inf, -89.7847], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.6592, -77.5063, -79.8228, -85.6856,     -inf,     -inf,
            -inf,     -inf, -83.3568], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.1784, -65.9994, -76.9428,     -inf,     -inf,
            -inf,     -inf, -68.7874], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.5876,     -inf, -73.0154,     -inf,     -inf,
            -inf,     -inf, -62.2882], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.1907,     -inf, -75.7727,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.8147,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 881: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.2025, -71.6723, -71.9384, -77.0580, -64.6748, -55.5145,
        -67.2434, -69.8585, -75.7118], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False  True False]
greedy_action q_values = tensor([    -inf, -73.8192, -76.3396, -85.1465, -87.7262, -54.5758,     -inf,
        -60.2445,     -inf, -89.6466], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.7294, -72.3667, -83.8349, -84.1952,     -inf,     -inf,
        -63.4607,     -inf, -89.2072], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.3214, -77.6415, -78.8601, -85.4483,     -inf,     -inf,
            -inf,     -inf, -82.7994], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.2409, -65.1376, -76.8209,     -inf,     -inf,
            -inf,     -inf, -68.3744], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.2876,     -inf, -75.7055,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.8263,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 882: Reward=-194.38, route=[0, 6, 8, 5, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9164, -71.7132, -70.8898, -76.7043, -65.7785, -56.1932,
        -68.5176, -71.5988, -75.1863], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.5707, -71.3297, -79.1222, -80.8452, -57.7580,     -inf,
        -65.2741, -63.9820, -84.0219], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.6732, -72.2968, -83.8230, -84.1568,     -inf,     -inf,
        -63.4161, -59.2395, -89.2153], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9316, -76.4734, -84.7027, -87.7411,     -inf,     -inf,
        -61.3270,     -inf, -89.6955], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.3214, -77.6415, -78.8601, -85.4483,     -inf,     -inf,
            -inf,     -inf, -82.7994], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.2409, -65.1376, -76.8209,     -inf,     -inf,
            -inf,     -inf, -68.3744], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.6601,     -inf, -72.9183,     -inf,     -inf,
            -inf,     -inf, -61.9132], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.2876,     -inf, -75.7055,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.8263,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 883: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.9164, -71.7132, -70.8898, -76.7043, -65.7785, -56.1932,
        -68.5176, -71.5988, -75.1863], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.5707, -71.3297, -79.1222, -80.8452, -57.7580,     -inf,
        -65.2741, -63.9820, -84.0219], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.6732, -72.2968, -83.8230, -84.1568,     -inf,     -inf,
        -63.4161, -59.2395, -89.2153], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.9316, -76.4734, -84.7027, -87.7411,     -inf,     -inf,
        -61.3270,     -inf, -89.6955], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.3214, -77.6415, -78.8601, -85.4483,     -inf,     -inf,
            -inf,     -inf, -82.7994], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.4162, -64.3313, -76.3013,     -inf,     -inf,
            -inf,     -inf, -68.0159], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.8485,     -inf, -72.4028,     -inf,     -inf,
            -inf,     -inf, -61.5867], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.5085,     -inf, -75.2095,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.9490,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 884: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.4898, -71.8495, -69.9362, -76.0099, -66.2880, -56.5233,
        -69.3547, -73.0179, -74.7363], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -70.7122, -77.7019, -77.9711, -84.8000, -61.2773,     -inf,
            -inf, -63.3618, -82.3372], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -66.4644, -68.0353, -63.5099,     -inf,     -inf,     -inf,
            -inf, -86.3829, -68.3994], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True False False]
greedy_action q_values = tensor([    -inf, -70.1806,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -74.3117, -79.5922], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False False]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -89.3120], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 885: Reward=-297.3, route=[0, 6, 7, 5, 4, 3, 2, 1, 8, 9] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False False False  True]
greedy_action q_values = tensor([    -inf, -62.5400, -79.1036, -57.0467, -74.9121, -86.2909, -71.1115,
        -75.6183, -88.2116,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False False False False False  True]
greedy_action q_values = tensor([    -inf, -62.9455, -74.2527,     -inf, -71.8212, -82.2733, -68.1975,
        -76.2394, -87.2744,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False False False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.7624,     -inf, -75.5748, -75.2763, -62.9791,
        -71.5121, -79.3532,     -inf], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.
  0.  1. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False False  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.3097,     -inf, -79.7904, -58.5866,     -inf,
        -66.3522, -65.8623,     -inf], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.4685,     -inf, -87.0086,     -inf,     -inf,
        -62.0005,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.6167,     -inf, -84.1640,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.7939,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 886: Reward=-204.02, route=[0, 9, 3, 1, 6, 5, 8, 7, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1364, -71.6678, -69.2245, -75.5878, -66.8313, -56.8174,
        -69.9740, -74.0258, -74.1737], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.7972, -71.2803, -77.5369, -79.7671, -58.7183,     -inf,
        -66.7049, -66.3710, -83.0427], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.2169, -72.2293, -82.8527, -83.4208,     -inf,     -inf,
        -64.4113, -61.0498, -88.7823], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.4575, -76.4727, -83.7130, -87.0530,     -inf,     -inf,
        -62.3103,     -inf, -89.2379], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.4562, -77.7545, -77.3142, -84.5220,     -inf,     -inf,
            -inf,     -inf, -81.7263], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.2718, -63.7373, -76.0295,     -inf,     -inf,
            -inf,     -inf, -67.5232], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -74.6842,     -inf, -72.1111,     -inf,     -inf,
            -inf,     -inf, -61.0877], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.3783,     -inf, -74.9415,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -67.7667,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 887: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.7972, -71.2803, -77.5369, -79.7671, -58.7183,     -inf,
        -66.7049, -66.3710, -83.0427], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.2169, -72.2293, -82.8527, -83.4208,     -inf,     -inf,
        -64.4113, -61.0498, -88.7823], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.4575, -76.4727, -83.7130, -87.0530,     -inf,     -inf,
        -62.3103,     -inf, -89.2379], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.4562, -77.7545, -77.3142, -84.5220,     -inf,     -inf,
            -inf,     -inf, -81.7263], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.2718, -63.7373, -76.0295,     -inf,     -inf,
            -inf,     -inf, -67.5232], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.8477,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.7093], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -79.2560,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 888: Reward=-213.32, route=[0, 6, 5, 8, 7, 1, 3, 4, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.
  0.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False False  True False False]
greedy_action q_values = tensor([    -inf, -69.8462, -77.2339, -76.6794, -84.0826, -61.1814, -53.2970,
            -inf, -64.3471, -81.4284], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True  True False False]
greedy_action q_values = tensor([    -inf, -70.6629, -71.1625, -77.2560, -79.6619, -58.3920,     -inf,
            -inf, -66.6636, -83.1190], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True False False]
greedy_action q_values = tensor([    -inf, -73.0879, -72.1225, -82.5939, -83.3325,     -inf,     -inf,
            -inf, -61.3441, -88.8640], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -73.3219, -76.4019, -83.4489, -86.9938,     -inf,     -inf,
            -inf,     -inf, -89.3124], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -76.0880, -63.4177, -75.8877,     -inf,     -inf,
            -inf,     -inf, -67.5739], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.5731,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -67.7894], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 889: Reward=-236.56, route=[0, 7, 6, 5, 8, 1, 3, 4, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.9519, -71.4465, -68.8831, -75.3855, -66.3936, -56.6677,
        -69.8896, -74.2318, -74.2095], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.6205, -71.0556, -77.2130, -79.5679, -58.2609,     -inf,
        -66.6281, -66.5721, -83.0928], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -62.3832, -79.1267, -56.3951, -74.8099,     -inf,     -inf,
        -76.4760, -89.7959,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf, -62.8497, -74.1636,     -inf, -71.6724,     -inf,     -inf,
        -77.1263, -88.8343,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  0.
  0.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.7137,     -inf, -75.4615,     -inf,     -inf,
        -72.3842, -80.8870,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf, -77.3759,     -inf, -83.9999,     -inf,     -inf,
            -inf, -65.3516,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.2432,     -inf, -86.7116,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.5481,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 890: Reward=-215.26, route=[0, 6, 5, 9, 3, 1, 7, 8, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.9519, -71.4465, -68.8831, -75.3855, -66.3936, -56.6677,
        -69.8896, -74.2318, -74.2095], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.6205, -71.0556, -77.2130, -79.5679, -58.2609,     -inf,
        -66.6281, -66.5721, -83.0928], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.0922, -71.7205, -82.6291, -83.5858,     -inf,     -inf,
        -64.1118, -61.1706, -89.4467], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.3234, -76.0375, -83.4838, -87.2828,     -inf,     -inf,
        -61.9855,     -inf, -89.8949], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -62.6749, -79.0266, -56.7054, -75.4768,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.5945,     -inf, -76.0887,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -74.0273,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 891: Reward=-191.06, route=[0, 6, 5, 8, 7, 9, 3, 1, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1854, -71.1152, -69.2650, -75.9102, -65.3292, -56.2449,
        -69.3985, -73.7990, -75.1213], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8557, -70.7218, -77.6046, -80.0825, -57.1805,     -inf,
        -66.1483, -66.1464, -84.0099], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.0922, -71.7205, -82.6291, -83.5858,     -inf,     -inf,
        -64.1118, -61.1706, -89.4467], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.3234, -76.0375, -83.4838, -87.2828,     -inf,     -inf,
        -61.9855,     -inf, -89.8949], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.2708, -67.2089, -62.9130,     -inf,     -inf,     -inf,
            -inf,     -inf, -68.8610], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -63.1900, -73.9773,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -62.0185], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -62.5299, -78.8212,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.4525,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 892: Reward=-201.78, route=[0, 6, 5, 8, 7, 4, 3, 9, 1, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1854, -71.1152, -69.2650, -75.9102, -65.3292, -56.2449,
        -69.3985, -73.7990, -75.1213], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8557, -70.7218, -77.6046, -80.0825, -57.1805,     -inf,
        -66.1483, -66.1464, -84.0099], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.0922, -71.7205, -82.6291, -83.5858,     -inf,     -inf,
        -64.1118, -61.1706, -89.4467], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.3234, -76.0375, -83.4838, -87.2828,     -inf,     -inf,
        -61.9855,     -inf, -89.8949], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.4354, -76.5412, -77.3962, -85.0395,     -inf,     -inf,
            -inf,     -inf, -83.3530], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -75.0144, -63.7084, -76.4567,     -inf,     -inf,
            -inf,     -inf, -69.0579], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.3423,     -inf, -72.5083,     -inf,     -inf,
            -inf,     -inf, -62.6489], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -78.2334,     -inf, -75.4195,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -66.1803,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 893: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1058, -70.3293, -69.3750, -76.0396, -64.0357, -55.6311,
        -68.7710, -73.3416, -75.8019], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.7789, -69.9400, -77.7248, -80.2090, -55.8767,     -inf,
        -65.5316, -65.6899, -84.6935], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  0.
  0.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.9566,     -inf, -73.2006, -74.4215,     -inf,     -inf,
        -71.8861, -74.4941, -80.9636], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  1.  0.
  0.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True False False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf, -63.6154, -76.2467,     -inf,     -inf,
        -71.3463, -80.1537, -68.9928], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.2982,     -inf,     -inf,
        -76.2412, -88.3879, -62.5838], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -75.2017,     -inf,     -inf,
        -75.5874, -89.5302,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  0.
  0.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True False False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
        -78.3807, -87.1890,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  0.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True False  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf, -64.6997,     -inf], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 894: Reward=-231.71, route=[0, 6, 5, 2, 1, 3, 9, 4, 7, 8] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1058, -70.3293, -69.3750, -76.0396, -64.0357, -55.6311,
        -68.7710, -73.3416, -75.8019], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.7789, -69.9400, -77.7248, -80.2090, -55.8767,     -inf,
        -65.5316, -65.6899, -84.6935], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False False]
greedy_action q_values = tensor([    -inf, -63.0503, -73.1303,     -inf, -72.3817,     -inf,     -inf,
        -76.0318, -88.0338, -62.7307], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  0.
  0.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False False  True]
random_action
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  0.
  1.  1. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True False  True  True]
greedy_action q_values = tensor([    -inf, -72.9350, -75.1223,     -inf, -86.9973,     -inf,     -inf,
        -61.6118,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  1.  1.
  1.  1. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -69.9171, -75.0297,     -inf, -84.6180,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.4438,     -inf, -75.9313,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -73.9874,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 895: Reward=-238.02, route=[0, 6, 5, 3, 9, 8, 7, 1, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.7848, -68.9720, -69.2664, -75.9483, -62.4529, -54.6856,
        -67.8098, -71.7534, -76.2931], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4625, -68.5982, -77.6310, -80.1213, -54.2919,     -inf,
        -64.5788, -64.1017, -85.1914], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.3180, -69.6851, -82.0341, -83.3126,     -inf,     -inf,
        -63.0347, -59.8022, -90.0015], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.5319, -74.0606, -82.8765, -87.0647,     -inf,     -inf,
        -60.8722,     -inf, -90.4394], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.8195, -64.8731, -62.6350,     -inf,     -inf,     -inf,
            -inf,     -inf, -69.9140], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -62.7011, -71.7416,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -63.0327], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.4030,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -69.2176], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.7318,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 896: Reward=-216.2, route=[0, 6, 5, 8, 7, 4, 3, 1, 9, 2] 

==================

mask = [ True False False False False False False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.
  0.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False False False False False]
greedy_action q_values = tensor([    -inf, -65.3364, -64.4250, -62.2347,     -inf, -71.3905, -61.3211,
        -76.7803, -84.7498, -69.5064], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4050, -68.4484, -77.5413,     -inf, -54.2403,     -inf,
        -64.5662, -64.0792, -85.1156], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.2474, -69.5421, -81.9460,     -inf,     -inf,     -inf,
        -63.0178, -59.7904, -89.9084], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.4612, -73.9176, -82.7883,     -inf,     -inf,     -inf,
        -60.8552,     -inf, -90.3462], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.0548, -75.0758, -77.1754,     -inf,     -inf,     -inf,
            -inf,     -inf, -83.7679], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.4963, -63.3314,     -inf,     -inf,     -inf,
            -inf,     -inf, -69.3686], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -81.7752], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 897: Reward=-242.19, route=[0, 4, 6, 5, 8, 7, 1, 3, 2, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.6241, -67.8117, -69.4269, -75.4395, -60.7390, -53.4462,
        -66.7329, -69.9071, -77.0643], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.3201, -67.4368, -77.7724, -79.5869, -52.6272,     -inf,
        -63.5483, -62.2649, -85.9761], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.9083, -68.6014, -81.8090, -82.6123,     -inf,     -inf,
        -62.2718, -58.3862, -90.3717], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.1135, -73.0045, -82.6462, -86.3843,     -inf,     -inf,
        -60.0888,     -inf, -90.8075], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.9630, -74.0921, -77.3779, -84.4489,     -inf,     -inf,
            -inf,     -inf, -84.6258], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.4637, -63.3302, -75.5343,     -inf,     -inf,
            -inf,     -inf, -70.0586], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.6898,     -inf, -71.5437,     -inf,     -inf,
            -inf,     -inf, -63.6704], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.6892,     -inf, -74.4783,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -63.4373,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 898: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.6241, -67.8117, -69.4269, -75.4395, -60.7390, -53.4462,
        -66.7329, -69.9071, -77.0643], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.3201, -67.4368, -77.7724, -79.5869, -52.6272,     -inf,
        -63.5483, -62.2649, -85.9761], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.9083, -68.6014, -81.8090, -82.6123,     -inf,     -inf,
        -62.2718, -58.3862, -90.3717], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.1135, -73.0045, -82.6462, -86.3843,     -inf,     -inf,
        -60.0888,     -inf, -90.8075], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.9630, -74.0921, -77.3779, -84.4489,     -inf,     -inf,
            -inf,     -inf, -84.6258], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.4637, -63.3302, -75.5343,     -inf,     -inf,
            -inf,     -inf, -70.0586], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.6898,     -inf, -71.5437,     -inf,     -inf,
            -inf,     -inf, -63.6704], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.6892,     -inf, -74.4783,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -63.4373,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 899: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.6241, -67.8117, -69.4269, -75.4395, -60.7390, -53.4462,
        -66.7329, -69.9071, -77.0643], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.1669, -66.7552, -78.2457, -79.2173, -51.1309,     -inf,
        -62.5422, -60.4360, -86.7971], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5570, -67.9734, -82.0472, -82.1028,     -inf,     -inf,
        -61.4766, -56.8290, -90.9360], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.7544, -72.4075, -82.8858, -85.8977,     -inf,     -inf,
        -59.2711,     -inf, -91.3718], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.9481, -73.4151, -78.0842, -84.1925,     -inf,     -inf,
            -inf,     -inf, -85.7247], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7745, -63.8594, -75.1130,     -inf,     -inf,
            -inf,     -inf, -70.9951], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.9640,     -inf, -71.1057,     -inf,     -inf,
            -inf,     -inf, -64.6235], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.0036,     -inf, -74.0592,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -62.6592,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 900: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.5853, -67.1191, -70.1921, -75.2135, -58.8604, -51.9757,
        -65.5064, -67.7877, -78.1451], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.1669, -66.7552, -78.2457, -79.2173, -51.1309,     -inf,
        -62.5422, -60.4360, -86.7971], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5570, -67.9734, -82.0472, -82.1028,     -inf,     -inf,
        -61.4766, -56.8290, -90.9360], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.7544, -72.4075, -82.8858, -85.8977,     -inf,     -inf,
        -59.2711,     -inf, -91.3718], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.9481, -73.4151, -78.0842, -84.1925,     -inf,     -inf,
            -inf,     -inf, -85.7247], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7745, -63.8594, -75.1130,     -inf,     -inf,
            -inf,     -inf, -70.9951], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.9640,     -inf, -71.1057,     -inf,     -inf,
            -inf,     -inf, -64.6235], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.0036,     -inf, -74.0592,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -62.6592,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 901: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.5853, -67.1191, -70.1921, -75.2135, -58.8604, -51.9757,
        -65.5064, -67.7877, -78.1451], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.1669, -66.7552, -78.2457, -79.2173, -51.1309,     -inf,
        -62.5422, -60.4360, -86.7971], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5570, -67.9734, -82.0472, -82.1028,     -inf,     -inf,
        -61.4766, -56.8290, -90.9360], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.2233, -71.8310, -82.9851, -85.0788,     -inf,     -inf,
        -58.4048,     -inf, -91.5018], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.6431, -72.7786, -78.5073, -83.5113,     -inf,     -inf,
            -inf,     -inf, -86.2254], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.1277, -64.2218, -74.3778,     -inf,     -inf,
            -inf,     -inf, -71.4220], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.2816,     -inf, -70.3002,     -inf,     -inf,
            -inf,     -inf, -65.0181], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.3479,     -inf, -73.2678,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.9235,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 902: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.3070, -66.4610, -70.6943, -74.5972, -57.3782, -50.5725,
        -64.3206, -65.6041, -78.6677], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.7085, -66.1326, -78.3916, -78.4455, -50.0855,     -inf,
        -61.6052, -58.6177, -86.9788], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.0353, -67.3668, -82.1463, -81.2660,     -inf,     -inf,
        -60.6325, -55.0729, -91.0703], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.2233, -71.8310, -82.9851, -85.0788,     -inf,     -inf,
        -58.4048,     -inf, -91.5018], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.6431, -72.7786, -78.5073, -83.5113,     -inf,     -inf,
            -inf,     -inf, -86.2254], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.1277, -64.2218, -74.3778,     -inf,     -inf,
            -inf,     -inf, -71.4220], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.2816,     -inf, -70.3002,     -inf,     -inf,
            -inf,     -inf, -65.0181], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.3479,     -inf, -73.2678,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.9235,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 903: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.3070, -66.4610, -70.6943, -74.5972, -57.3782, -50.5725,
        -64.3206, -65.6041, -78.6677], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.7085, -66.1326, -78.3916, -78.4455, -50.0855,     -inf,
        -61.6052, -58.6177, -86.9788], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.0353, -67.3668, -82.1463, -81.2660,     -inf,     -inf,
        -60.6325, -55.0729, -91.0703], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.2233, -71.8310, -82.9851, -85.0788,     -inf,     -inf,
        -58.4048,     -inf, -91.5018], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.6431, -72.7786, -78.5073, -83.5113,     -inf,     -inf,
            -inf,     -inf, -86.2254], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.4005, -63.9978, -73.4318,     -inf,     -inf,
            -inf,     -inf, -71.0273], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.5265,     -inf, -69.3445,     -inf,     -inf,
            -inf,     -inf, -64.6319], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.6224,     -inf, -72.3266,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.1090,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 904: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.8298, -65.7203, -70.4914, -73.6497, -57.0243, -49.8567,
        -63.7623, -64.5178, -78.3030], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.1836, -65.4066, -78.1584, -77.4647, -49.7539,     -inf,
        -61.1040, -57.5818, -86.5742], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.5077, -66.6690, -81.9274, -80.3000,     -inf,     -inf,
        -60.1272, -54.0231, -90.6644], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -70.6932, -71.1502, -82.7603, -84.1226,     -inf,     -inf,
        -57.8895,     -inf, -91.0971], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.1197, -72.0920, -78.2886, -82.5612,     -inf,     -inf,
            -inf,     -inf, -85.8258], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.4005, -63.9978, -73.4318,     -inf,     -inf,
            -inf,     -inf, -71.0273], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.5265,     -inf, -69.3445,     -inf,     -inf,
            -inf,     -inf, -64.6319], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.6224,     -inf, -72.3266,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.1090,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 905: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.8298, -65.7203, -70.4914, -73.6497, -57.0243, -49.8567,
        -63.7623, -64.5178, -78.3030], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.1836, -65.4066, -78.1584, -77.4647, -49.7539,     -inf,
        -61.1040, -57.5818, -86.5742], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.5077, -66.6690, -81.9274, -80.3000,     -inf,     -inf,
        -60.1272, -54.0231, -90.6644], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -70.6932, -71.1502, -82.7603, -84.1226,     -inf,     -inf,
        -57.8895,     -inf, -91.0971], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.1197, -72.0920, -78.2886, -82.5612,     -inf,     -inf,
            -inf,     -inf, -85.8258], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.4005, -63.9978, -73.4318,     -inf,     -inf,
            -inf,     -inf, -71.0273], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.5265,     -inf, -69.3445,     -inf,     -inf,
            -inf,     -inf, -64.6319], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.7827,     -inf, -70.8613,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.1884,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 906: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.9686, -64.8831, -69.9036, -72.1507, -56.8078, -49.2772,
        -63.0976, -63.7511, -77.3972], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.3516, -64.5894, -77.6904, -76.0236, -49.4142,     -inf,
        -60.3830, -56.7292, -85.7576], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.6797, -65.8700, -81.4764, -78.8674,     -inf,     -inf,
        -59.4099, -53.1627, -89.8613], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.8511, -70.3840, -82.3021, -82.7021,     -inf,     -inf,
        -57.1505,     -inf, -90.2789], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.2245, -71.3310, -77.7397, -81.1138,     -inf,     -inf,
            -inf,     -inf, -84.9035], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5773, -63.4198, -71.9534,     -inf,     -inf,
            -inf,     -inf, -70.1114], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.6605,     -inf, -67.8761,     -inf,     -inf,
            -inf,     -inf, -63.7333], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.7827,     -inf, -70.8613,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.1884,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 907: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.9686, -64.8831, -69.9036, -72.1507, -56.8078, -49.2772,
        -63.0976, -63.7511, -77.3972], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.3516, -64.5894, -77.6904, -76.0236, -49.4142,     -inf,
        -60.3830, -56.7292, -85.7576], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.6797, -65.8700, -81.4764, -78.8674,     -inf,     -inf,
        -59.4099, -53.1627, -89.8613], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.8511, -70.3840, -82.3021, -82.7021,     -inf,     -inf,
        -57.1505,     -inf, -90.2789], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.2245, -71.3310, -77.7397, -81.1138,     -inf,     -inf,
            -inf,     -inf, -84.9035], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5773, -63.4198, -71.9534,     -inf,     -inf,
            -inf,     -inf, -70.1114], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.6605,     -inf, -67.8761,     -inf,     -inf,
            -inf,     -inf, -63.7333], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.7827,     -inf, -70.8613,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.1884,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 908: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.9630, -64.1252, -68.3313, -69.9341, -57.7692, -49.3590,
        -62.7580, -64.0405, -75.2901], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.5530, -63.8479, -76.6269, -74.0710, -49.8083,     -inf,
        -59.7016, -56.5593, -84.0826], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.9154, -65.1371, -80.4471, -76.9401,     -inf,     -inf,
        -58.7098, -52.9664, -88.2305], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.0667, -69.7023, -81.2618, -80.7925,     -inf,     -inf,
        -56.4195,     -inf, -88.6141], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.2095, -70.7008, -76.3310, -79.0875,     -inf,     -inf,
            -inf,     -inf, -82.8090], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.8367, -62.0986, -69.9722,     -inf,     -inf,
            -inf,     -inf, -68.1344], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.8737,     -inf, -65.8566,     -inf,     -inf,
            -inf,     -inf, -61.7289], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.9968,     -inf, -68.8421,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.3452,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 909: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.9630, -64.1252, -68.3313, -69.9341, -57.7692, -49.3590,
        -62.7580, -64.0405, -75.2901], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.5530, -63.8479, -76.6269, -74.0710, -49.8083,     -inf,
        -59.7016, -56.5593, -84.0826], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.9154, -65.1371, -80.4471, -76.9401,     -inf,     -inf,
        -58.7098, -52.9664, -88.2305], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.0667, -69.7023, -81.2618, -80.7925,     -inf,     -inf,
        -56.4195,     -inf, -88.6141], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.2095, -70.7008, -76.3310, -79.0875,     -inf,     -inf,
            -inf,     -inf, -82.8090], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.8367, -62.0986, -69.9722,     -inf,     -inf,
            -inf,     -inf, -68.1344], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.8737,     -inf, -65.8566,     -inf,     -inf,
            -inf,     -inf, -61.7289], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.9968,     -inf, -68.8421,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.3452,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 910: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.9630, -64.1252, -68.3313, -69.9341, -57.7692, -49.3590,
        -62.7580, -64.0405, -75.2901], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.5530, -63.8479, -76.6269, -74.0710, -49.8083,     -inf,
        -59.7016, -56.5593, -84.0826], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.4925, -64.6910, -79.5672, -75.3104,     -inf,     -inf,
        -58.5145, -54.0141, -86.8758], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.6325, -69.2953, -80.3702, -79.1759,     -inf,     -inf,
        -56.2055,     -inf, -87.2401], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.3248, -70.3840, -74.7927, -77.1851,     -inf,     -inf,
            -inf,     -inf, -80.6977], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4006, -60.7908, -68.2709,     -inf,     -inf,
            -inf,     -inf, -66.3012], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.3960,     -inf, -64.1260,     -inf,     -inf,
            -inf,     -inf, -59.8748], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.4878,     -inf, -67.1223,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -58.8177,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 911: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.1683, -63.6547, -66.6401, -67.8705, -59.6207, -50.3298,
        -63.1567, -65.8491, -73.2287], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.8778, -63.3577, -75.1495, -72.0695, -51.4277,     -inf,
        -59.9987, -58.1547, -82.2557], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.4925, -64.6910, -79.5672, -75.3104,     -inf,     -inf,
        -58.5145, -54.0141, -86.8758], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.6325, -69.2953, -80.3702, -79.1759,     -inf,     -inf,
        -56.2055,     -inf, -87.2401], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.3248, -70.3840, -74.7927, -77.1851,     -inf,     -inf,
            -inf,     -inf, -80.6977], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4006, -60.7908, -68.2709,     -inf,     -inf,
            -inf,     -inf, -66.3012], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.3960,     -inf, -64.1260,     -inf,     -inf,
            -inf,     -inf, -59.8748], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.4878,     -inf, -67.1223,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -58.8177,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 912: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.1683, -63.6547, -66.6401, -67.8705, -59.6207, -50.3298,
        -63.1567, -65.8491, -73.2287], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.8778, -63.3577, -75.1495, -72.0695, -51.4277,     -inf,
        -59.9987, -58.1547, -82.2557], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.4925, -64.6910, -79.5672, -75.3104,     -inf,     -inf,
        -58.5145, -54.0141, -86.8758], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.6325, -69.2953, -80.3702, -79.1759,     -inf,     -inf,
        -56.2055,     -inf, -87.2401], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.8006, -70.1628, -73.8974, -75.7470,     -inf,     -inf,
            -inf,     -inf, -79.2126], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.0887, -60.1002, -67.0094,     -inf,     -inf,
            -inf,     -inf, -65.0389], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.0484,     -inf, -62.8416,     -inf,     -inf,
            -inf,     -inf, -58.5970], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.1296,     -inf, -65.8557,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -58.5632,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 913: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.7145, -63.3057, -65.6311, -66.3058, -61.2472, -51.2406,
        -63.6238, -67.4593, -71.7815], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.4272, -63.0184, -74.1681, -70.5053, -53.0297,     -inf,
        -60.4582, -59.7504, -80.8371], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.3254, -64.3676, -79.2077, -74.0928,     -inf,     -inf,
        -58.5022, -55.0218, -85.9909], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.4576, -69.0103, -80.0045, -77.9779,     -inf,     -inf,
        -56.1770,     -inf, -86.3408], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.8006, -70.1628, -73.8974, -75.7470,     -inf,     -inf,
            -inf,     -inf, -79.2126], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.0887, -60.1002, -67.0094,     -inf,     -inf,
            -inf,     -inf, -65.0389], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.0484,     -inf, -62.8416,     -inf,     -inf,
            -inf,     -inf, -58.5970], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.1296,     -inf, -65.8557,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -58.5632,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 914: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.7145, -63.3057, -65.6311, -66.3058, -61.2472, -51.2406,
        -63.6238, -67.4593, -71.7815], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.4272, -63.0184, -74.1681, -70.5053, -53.0297,     -inf,
        -60.4582, -59.7504, -80.8371], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.3254, -64.3676, -79.2077, -74.0928,     -inf,     -inf,
        -58.5022, -55.0218, -85.9909], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.4576, -69.0103, -80.0045, -77.9779,     -inf,     -inf,
        -56.1770,     -inf, -86.3408], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.8006, -70.1628, -73.8974, -75.7470,     -inf,     -inf,
            -inf,     -inf, -79.2126], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.0887, -60.1002, -67.0094,     -inf,     -inf,
            -inf,     -inf, -65.0389], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.3741,     -inf, -62.1210,     -inf,     -inf,
            -inf,     -inf, -57.9055], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.4661,     -inf, -65.1604,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -58.9017,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 915: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.6580, -63.6000, -65.2211, -65.4029, -62.6315, -52.0968,
        -63.8711, -68.6359, -70.9880], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.3652, -63.3130, -73.7835, -69.5962, -54.3920,     -inf,
        -60.6925, -60.9156, -80.0629], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.4603, -64.6796, -79.2837, -73.4381,     -inf,     -inf,
        -58.3824, -55.7552, -85.6041], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.5854, -69.3677, -80.0781, -77.3475,     -inf,     -inf,
        -56.0374,     -inf, -85.9427], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.7240, -70.5278, -73.4953, -74.8716,     -inf,     -inf,
            -inf,     -inf, -78.4065], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4363, -59.8769, -66.3029,     -inf,     -inf,
            -inf,     -inf, -64.3514], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.3741,     -inf, -62.1210,     -inf,     -inf,
            -inf,     -inf, -57.9055], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.4661,     -inf, -65.1604,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -58.9017,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 916: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.6580, -63.6000, -65.2211, -65.4029, -62.6315, -52.0968,
        -63.8711, -68.6359, -70.9880], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.3652, -63.3130, -73.7835, -69.5962, -54.3920,     -inf,
        -60.6925, -60.9156, -80.0629], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.4603, -64.6796, -79.2837, -73.4381,     -inf,     -inf,
        -58.3824, -55.7552, -85.6041], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.5854, -69.3677, -80.0781, -77.3475,     -inf,     -inf,
        -56.0374,     -inf, -85.9427], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.7240, -70.5278, -73.4953, -74.8716,     -inf,     -inf,
            -inf,     -inf, -78.4065], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4363, -59.8769, -66.3029,     -inf,     -inf,
            -inf,     -inf, -64.3514], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.3741,     -inf, -62.1210,     -inf,     -inf,
            -inf,     -inf, -57.9055], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.4661,     -inf, -65.1604,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.3016,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 917: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.8731, -64.0061, -65.0961, -65.2047, -63.7638, -52.8310,
        -64.0538, -69.3630, -70.7593], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.5636, -63.7100, -73.6745, -69.3713, -55.5122,     -inf,
        -60.8682, -61.6473, -79.8366], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.7726, -65.0916, -79.4806, -73.3691,     -inf,     -inf,
        -58.3298, -56.2076, -85.6268], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.8918, -69.8221, -80.2720, -77.3080,     -inf,     -inf,
        -55.9654,     -inf, -85.9578], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.9115, -70.9919, -73.3710, -74.6926,     -inf,     -inf,
            -inf,     -inf, -78.1582], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.8878, -59.8334, -66.2363,     -inf,     -inf,
            -inf,     -inf, -64.1713], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.8102,     -inf, -62.0571,     -inf,     -inf,
            -inf,     -inf, -57.7305], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.9244,     -inf, -65.1321,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.3016,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 918: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.8731, -64.0061, -65.0961, -65.2047, -63.7638, -52.8310,
        -64.0538, -69.3630, -70.7593], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.5636, -63.7100, -73.6745, -69.3713, -55.5122,     -inf,
        -60.8682, -61.6473, -79.8366], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.7726, -65.0916, -79.4806, -73.3691,     -inf,     -inf,
        -58.3298, -56.2076, -85.6268], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.8918, -69.8221, -80.2720, -77.3080,     -inf,     -inf,
        -55.9654,     -inf, -85.9578], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.9115, -70.9919, -73.3710, -74.6926,     -inf,     -inf,
            -inf,     -inf, -78.1582], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.8878, -59.8334, -66.2363,     -inf,     -inf,
            -inf,     -inf, -64.1713], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.8102,     -inf, -62.0571,     -inf,     -inf,
            -inf,     -inf, -57.7305], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.9244,     -inf, -65.1321,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.3016,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 919: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.8731, -64.0061, -65.0961, -65.2047, -63.7638, -52.8310,
        -64.0538, -69.3630, -70.7593], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.6908, -64.2617, -73.5683, -69.5477, -56.2137,     -inf,
        -60.8592, -61.8490, -79.6194], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.9713, -65.6485, -79.5582, -73.6182,     -inf,     -inf,
        -58.2002, -56.2433, -85.5680], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.0838, -70.4232, -80.3452, -77.5890,     -inf,     -inf,
        -55.8169,     -inf, -85.8897], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.0266, -71.6143, -73.2482, -74.9218,     -inf,     -inf,
            -inf,     -inf, -77.9179], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.4996, -59.7099, -66.5292,     -inf,     -inf,
            -inf,     -inf, -63.9459], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.4097,     -inf, -62.3625,     -inf,     -inf,
            -inf,     -inf, -57.5074], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.5453,     -inf, -65.4810,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.8149,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 920: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.0101, -64.5677, -64.9682, -65.4129, -64.4717, -53.3326,
        -64.0476, -69.5581, -70.5358], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.6908, -64.2617, -73.5683, -69.5477, -56.2137,     -inf,
        -60.8592, -61.8490, -79.6194], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.9713, -65.6485, -79.5582, -73.6182,     -inf,     -inf,
        -58.2002, -56.2433, -85.5680], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.0838, -70.4232, -80.3452, -77.5890,     -inf,     -inf,
        -55.8169,     -inf, -85.8897], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.0266, -71.6143, -73.2482, -74.9218,     -inf,     -inf,
            -inf,     -inf, -77.9179], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.4996, -59.7099, -66.5292,     -inf,     -inf,
            -inf,     -inf, -63.9459], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.4097,     -inf, -62.3625,     -inf,     -inf,
            -inf,     -inf, -57.5074], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.5453,     -inf, -65.4810,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.8149,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 921: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.0101, -64.5677, -64.9682, -65.4129, -64.4717, -53.3326,
        -64.0476, -69.5581, -70.5358], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.6908, -64.2617, -73.5683, -69.5477, -56.2137,     -inf,
        -60.8592, -61.8490, -79.6194], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.9713, -65.6485, -79.5582, -73.6182,     -inf,     -inf,
        -58.2002, -56.2433, -85.5680], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.5790, -71.0836, -80.8227, -78.3829,     -inf,     -inf,
        -55.7940,     -inf, -86.2611], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.5643, -72.2877, -73.7570, -75.7917,     -inf,     -inf,
            -inf,     -inf, -78.3284], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.1485, -60.0882, -67.3584,     -inf,     -inf,
            -inf,     -inf, -64.2919], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.0427,     -inf, -63.2147,     -inf,     -inf,
            -inf,     -inf, -57.8648], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.2190,     -inf, -66.3882,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.2980,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 922: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.5450, -65.1639, -65.4369, -66.2354, -64.7178, -53.6515,
        -64.0121, -69.1928, -70.9345], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.2311, -64.8597, -74.0747, -70.3475, -56.4472,     -inf,
        -60.8129, -61.4665, -80.0369], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.4691, -66.2614, -80.0325, -74.3721,     -inf,     -inf,
        -58.1945, -55.9053, -85.9426], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.5790, -71.0836, -80.8227, -78.3829,     -inf,     -inf,
        -55.7940,     -inf, -86.2611], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.5643, -72.2877, -73.7570, -75.7917,     -inf,     -inf,
            -inf,     -inf, -78.3284], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.1485, -60.0882, -67.3584,     -inf,     -inf,
            -inf,     -inf, -64.2919], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.0427,     -inf, -63.2147,     -inf,     -inf,
            -inf,     -inf, -57.8648], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.2190,     -inf, -66.3882,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.2980,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 923: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.5450, -65.1639, -65.4369, -66.2354, -64.7178, -53.6515,
        -64.0121, -69.1928, -70.9345], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.2311, -64.8597, -74.0747, -70.3475, -56.4472,     -inf,
        -60.8129, -61.4665, -80.0369], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.4691, -66.2614, -80.0325, -74.3721,     -inf,     -inf,
        -58.1945, -55.9053, -85.9426], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.5790, -71.0836, -80.8227, -78.3829,     -inf,     -inf,
        -55.7940,     -inf, -86.2611], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.5643, -72.2877, -73.7570, -75.7917,     -inf,     -inf,
            -inf,     -inf, -78.3284], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.0963, -60.9685, -68.5186,     -inf,     -inf,
            -inf,     -inf, -65.3867], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.9627,     -inf, -64.4010,     -inf,     -inf,
            -inf,     -inf, -58.9850], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.2130,     -inf, -67.6316,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.0200,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 924: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.4726, -65.0942, -66.5842, -67.5434, -63.7415, -53.3604,
        -63.5456, -67.9808, -72.1883], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.1459, -64.7872, -75.2349, -71.6170, -55.4730,     -inf,
        -60.3461, -60.2616, -81.2831], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.1527, -66.2204, -80.7985, -75.4124,     -inf,     -inf,
        -58.0356, -55.1041, -86.8086], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -70.2598, -71.0832, -81.5933, -79.4666,     -inf,     -inf,
        -55.6144,     -inf, -87.1255], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.4786, -72.2778, -74.9275, -77.1386,     -inf,     -inf,
            -inf,     -inf, -79.5761], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.0963, -60.9685, -68.5186,     -inf,     -inf,
            -inf,     -inf, -65.3867], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.9627,     -inf, -64.4010,     -inf,     -inf,
            -inf,     -inf, -58.9850], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.2130,     -inf, -67.6316,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.0200,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 925: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.4726, -65.0942, -66.5842, -67.5434, -63.7415, -53.3604,
        -63.5456, -67.9808, -72.1883], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.1459, -64.7872, -75.2349, -71.6170, -55.4730,     -inf,
        -60.3461, -60.2616, -81.2831], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.1527, -66.2204, -80.7985, -75.4124,     -inf,     -inf,
        -58.0356, -55.1041, -86.8086], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -70.2598, -71.0832, -81.5933, -79.4666,     -inf,     -inf,
        -55.6144,     -inf, -87.1255], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.4786, -72.2778, -74.9275, -77.1386,     -inf,     -inf,
            -inf,     -inf, -79.5761], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.0963, -60.9685, -68.5186,     -inf,     -inf,
            -inf,     -inf, -65.3867], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.9627,     -inf, -64.4010,     -inf,     -inf,
            -inf,     -inf, -58.9850], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.9918,     -inf, -69.5341,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.5151,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 926: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.7451, -65.7472, -68.0825, -69.4977, -63.0335, -53.3395,
        -63.6183, -67.1089, -73.9984], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.4049, -65.4258, -76.7435, -73.5275, -54.7606,     -inf,
        -60.4131, -59.3927, -83.0817], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.2005, -66.8754, -81.9176, -77.0936,     -inf,     -inf,
        -58.4122, -54.6198, -88.2506], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.3076, -71.7840, -82.7193, -81.1976,     -inf,     -inf,
        -55.9765,     -inf, -88.5720], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.7426, -72.9912, -76.4515, -79.1392,     -inf,     -inf,
            -inf,     -inf, -81.3873], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7910, -62.1736, -70.3164,     -inf,     -inf,
            -inf,     -inf, -67.0319], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.6475,     -inf, -66.2344,     -inf,     -inf,
            -inf,     -inf, -60.6625], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.9918,     -inf, -69.5341,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.5151,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 927: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.7451, -65.7472, -68.0825, -69.4977, -63.0335, -53.3395,
        -63.6183, -67.1089, -73.9984], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.4049, -65.4258, -76.7435, -73.5275, -54.7606,     -inf,
        -60.4131, -59.3927, -83.0817], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.2005, -66.8754, -81.9176, -77.0936,     -inf,     -inf,
        -58.4122, -54.6198, -88.2506], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.3076, -71.7840, -82.7193, -81.1976,     -inf,     -inf,
        -55.9765,     -inf, -88.5720], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.7426, -72.9912, -76.4515, -79.1392,     -inf,     -inf,
            -inf,     -inf, -81.3873], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7910, -62.1736, -70.3164,     -inf,     -inf,
            -inf,     -inf, -67.0319], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.6475,     -inf, -66.2344,     -inf,     -inf,
            -inf,     -inf, -60.6625], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.9918,     -inf, -69.5341,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.5151,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 928: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.2224, -66.9547, -69.9380, -71.9932, -62.1365, -53.4409,
        -63.8148, -66.3991, -76.1480], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8669, -66.6166, -78.6011, -75.9756, -53.8617,     -inf,
        -60.6120, -58.6911, -85.2133], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.4251, -68.0753, -83.2831, -79.2586,     -inf,     -inf,
        -59.0100, -54.3913, -89.9575], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.5344, -73.0372, -84.0950, -83.4181,     -inf,     -inf,
        -56.5636,     -inf, -90.2857], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.2310, -74.2503, -78.2978, -81.6569,     -inf,     -inf,
            -inf,     -inf, -83.5449], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.0542, -63.7293, -72.6529,     -inf,     -inf,
            -inf,     -inf, -69.0143], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.9073,     -inf, -68.6133,     -inf,     -inf,
            -inf,     -inf, -62.6840], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.3596,     -inf, -71.9921,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.6762,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 929: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.2224, -66.9547, -69.9380, -71.9932, -62.1365, -53.4409,
        -63.8148, -66.3991, -76.1480], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8669, -66.6166, -78.6011, -75.9756, -53.8617,     -inf,
        -60.6120, -58.6911, -85.2133], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.4251, -68.0753, -83.2831, -79.2586,     -inf,     -inf,
        -59.0100, -54.3913, -89.9575], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.5344, -73.0372, -84.0950, -83.4181,     -inf,     -inf,
        -56.5636,     -inf, -90.2857], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.2310, -74.2503, -78.2978, -81.6569,     -inf,     -inf,
            -inf,     -inf, -83.5449], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.0542, -63.7293, -72.6529,     -inf,     -inf,
            -inf,     -inf, -69.0143], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.9073,     -inf, -68.6133,     -inf,     -inf,
            -inf,     -inf, -62.6840], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.3596,     -inf, -71.9921,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.6762,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 930: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.2224, -66.9547, -69.9380, -71.9932, -62.1365, -53.4409,
        -63.8148, -66.3991, -76.1480], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8669, -66.6166, -78.6011, -75.9756, -53.8617,     -inf,
        -60.6120, -58.6911, -85.2133], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4674, -68.6327, -84.5738, -81.0385,     -inf,     -inf,
        -59.7347, -54.0807, -91.3625], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.5871, -73.5471, -85.3486, -85.1397,     -inf,     -inf,
        -57.3701,     -inf, -91.6669], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.4986, -74.8104, -79.9381, -83.6266,     -inf,     -inf,
            -inf,     -inf, -85.3572], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.6235, -65.2040, -74.5567,     -inf,     -inf,
            -inf,     -inf, -70.6955], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.4554,     -inf, -70.5453,     -inf,     -inf,
            -inf,     -inf, -64.3968], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.0134,     -inf, -73.9942,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -62.1372,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 931: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.5149, -67.4956, -71.7072, -74.0661, -60.9888, -53.3997,
        -64.1454, -65.6013, -78.0002], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.1052, -67.1518, -80.3389, -77.9665, -52.7243,     -inf,
        -61.0059, -57.9494, -87.0141], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4674, -68.6327, -84.5738, -81.0385,     -inf,     -inf,
        -59.7347, -54.0807, -91.3625], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.5871, -73.5471, -85.3486, -85.1397,     -inf,     -inf,
        -57.3701,     -inf, -91.6669], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.4986, -74.8104, -79.9381, -83.6266,     -inf,     -inf,
            -inf,     -inf, -85.3572], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.6235, -65.2040, -74.5567,     -inf,     -inf,
            -inf,     -inf, -70.6955], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.4554,     -inf, -70.5453,     -inf,     -inf,
            -inf,     -inf, -64.3968], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.0134,     -inf, -73.9942,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -62.1372,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 932: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.5149, -67.4956, -71.7072, -74.0661, -60.9888, -53.3997,
        -64.1454, -65.6013, -78.0002], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.1052, -67.1518, -80.3389, -77.9665, -52.7243,     -inf,
        -61.0059, -57.9494, -87.0141], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4674, -68.6327, -84.5738, -81.0385,     -inf,     -inf,
        -59.7347, -54.0807, -91.3625], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.5871, -73.5471, -85.3486, -85.1397,     -inf,     -inf,
        -57.3701,     -inf, -91.6669], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.2502, -73.9581, -80.9317, -84.4373,     -inf,     -inf,
            -inf,     -inf, -86.3245], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7058, -66.0737, -75.3058,     -inf,     -inf,
            -inf,     -inf, -71.5860], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.4826,     -inf, -71.2970,     -inf,     -inf,
            -inf,     -inf, -65.2985], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.1333,     -inf, -74.7962,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.1019,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 933: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.2905, -66.5945, -72.7421, -74.8937, -60.0184, -53.2270,
        -64.8264, -65.2789, -78.9920], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.7939, -66.2816, -81.2818, -78.7160, -51.8461,     -inf,
        -61.7833, -57.7559, -87.8916], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.0836, -67.7880, -85.3476, -81.7299,     -inf,     -inf,
        -60.6358, -54.0669, -92.0727], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.2010, -72.7406, -86.1247, -85.8731,     -inf,     -inf,
        -58.2664,     -inf, -92.3742], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.2502, -73.9581, -80.9317, -84.4373,     -inf,     -inf,
            -inf,     -inf, -86.3245], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7058, -66.0737, -75.3058,     -inf,     -inf,
            -inf,     -inf, -71.5860], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.4826,     -inf, -71.2970,     -inf,     -inf,
            -inf,     -inf, -65.2985], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.1333,     -inf, -74.7962,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.1019,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 934: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.2905, -66.5945, -72.7421, -74.8937, -60.0184, -53.2270,
        -64.8264, -65.2789, -78.9920], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.7939, -66.2816, -81.2818, -78.7160, -51.8461,     -inf,
        -61.7833, -57.7559, -87.8916], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.0836, -67.7880, -85.3476, -81.7299,     -inf,     -inf,
        -60.6358, -54.0669, -92.0727], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.2010, -72.7406, -86.1247, -85.8731,     -inf,     -inf,
        -58.2664,     -inf, -92.3742], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.2502, -73.9581, -80.9317, -84.4373,     -inf,     -inf,
            -inf,     -inf, -86.3245], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.7058, -66.0737, -75.3058,     -inf,     -inf,
            -inf,     -inf, -71.5860], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.7340,     -inf, -71.4880,     -inf,     -inf,
            -inf,     -inf, -65.5666], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.4252,     -inf, -75.0295,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.2369,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 935: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.7823, -65.9037, -73.2622, -75.0504, -59.7990, -52.9676,
        -65.7820, -65.8752, -79.2832], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.2577, -65.6158, -81.7794, -78.8439, -51.6689,     -inf,
        -62.7787, -58.4054, -88.1478], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.5535, -67.1412, -85.8521, -81.8656,     -inf,     -inf,
        -61.6449, -54.7248, -92.3299], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.6657, -72.1923, -86.6635, -86.1122,     -inf,     -inf,
        -59.2222,     -inf, -92.6476], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.7339, -73.3417, -81.4612, -84.6299,     -inf,     -inf,
            -inf,     -inf, -86.6088], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.0122, -66.5793, -75.5055,     -inf,     -inf,
            -inf,     -inf, -71.8563], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.7340,     -inf, -71.4880,     -inf,     -inf,
            -inf,     -inf, -65.5666], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.4252,     -inf, -75.0295,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.2369,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 936: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.7823, -65.9037, -73.2622, -75.0504, -59.7990, -52.9676,
        -65.7820, -65.8752, -79.2832], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.2577, -65.6158, -81.7794, -78.8439, -51.6689,     -inf,
        -62.7787, -58.4054, -88.1478], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.5535, -67.1412, -85.8521, -81.8656,     -inf,     -inf,
        -61.6449, -54.7248, -92.3299], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.6657, -72.1923, -86.6635, -86.1122,     -inf,     -inf,
        -59.2222,     -inf, -92.6476], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.7339, -73.3417, -81.4612, -84.6299,     -inf,     -inf,
            -inf,     -inf, -86.6088], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.0122, -66.5793, -75.5055,     -inf,     -inf,
            -inf,     -inf, -71.8563], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.7340,     -inf, -71.4880,     -inf,     -inf,
            -inf,     -inf, -65.5666], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.4252,     -inf, -75.0295,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -72.0150,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 937: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.7293, -64.9658, -73.3723, -74.8231, -59.4681, -52.7726,
        -66.3133, -66.6273, -79.1905], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.2184, -64.6988, -81.9266, -78.6150, -51.3320,     -inf,
        -63.3150, -59.1552, -88.0834], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.5150, -66.2482, -86.0098, -81.6489,     -inf,     -inf,
        -62.1868, -55.4862, -92.2658], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.6203, -71.3771, -86.8601, -85.9834,     -inf,     -inf,
        -59.7193,     -inf, -92.6059], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.6711, -72.4778, -81.5951, -84.4489,     -inf,     -inf,
            -inf,     -inf, -86.5185], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.8729,     -inf, -77.3819, -72.4559,     -inf,     -inf,
            -inf,     -inf, -84.4655], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.2551,     -inf, -66.1994,     -inf,     -inf,     -inf,
            -inf,     -inf, -72.7646], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.8371,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -65.3847], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -64.9276,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 938: Reward=-176.82, route=[0, 6, 5, 8, 7, 2, 4, 3, 9, 1] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.7293, -64.9658, -73.3723, -74.8231, -59.4681, -52.7726,
        -66.3133, -66.6273, -79.1905], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -73.2184, -64.6988, -81.9266, -78.6150, -51.3320,     -inf,
        -63.3150, -59.1552, -88.0834], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.5150, -66.2482, -86.0098, -81.6489,     -inf,     -inf,
        -62.1868, -55.4862, -92.2658], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.6203, -71.3771, -86.8601, -85.9834,     -inf,     -inf,
        -59.7193,     -inf, -92.6059], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.6711, -72.4778, -81.5951, -84.4489,     -inf,     -inf,
            -inf,     -inf, -86.5185], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.8729,     -inf, -77.3819, -72.4559,     -inf,     -inf,
            -inf,     -inf, -84.4655], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True False  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.2551,     -inf, -66.1994,     -inf,     -inf,     -inf,
            -inf,     -inf, -72.7646], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.8371,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -65.3847], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False  True  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf, -64.9276,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 939: Reward=-176.82, route=[0, 6, 5, 8, 7, 2, 4, 3, 9, 1] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.7293, -64.9658, -73.3723, -74.8231, -59.4681, -52.7726,
        -66.3133, -66.6273, -79.1905], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.8647, -64.5015, -81.3243, -78.2254, -51.2398,     -inf,
        -63.5436, -59.8874, -87.4218], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.1964, -66.0861, -85.5023, -81.3095,     -inf,     -inf,
        -62.3839, -56.1594, -91.6911], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.2808, -71.2695, -86.3316, -85.6712,     -inf,     -inf,
        -59.8992,     -inf, -92.0044], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.2144, -72.3814, -80.8723, -84.0865,     -inf,     -inf,
            -inf,     -inf, -85.7032], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.8623, -65.9809, -74.9936,     -inf,     -inf,
            -inf,     -inf, -70.9313], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.4620,     -inf, -70.9378,     -inf,     -inf,
            -inf,     -inf, -64.6081], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.2174,     -inf, -74.5392,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.5291,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 940: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.2722, -64.7607, -72.6066, -74.3780, -59.4981, -52.7207,
        -66.6177, -67.4926, -78.3595], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.8647, -64.5015, -81.3243, -78.2254, -51.2398,     -inf,
        -63.5436, -59.8874, -87.4218], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.1964, -66.0861, -85.5023, -81.3095,     -inf,     -inf,
        -62.3839, -56.1594, -91.6911], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -74.2808, -71.2695, -86.3316, -85.6712,     -inf,     -inf,
        -59.8992,     -inf, -92.0044], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -72.2144, -72.3814, -80.8723, -84.0865,     -inf,     -inf,
            -inf,     -inf, -85.7032], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.8623, -65.9809, -74.9936,     -inf,     -inf,
            -inf,     -inf, -70.9313], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.4620,     -inf, -70.9378,     -inf,     -inf,
            -inf,     -inf, -64.6081], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.2174,     -inf, -74.5392,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -71.5291,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 941: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -69.2722, -64.7607, -72.6066, -74.3780, -59.4981, -52.7207,
        -66.6177, -67.4926, -78.3595], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.8647, -64.5015, -81.3243, -78.2254, -51.2398,     -inf,
        -63.5436, -59.8874, -87.4218], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -74.1964, -66.0861, -85.5023, -81.3095,     -inf,     -inf,
        -62.3839, -56.1594, -91.6911], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.5575, -71.0386, -85.7993, -85.2737,     -inf,     -inf,
        -59.8850,     -inf, -91.2877], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.3540, -72.1763, -80.1138, -83.6328,     -inf,     -inf,
            -inf,     -inf, -84.7365], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5826, -65.2673, -74.5865,     -inf,     -inf,
            -inf,     -inf, -69.9739], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.1297,     -inf, -70.5075,     -inf,     -inf,
            -inf,     -inf, -63.6283], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.9234,     -inf, -74.1321,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.9567,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 942: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.4172, -64.4650, -71.8170, -73.8516, -59.7224, -52.7664,
        -66.7413, -68.5526, -77.3796], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.0470, -64.2274, -80.5909, -77.7311, -51.4600,     -inf,
        -63.6421, -60.9249, -86.4957], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4940, -65.8073, -84.9788, -80.8841,     -inf,     -inf,
        -62.3862, -57.0072, -90.9879], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.5575, -71.0386, -85.7993, -85.2737,     -inf,     -inf,
        -59.8850,     -inf, -91.2877], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.3540, -72.1763, -80.1138, -83.6328,     -inf,     -inf,
            -inf,     -inf, -84.7365], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5826, -65.2673, -74.5865,     -inf,     -inf,
            -inf,     -inf, -69.9739], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.1297,     -inf, -70.5075,     -inf,     -inf,
            -inf,     -inf, -63.6283], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.9234,     -inf, -74.1321,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.9567,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 943: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -68.4172, -64.4650, -71.8170, -73.8516, -59.7224, -52.7664,
        -66.7413, -68.5526, -77.3796], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -72.0470, -64.2274, -80.5909, -77.7311, -51.4600,     -inf,
        -63.6421, -60.9249, -86.4957], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -73.4940, -65.8073, -84.9788, -80.8841,     -inf,     -inf,
        -62.3862, -57.0072, -90.9879], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -73.5575, -71.0386, -85.7993, -85.2737,     -inf,     -inf,
        -59.8850,     -inf, -91.2877], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -71.3540, -72.1763, -80.1138, -83.6328,     -inf,     -inf,
            -inf,     -inf, -84.7365], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.0727, -64.5366, -74.0720,     -inf,     -inf,
            -inf,     -inf, -68.9581], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.5681,     -inf, -69.9690,     -inf,     -inf,
            -inf,     -inf, -62.5943], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.3897,     -inf, -73.6128,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.2816,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 944: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3258, -63.9440, -71.0056, -73.2159, -59.8685, -52.7946,
        -66.9111, -69.5615, -76.3352], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0027, -63.7276, -79.8385, -77.1305, -51.6033,     -inf,
        -63.7882, -61.9099, -85.5029], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5650, -65.3006, -84.4336, -80.3505,     -inf,     -inf,
        -62.4408, -57.8058, -90.2127], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.6020, -70.5733, -85.2420, -84.7645,     -inf,     -inf,
        -59.9224,     -inf, -90.4950], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.2570, -71.7355, -79.3307, -83.0669,     -inf,     -inf,
            -inf,     -inf, -83.6982], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.0727, -64.5366, -74.0720,     -inf,     -inf,
            -inf,     -inf, -68.9581], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.5681,     -inf, -69.9690,     -inf,     -inf,
            -inf,     -inf, -62.5943], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.3897,     -inf, -73.6128,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -70.2816,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 945: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.3258, -63.9440, -71.0056, -73.2159, -59.8685, -52.7946,
        -66.9111, -69.5615, -76.3352], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0027, -63.7276, -79.8385, -77.1305, -51.6033,     -inf,
        -63.7882, -61.9099, -85.5029], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5650, -65.3006, -84.4336, -80.3505,     -inf,     -inf,
        -62.4408, -57.8058, -90.2127], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.6020, -70.5733, -85.2420, -84.7645,     -inf,     -inf,
        -59.9224,     -inf, -90.4950], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -70.2570, -71.7355, -79.3307, -83.0669,     -inf,     -inf,
            -inf,     -inf, -83.6982], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.0727, -64.5366, -74.0720,     -inf,     -inf,
            -inf,     -inf, -68.9581], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.5681,     -inf, -69.9690,     -inf,     -inf,
            -inf,     -inf, -62.5943], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.7672,     -inf, -72.8898,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.4155,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 946: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.1938, -63.3545, -70.2408, -72.3850, -59.9618, -52.6913,
        -66.9876, -70.5316, -75.4528], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.9190, -63.1618, -79.1254, -76.3309, -51.6982,     -inf,
        -63.8542, -62.8650, -84.6671], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5903, -64.7331, -83.9048, -79.6141,     -inf,     -inf,
        -62.4261, -58.5968, -89.5742], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.5997, -70.0451, -84.7014, -84.0502,     -inf,     -inf,
        -59.8895,     -inf, -89.8408], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.1228, -71.2236, -78.5891, -82.2995,     -inf,     -inf,
            -inf,     -inf, -82.8241], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4906, -63.8658, -73.3635,     -inf,     -inf,
            -inf,     -inf, -68.1144], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -65.9328,     -inf, -69.2317,     -inf,     -inf,
            -inf,     -inf, -61.7337], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.7672,     -inf, -72.8898,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.4155,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 947: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.1938, -63.3545, -70.2408, -72.3850, -59.9618, -52.6913,
        -66.9876, -70.5316, -75.4528], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.9190, -63.1618, -79.1254, -76.3309, -51.6982,     -inf,
        -63.8542, -62.8650, -84.6671], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5903, -64.7331, -83.9048, -79.6141,     -inf,     -inf,
        -62.4261, -58.5968, -89.5742], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.5997, -70.0451, -84.7014, -84.0502,     -inf,     -inf,
        -59.8895,     -inf, -89.8408], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.1228, -71.2236, -78.5891, -82.2995,     -inf,     -inf,
            -inf,     -inf, -82.8241], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4906, -63.8658, -73.3635,     -inf,     -inf,
            -inf,     -inf, -68.1144], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -65.9328,     -inf, -69.2317,     -inf,     -inf,
            -inf,     -inf, -61.7337], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.7672,     -inf, -72.8898,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -69.4155,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 948: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.0187, -63.2891, -69.4857, -71.7234, -60.0495, -52.5731,
        -66.6914, -71.0827, -74.6337], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.7704, -63.1123, -78.4014, -75.6841, -51.7936,     -inf,
        -63.5710, -63.4238, -83.8719], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.5573, -64.6774, -83.3406, -79.0304,     -inf,     -inf,
        -62.0641, -59.0034, -88.9625], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -70.5383, -70.0311, -84.1229, -83.4885,     -inf,     -inf,
        -59.5044,     -inf, -89.2119], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.9449, -71.2274, -77.8344, -81.6893,     -inf,     -inf,
            -inf,     -inf, -82.0065], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4515, -63.1586, -72.7822,     -inf,     -inf,
            -inf,     -inf, -67.3103], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -65.8544,     -inf, -68.6191,     -inf,     -inf,
            -inf,     -inf, -60.9194], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.6918,     -inf, -72.2900,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.6929,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 949: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.0187, -63.2891, -69.4857, -71.7234, -60.0495, -52.5731,
        -66.6914, -71.0827, -74.6337], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.7704, -63.1123, -78.4014, -75.6841, -51.7936,     -inf,
        -63.5710, -63.4238, -83.8719], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.5573, -64.6774, -83.3406, -79.0304,     -inf,     -inf,
        -62.0641, -59.0034, -88.9625], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -70.5383, -70.0311, -84.1229, -83.4885,     -inf,     -inf,
        -59.5044,     -inf, -89.2119], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.9449, -71.2274, -77.8344, -81.6893,     -inf,     -inf,
            -inf,     -inf, -82.0065], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.4515, -63.1586, -72.7822,     -inf,     -inf,
            -inf,     -inf, -67.3103], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -65.8544,     -inf, -68.6191,     -inf,     -inf,
            -inf,     -inf, -60.9194], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.6918,     -inf, -72.2900,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -68.6929,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 950: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.0187, -63.2891, -69.4857, -71.7234, -60.0495, -52.5731,
        -66.6914, -71.0827, -74.6337], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.7704, -63.1123, -78.4014, -75.6841, -51.7936,     -inf,
        -63.5710, -63.4238, -83.8719], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.9593, -65.4821, -82.9491, -78.9409,     -inf,     -inf,
        -61.3962, -59.0185, -88.6069], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.9167, -70.8860, -83.7170, -83.4256,     -inf,     -inf,
        -58.8085,     -inf, -88.8383], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.2583, -72.0950, -77.3404, -81.6081,     -inf,     -inf,
            -inf,     -inf, -81.5463], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.3149, -62.7141, -72.7504,     -inf,     -inf,
            -inf,     -inf, -66.8582], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.6954,     -inf, -68.5677,     -inf,     -inf,
            -inf,     -inf, -60.4716], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.5420,     -inf, -72.2607,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -57.8653,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 951: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.3509, -64.1027, -69.0709, -71.6666, -60.1691, -52.2589,
        -65.9526, -71.1000, -74.2094], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.1272, -63.9325, -78.0101, -75.6328, -51.9218,     -inf,
        -62.8459, -63.4490, -83.4599], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.9593, -65.4821, -82.9491, -78.9409,     -inf,     -inf,
        -61.3962, -59.0185, -88.6069], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.9167, -70.8860, -83.7170, -83.4256,     -inf,     -inf,
        -58.8085,     -inf, -88.8383], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.2583, -72.0950, -77.3404, -81.6081,     -inf,     -inf,
            -inf,     -inf, -81.5463], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.3149, -62.7141, -72.7504,     -inf,     -inf,
            -inf,     -inf, -66.8582], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.6954,     -inf, -68.5677,     -inf,     -inf,
            -inf,     -inf, -60.4716], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.5420,     -inf, -72.2607,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -57.8653,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 952: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.3509, -64.1027, -69.0709, -71.6666, -60.1691, -52.2589,
        -65.9526, -71.1000, -74.2094], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.1272, -63.9325, -78.0101, -75.6328, -51.9218,     -inf,
        -62.8459, -63.4490, -83.4599], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.9593, -65.4821, -82.9491, -78.9409,     -inf,     -inf,
        -61.3962, -59.0185, -88.6069], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.9167, -70.8860, -83.7170, -83.4256,     -inf,     -inf,
        -58.8085,     -inf, -88.8383], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.7042, -73.4883, -77.3032, -81.9689,     -inf,     -inf,
            -inf,     -inf, -81.5714], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7335, -62.6771, -73.1218,     -inf,     -inf,
            -inf,     -inf, -66.8302], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.1043,     -inf, -68.9259,     -inf,     -inf,
            -inf,     -inf, -60.4548], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.9774,     -inf, -72.6464,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.1198,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 953: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.8294, -65.4638, -69.1825, -72.1176, -59.9906, -51.7261,
        -64.9558, -70.3323, -74.2850], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.5744, -65.2904, -78.0882, -76.0304, -51.7604,     -inf,
        -61.9365, -62.7499, -83.4977], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.4107, -66.8218, -82.8779, -79.2527,     -inf,     -inf,
        -60.6236, -58.4313, -88.5840], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.3488, -72.2570, -83.6298, -83.7454,     -inf,     -inf,
        -58.0265,     -inf, -88.8002], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.7042, -73.4883, -77.3032, -81.9689,     -inf,     -inf,
            -inf,     -inf, -81.5714], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7335, -62.6771, -73.1218,     -inf,     -inf,
            -inf,     -inf, -66.8302], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.1043,     -inf, -68.9259,     -inf,     -inf,
            -inf,     -inf, -60.4548], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.9774,     -inf, -72.6464,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.1198,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 954: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.8294, -65.4638, -69.1825, -72.1176, -59.9906, -51.7261,
        -64.9558, -70.3323, -74.2850], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.5744, -65.2904, -78.0882, -76.0304, -51.7604,     -inf,
        -61.9365, -62.7499, -83.4977], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.4107, -66.8218, -82.8779, -79.2527,     -inf,     -inf,
        -60.6236, -58.4313, -88.5840], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.3488, -72.2570, -83.6298, -83.7454,     -inf,     -inf,
        -58.0265,     -inf, -88.8002], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.7042, -73.4883, -77.3032, -81.9689,     -inf,     -inf,
            -inf,     -inf, -81.5714], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7335, -62.6771, -73.1218,     -inf,     -inf,
            -inf,     -inf, -66.8302], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.6206,     -inf, -69.4913,     -inf,     -inf,
            -inf,     -inf, -60.9129], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.5365,     -inf, -73.2474,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.5395,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 955: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.4653, -66.9299, -69.6383, -72.7886, -59.8694, -51.2929,
        -64.0976, -69.4825, -74.8315], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.2041, -66.7102, -78.4299, -76.5722, -51.7482,     -inf,
        -61.2471, -61.9855, -84.0118], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.9825, -68.2722, -83.1047, -79.7620,     -inf,     -inf,
        -60.0075, -57.7867, -88.9796], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.9128, -73.6941, -83.8378, -84.2235,     -inf,     -inf,
        -57.4429,     -inf, -89.1837], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.3060, -74.9678, -77.6053, -82.5254,     -inf,     -inf,
            -inf,     -inf, -82.0639], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.2594, -62.9595, -73.6933,     -inf,     -inf,
            -inf,     -inf, -67.2658], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.6206,     -inf, -69.4913,     -inf,     -inf,
            -inf,     -inf, -60.9129], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.5365,     -inf, -73.2474,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.5395,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 956: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.4653, -66.9299, -69.6383, -72.7886, -59.8694, -51.2929,
        -64.0976, -69.4825, -74.8315], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.2041, -66.7102, -78.4299, -76.5722, -51.7482,     -inf,
        -61.2471, -61.9855, -84.0118], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.9825, -68.2722, -83.1047, -79.7620,     -inf,     -inf,
        -60.0075, -57.7867, -88.9796], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.9128, -73.6941, -83.8378, -84.2235,     -inf,     -inf,
        -57.4429,     -inf, -89.1837], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.3060, -74.9678, -77.6053, -82.5254,     -inf,     -inf,
            -inf,     -inf, -82.0639], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.2594, -62.9595, -73.6933,     -inf,     -inf,
            -inf,     -inf, -67.2658], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.6206,     -inf, -69.4913,     -inf,     -inf,
            -inf,     -inf, -60.9129], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.5365,     -inf, -73.2474,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.5559,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 957: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.1201, -68.0229, -69.8624, -73.4622, -60.0931, -51.1085,
        -63.2646, -68.8929, -75.0416], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.8632, -67.7700, -78.5626, -77.1391, -52.0611,     -inf,
        -60.5571, -61.4658, -84.2029], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.6253, -69.3609, -83.2095, -80.3317,     -inf,     -inf,
        -59.3362, -57.3027, -89.1357], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.5485, -74.7721, -83.9195, -84.7645,     -inf,     -inf,
        -56.8012,     -inf, -89.3232], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.9352, -76.0604, -77.7012, -83.0927,     -inf,     -inf,
            -inf,     -inf, -82.2206], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.3931, -63.0270, -74.2885,     -inf,     -inf,
            -inf,     -inf, -67.3645], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7308,     -inf, -70.0769,     -inf,     -inf,
            -inf,     -inf, -61.0240], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.6908,     -inf, -73.8707,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.5559,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 958: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.1201, -68.0229, -69.8624, -73.4622, -60.0931, -51.1085,
        -63.2646, -68.8929, -75.0416], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.8632, -67.7700, -78.5626, -77.1391, -52.0611,     -inf,
        -60.5571, -61.4658, -84.2029], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.6253, -69.3609, -83.2095, -80.3317,     -inf,     -inf,
        -59.3362, -57.3027, -89.1357], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.5485, -74.7721, -83.9195, -84.7645,     -inf,     -inf,
        -56.8012,     -inf, -89.3232], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.9352, -76.0604, -77.7012, -83.0927,     -inf,     -inf,
            -inf,     -inf, -82.2206], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.3931, -63.0270, -74.2885,     -inf,     -inf,
            -inf,     -inf, -67.3645], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7308,     -inf, -70.0769,     -inf,     -inf,
            -inf,     -inf, -61.0240], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.6908,     -inf, -73.8707,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.5559,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 959: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.1201, -68.0229, -69.8624, -73.4622, -60.0931, -51.1085,
        -63.2646, -68.8929, -75.0416], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.5030, -67.9139, -78.2414, -76.9998, -52.4205,     -inf,
        -60.1335, -61.0867, -84.1916], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.2804, -69.5250, -82.9099, -80.2106,     -inf,     -inf,
        -58.9062, -56.9029, -89.1468], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.1905, -74.9535, -83.5962, -84.6411,     -inf,     -inf,
        -56.3727,     -inf, -89.3170], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.5424, -76.2579, -77.3437, -82.9774,     -inf,     -inf,
            -inf,     -inf, -82.1790], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.5363, -62.6012, -74.1187,     -inf,     -inf,
            -inf,     -inf, -67.2867], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.8329,     -inf, -69.8813,     -inf,     -inf,
            -inf,     -inf, -60.9555], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.8329,     -inf, -73.6970,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.5848,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 960: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.7583, -68.1565, -69.5426, -73.3385, -60.4465, -50.8816,
        -62.8016, -68.4985, -75.0358], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.5030, -67.9139, -78.2414, -76.9998, -52.4205,     -inf,
        -60.1335, -61.0867, -84.1916], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.2804, -69.5250, -82.9099, -80.2106,     -inf,     -inf,
        -58.9062, -56.9029, -89.1468], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.1905, -74.9535, -83.5962, -84.6411,     -inf,     -inf,
        -56.3727,     -inf, -89.3170], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.5424, -76.2579, -77.3437, -82.9774,     -inf,     -inf,
            -inf,     -inf, -82.1790], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.5363, -62.6012, -74.1187,     -inf,     -inf,
            -inf,     -inf, -67.2867], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.8329,     -inf, -69.8813,     -inf,     -inf,
            -inf,     -inf, -60.9555], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.8329,     -inf, -73.6970,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.5848,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 961: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.7583, -68.1565, -69.5426, -73.3385, -60.4465, -50.8816,
        -62.8016, -68.4985, -75.0358], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.5030, -67.9139, -78.2414, -76.9998, -52.4205,     -inf,
        -60.1335, -61.0867, -84.1916], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.2804, -69.5250, -82.9099, -80.2106,     -inf,     -inf,
        -58.9062, -56.9029, -89.1468], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.1255, -75.0769, -83.4020, -84.6304,     -inf,     -inf,
        -56.1647,     -inf, -89.6959], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.4640, -76.3978, -77.1487, -82.9838,     -inf,     -inf,
            -inf,     -inf, -82.5660], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.6216, -62.3200, -74.0442,     -inf,     -inf,
            -inf,     -inf, -67.6664], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.8777,     -inf, -69.7758,     -inf,     -inf,
            -inf,     -inf, -61.3513], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.9302,     -inf, -73.6139,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.5536,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 962: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.7133, -68.2208, -69.3645, -73.3105, -60.9697, -50.9706,
        -62.5813, -67.9461, -75.4634], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.4495, -67.9910, -78.0780, -76.9721, -52.9282,     -inf,
        -59.9247, -60.5439, -84.5992], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.2252, -69.6218, -82.7368, -80.1921,     -inf,     -inf,
        -58.7031, -56.3687, -89.5396], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.1255, -75.0769, -83.4020, -84.6304,     -inf,     -inf,
        -56.1647,     -inf, -89.6959], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.4640, -76.3978, -77.1487, -82.9838,     -inf,     -inf,
            -inf,     -inf, -82.5660], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.6216, -62.3200, -74.0442,     -inf,     -inf,
            -inf,     -inf, -67.6664], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.8777,     -inf, -69.7758,     -inf,     -inf,
            -inf,     -inf, -61.3513], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.9302,     -inf, -73.6139,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.5536,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 963: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.7133, -68.2208, -69.3645, -73.3105, -60.9697, -50.9706,
        -62.5813, -67.9461, -75.4634], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.4495, -67.9910, -78.0780, -76.9721, -52.9282,     -inf,
        -59.9247, -60.5439, -84.5992], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.2252, -69.6218, -82.7368, -80.1921,     -inf,     -inf,
        -58.7031, -56.3687, -89.5396], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.1255, -75.0769, -83.4020, -84.6304,     -inf,     -inf,
        -56.1647,     -inf, -89.6959], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.4640, -76.3978, -77.1487, -82.9838,     -inf,     -inf,
            -inf,     -inf, -82.5660], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.5419, -62.0608, -73.7899,     -inf,     -inf,
            -inf,     -inf, -67.9657], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7587,     -inf, -69.4854,     -inf,     -inf,
            -inf,     -inf, -61.6640], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.8590,     -inf, -73.3444,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.3598,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 964: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.5804, -68.1113, -69.1657, -73.0771, -61.6794, -51.1350,
        -62.4928, -67.3002, -75.7815], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.3129, -67.9013, -77.9203, -76.7689, -53.5907,     -inf,
        -59.8069, -59.8849, -84.8977], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.1025, -69.5432, -82.5920, -80.0030,     -inf,     -inf,
        -58.5777, -55.6878, -89.8482], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -67.9897, -75.0350, -83.2434, -84.4622,     -inf,     -inf,
        -56.0245,     -inf, -89.9926], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.2987, -76.3752, -76.9679, -82.8212,     -inf,     -inf,
            -inf,     -inf, -82.8466], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.5419, -62.0608, -73.7899,     -inf,     -inf,
            -inf,     -inf, -67.9657], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7587,     -inf, -69.4854,     -inf,     -inf,
            -inf,     -inf, -61.6640], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.8590,     -inf, -73.3444,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -61.3598,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 965: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.5804, -68.1113, -69.1657, -73.0771, -61.6794, -51.1350,
        -62.4928, -67.3002, -75.7815], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.3129, -67.9013, -77.9203, -76.7689, -53.5907,     -inf,
        -59.8069, -59.8849, -84.8977], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.1025, -69.5432, -82.5920, -80.0030,     -inf,     -inf,
        -58.5777, -55.6878, -89.8482], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -67.9897, -75.0350, -83.2434, -84.4622,     -inf,     -inf,
        -56.0245,     -inf, -89.9926], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.2987, -76.3752, -76.9679, -82.8212,     -inf,     -inf,
            -inf,     -inf, -82.8466], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.5419, -62.0608, -73.7899,     -inf,     -inf,
            -inf,     -inf, -67.9657], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.7587,     -inf, -69.4854,     -inf,     -inf,
            -inf,     -inf, -61.6640], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.5621,     -inf, -72.7541,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.9251,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 966: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.8171, -67.7788, -69.2226, -72.5293, -62.3438, -51.3042,
        -62.8389, -66.8469, -76.3814], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.5376, -67.6045, -78.0343, -76.2687, -54.1888,     -inf,
        -60.1046, -59.4126, -85.4747], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.3277, -69.2663, -82.6974, -79.5104,     -inf,     -inf,
        -58.8818, -55.2185, -90.4109], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.2029, -74.8383, -83.3543, -84.0306,     -inf,     -inf,
        -56.2859,     -inf, -90.5555], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.5031, -76.1661, -77.0703, -82.3745,     -inf,     -inf,
            -inf,     -inf, -83.4153], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.2286, -62.0843, -73.2276,     -inf,     -inf,
            -inf,     -inf, -68.5676], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.3956,     -inf, -68.8808,     -inf,     -inf,
            -inf,     -inf, -62.2816], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.5621,     -inf, -72.7541,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.9251,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 967: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -62.8171, -67.7788, -69.2226, -72.5293, -62.3438, -51.3042,
        -62.8389, -66.8469, -76.3814], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.5376, -67.6045, -78.0343, -76.2687, -54.1888,     -inf,
        -60.1046, -59.4126, -85.4747], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.3277, -69.2663, -82.6974, -79.5104,     -inf,     -inf,
        -58.8818, -55.2185, -90.4109], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.2029, -74.8383, -83.3543, -84.0306,     -inf,     -inf,
        -56.2859,     -inf, -90.5555], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.5031, -76.1661, -77.0703, -82.3745,     -inf,     -inf,
            -inf,     -inf, -83.4153], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.2286, -62.0843, -73.2276,     -inf,     -inf,
            -inf,     -inf, -68.5676], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.3956,     -inf, -68.8808,     -inf,     -inf,
            -inf,     -inf, -62.2816], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.5621,     -inf, -72.7541,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.9251,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 968: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.1647, -67.8005, -69.5520, -72.2201, -62.6841, -51.2806,
        -62.9055, -66.1758, -77.1210], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.8685, -67.6383, -78.3770, -75.9606, -54.4970,     -inf,
        -60.1714, -58.7479, -86.1830], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.6203, -69.3292, -82.9690, -79.1913,     -inf,     -inf,
        -58.9850, -54.6246, -91.0344], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.4907, -74.9527, -83.6228, -83.7409,     -inf,     -inf,
        -56.3723,     -inf, -91.1750], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.8216, -76.2806, -77.4051, -82.1113,     -inf,     -inf,
            -inf,     -inf, -84.1182], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.2855, -62.3370, -72.8682,     -inf,     -inf,
            -inf,     -inf, -69.2808], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.4100,     -inf, -68.4815,     -inf,     -inf,
            -inf,     -inf, -63.0057], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.6501,     -inf, -72.3758,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.8569,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 969: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.1647, -67.8005, -69.5520, -72.2201, -62.6841, -51.2806,
        -62.9055, -66.1758, -77.1210], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.8685, -67.6383, -78.3770, -75.9606, -54.4970,     -inf,
        -60.1714, -58.7479, -86.1830], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.6203, -69.3292, -82.9690, -79.1913,     -inf,     -inf,
        -58.9850, -54.6246, -91.0344], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.4907, -74.9527, -83.6228, -83.7409,     -inf,     -inf,
        -56.3723,     -inf, -91.1750], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -65.8216, -76.2806, -77.4051, -82.1113,     -inf,     -inf,
            -inf,     -inf, -84.1182], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.2855, -62.3370, -72.8682,     -inf,     -inf,
            -inf,     -inf, -69.2808], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.4100,     -inf, -68.4815,     -inf,     -inf,
            -inf,     -inf, -63.0057], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.6501,     -inf, -72.3758,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.8569,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 970: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.1647, -67.8005, -69.5520, -72.2201, -62.6841, -51.2806,
        -62.9055, -66.1758, -77.1210], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -66.8685, -67.6383, -78.3770, -75.9606, -54.4970,     -inf,
        -60.1714, -58.7479, -86.1830], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.8477, -69.1431, -82.9592, -78.5561,     -inf,     -inf,
        -58.8474, -54.1493, -91.3234], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.7126, -74.8441, -83.6156, -83.1580,     -inf,     -inf,
        -56.1943,     -inf, -91.4609], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.0675, -76.1596, -77.4475, -81.5400,     -inf,     -inf,
            -inf,     -inf, -84.4703], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.0742, -62.3497, -72.2303,     -inf,     -inf,
            -inf,     -inf, -69.6766], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.1544,     -inf, -67.8134,     -inf,     -inf,
            -inf,     -inf, -63.4268], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.4586,     -inf, -71.7275,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.5165,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 971: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.4359, -67.5618, -69.5818, -71.5825, -62.9249, -51.1297,
        -62.7528, -65.6405, -77.5116], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.1342, -67.4110, -78.4094, -75.3180, -54.7241,     -inf,
        -60.0259, -58.2191, -86.5490], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.8477, -69.1431, -82.9592, -78.5561,     -inf,     -inf,
        -58.8474, -54.1493, -91.3234], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.7126, -74.8441, -83.6156, -83.1580,     -inf,     -inf,
        -56.1943,     -inf, -91.4609], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.0675, -76.1596, -77.4475, -81.5400,     -inf,     -inf,
            -inf,     -inf, -84.4703], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -73.0742, -62.3497, -72.2303,     -inf,     -inf,
            -inf,     -inf, -69.6766], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.1544,     -inf, -67.8134,     -inf,     -inf,
            -inf,     -inf, -63.4268], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -76.4586,     -inf, -71.7275,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -60.5165,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 972: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.4359, -67.5618, -69.5818, -71.5825, -62.9249, -51.1297,
        -62.7528, -65.6405, -77.5116], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.1342, -67.4110, -78.4094, -75.3180, -54.7241,     -inf,
        -60.0259, -58.2191, -86.5490], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -68.8477, -69.1431, -82.9592, -78.5561,     -inf,     -inf,
        -58.8474, -54.1493, -91.3234], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -68.7126, -74.8441, -83.6156, -83.1580,     -inf,     -inf,
        -56.1943,     -inf, -91.4609], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.4580, -75.7060, -77.6328, -80.9796,     -inf,     -inf,
            -inf,     -inf, -84.8795], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.5011, -62.5216, -71.5971,     -inf,     -inf,
            -inf,     -inf, -70.1455], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5379,     -inf, -67.1577,     -inf,     -inf,
            -inf,     -inf, -63.9297], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.9203,     -inf, -71.0954,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.8193,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 973: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.8463, -66.9693, -69.7199, -70.9067, -63.0886, -51.0668,
        -63.0625, -65.6886, -77.9461], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.5572, -66.8240, -78.5527, -74.6438, -54.8803,     -inf,
        -60.3301, -58.2584, -86.9750], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.2277, -68.6074, -83.0998, -77.9165,     -inf,     -inf,
        -59.1253, -54.2190, -91.6831], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.0811, -74.4325, -83.7784, -82.6246,     -inf,     -inf,
        -56.3942,     -inf, -91.8265], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.4580, -75.7060, -77.6328, -80.9796,     -inf,     -inf,
            -inf,     -inf, -84.8795], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.5011, -62.5216, -71.5971,     -inf,     -inf,
            -inf,     -inf, -70.1455], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5379,     -inf, -67.1577,     -inf,     -inf,
            -inf,     -inf, -63.9297], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.9203,     -inf, -71.0954,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.8193,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 974: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -63.8463, -66.9693, -69.7199, -70.9067, -63.0886, -51.0668,
        -63.0625, -65.6886, -77.9461], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -67.5572, -66.8240, -78.5527, -74.6438, -54.8803,     -inf,
        -60.3301, -58.2584, -86.9750], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.2277, -68.6074, -83.0998, -77.9165,     -inf,     -inf,
        -59.1253, -54.2190, -91.6831], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.0811, -74.4325, -83.7784, -82.6246,     -inf,     -inf,
        -56.3942,     -inf, -91.8265], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.4580, -75.7060, -77.6328, -80.9796,     -inf,     -inf,
            -inf,     -inf, -84.8795], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -72.5011, -62.5216, -71.5971,     -inf,     -inf,
            -inf,     -inf, -70.1455], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.9790,     -inf, -66.5726,     -inf,     -inf,
            -inf,     -inf, -64.3763], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.4429,     -inf, -70.5383,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.2105,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 975: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.2865, -66.4153, -69.6894, -70.2596, -63.1754, -51.4603,
        -63.5052, -66.0417, -78.3096], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.0340, -66.2700, -78.5543, -74.0181, -54.9506,     -inf,
        -60.7396, -58.5763, -87.3534], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.6899, -68.0950, -83.1525, -77.3401,     -inf,     -inf,
        -59.4814, -54.5168, -92.0476], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.5335, -74.0175, -83.8341, -82.1249,     -inf,     -inf,
        -56.6937,     -inf, -92.1848], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.9047, -75.2460, -77.6652, -80.4370,     -inf,     -inf,
            -inf,     -inf, -85.2302], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.9724, -62.5415, -71.0231,     -inf,     -inf,
            -inf,     -inf, -70.5530], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.9790,     -inf, -66.5726,     -inf,     -inf,
            -inf,     -inf, -64.3763], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.4429,     -inf, -70.5383,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -59.2105,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 976: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.2865, -66.4153, -69.6894, -70.2596, -63.1754, -51.4603,
        -63.5052, -66.0417, -78.3096], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.0340, -66.2700, -78.5543, -74.0181, -54.9506,     -inf,
        -60.7396, -58.5763, -87.3534], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -69.6899, -68.0950, -83.1525, -77.3401,     -inf,     -inf,
        -59.4814, -54.5168, -92.0476], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -69.5335, -74.0175, -83.8341, -82.1249,     -inf,     -inf,
        -56.6937,     -inf, -92.1848], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -66.9047, -75.2460, -77.6652, -80.4370,     -inf,     -inf,
            -inf,     -inf, -85.2302], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.9724, -62.5415, -71.0231,     -inf,     -inf,
            -inf,     -inf, -70.5530], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.9790,     -inf, -66.5726,     -inf,     -inf,
            -inf,     -inf, -64.3763], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -75.4429,     -inf, -70.5383,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -58.3479,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 977: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.8907, -65.5948, -69.6241, -69.5247, -62.7404, -51.6613,
        -63.7826, -66.1139, -78.3691], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.6724, -65.4536, -78.5208, -73.3043, -54.4962,     -inf,
        -60.9875, -58.6187, -87.4326], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.2904, -67.3223, -83.1008, -76.6491,     -inf,     -inf,
        -59.7226, -54.6051, -92.0555], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -70.1324, -73.3041, -83.7785, -81.4762,     -inf,     -inf,
        -56.9065,     -inf, -92.1786], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.5238, -74.5098, -77.6439, -79.7883,     -inf,     -inf,
            -inf,     -inf, -85.2722], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.1654, -62.4855, -70.3229,     -inf,     -inf,
            -inf,     -inf, -70.6146], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.1356,     -inf, -65.8596,     -inf,     -inf,
            -inf,     -inf, -64.4695], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.6571,     -inf, -69.8491,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -58.3479,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 978: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.8907, -65.5948, -69.6241, -69.5247, -62.7404, -51.6613,
        -63.7826, -66.1139, -78.3691], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -68.6724, -65.4536, -78.5208, -73.3043, -54.4962,     -inf,
        -60.9875, -58.6187, -87.4326], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -70.2904, -67.3223, -83.1008, -76.6491,     -inf,     -inf,
        -59.7226, -54.6051, -92.0555], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -70.1324, -73.3041, -83.7785, -81.4762,     -inf,     -inf,
        -56.9065,     -inf, -92.1786], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -67.5238, -74.5098, -77.6439, -79.7883,     -inf,     -inf,
            -inf,     -inf, -85.2722], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -71.1654, -62.4855, -70.3229,     -inf,     -inf,
            -inf,     -inf, -70.6146], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.1356,     -inf, -65.8596,     -inf,     -inf,
            -inf,     -inf, -64.4695], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.6571,     -inf, -69.8491,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -58.3479,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 979: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -64.8907, -65.5948, -69.6241, -69.5247, -62.7404, -51.6613,
        -63.7826, -66.1139, -78.3691], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.7820, -64.8905, -79.0127, -73.3096, -54.1644,     -inf,
        -61.8248, -59.0634, -88.0319], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.3529, -66.7839, -83.5198, -76.6446,     -inf,     -inf,
        -60.5975, -55.1351, -92.5559], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.1979, -72.8022, -84.1940, -81.5039,     -inf,     -inf,
        -57.7728,     -inf, -92.6656], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.6322, -74.0096, -78.1318, -79.8512,     -inf,     -inf,
            -inf,     -inf, -85.8448], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.6431, -62.9856, -70.3980,     -inf,     -inf,
            -inf,     -inf, -71.2216], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.6011,     -inf, -65.9488,     -inf,     -inf,
            -inf,     -inf, -65.1231], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.1630,     -inf, -69.9777,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -57.7781,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 980: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.9849, -65.0431, -70.1006, -69.5348, -62.4306, -52.0645,
        -64.6341, -66.5757, -78.9622], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.7820, -64.8905, -79.0127, -73.3096, -54.1644,     -inf,
        -61.8248, -59.0634, -88.0319], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.3529, -66.7839, -83.5198, -76.6446,     -inf,     -inf,
        -60.5975, -55.1351, -92.5559], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.1979, -72.8022, -84.1940, -81.5039,     -inf,     -inf,
        -57.7728,     -inf, -92.6656], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.6322, -74.0096, -78.1318, -79.8512,     -inf,     -inf,
            -inf,     -inf, -85.8448], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -70.6431, -62.9856, -70.3980,     -inf,     -inf,
            -inf,     -inf, -71.2216], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.6011,     -inf, -65.9488,     -inf,     -inf,
            -inf,     -inf, -65.1231], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -74.1630,     -inf, -69.9777,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -57.7781,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 981: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.9849, -65.0431, -70.1006, -69.5348, -62.4306, -52.0645,
        -64.6341, -66.5757, -78.9622], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.7820, -64.8905, -79.0127, -73.3096, -54.1644,     -inf,
        -61.8248, -59.0634, -88.0319], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.3529, -66.7839, -83.5198, -76.6446,     -inf,     -inf,
        -60.5975, -55.1351, -92.5559], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.8727, -72.1464, -84.8068, -81.7292,     -inf,     -inf,
        -58.5460,     -inf, -93.2089], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.3838, -73.3423, -78.8735, -80.1271,     -inf,     -inf,
            -inf,     -inf, -86.5342], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.9651, -63.7319, -70.6867,     -inf,     -inf,
            -inf,     -inf, -71.9097], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.9027,     -inf, -66.2532,     -inf,     -inf,
            -inf,     -inf, -65.8503], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.5006,     -inf, -70.3267,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -57.0198,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 982: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.7242, -64.3450, -70.8685, -69.7946, -61.7781, -52.2010,
        -65.3279, -66.8211, -79.6682], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.5294, -64.1840, -79.7858, -73.5505, -53.4901,     -inf,
        -62.5095, -59.3029, -88.7380], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.0306, -66.0936, -84.1346, -76.8350,     -inf,     -inf,
        -61.3787, -55.5301, -93.1109], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.8727, -72.1464, -84.8068, -81.7292,     -inf,     -inf,
        -58.5460,     -inf, -93.2089], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.3838, -73.3423, -78.8735, -80.1271,     -inf,     -inf,
            -inf,     -inf, -86.5342], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.9651, -63.7319, -70.6867,     -inf,     -inf,
            -inf,     -inf, -71.9097], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.9027,     -inf, -66.2532,     -inf,     -inf,
            -inf,     -inf, -65.8503], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.5006,     -inf, -70.3267,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -57.0198,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 983: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.7242, -64.3450, -70.8685, -69.7946, -61.7781, -52.2010,
        -65.3279, -66.8211, -79.6682], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.5294, -64.1840, -79.7858, -73.5505, -53.4901,     -inf,
        -62.5095, -59.3029, -88.7380], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.0306, -66.0936, -84.1346, -76.8350,     -inf,     -inf,
        -61.3787, -55.5301, -93.1109], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.8727, -72.1464, -84.8068, -81.7292,     -inf,     -inf,
        -58.5460,     -inf, -93.2089], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.3838, -73.3423, -78.8735, -80.1271,     -inf,     -inf,
            -inf,     -inf, -86.5342], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5406, -64.0712, -71.0981,     -inf,     -inf,
            -inf,     -inf, -72.0436], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.4496,     -inf, -66.6705,     -inf,     -inf,
            -inf,     -inf, -65.9982], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.0892,     -inf, -70.7929,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -56.4861,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 984: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.0342, -63.8815, -71.2279, -70.1576, -61.2718, -52.4177,
        -65.8421, -66.9978, -79.8233], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8534, -63.7114, -80.1621, -73.9004, -52.9579,     -inf,
        -63.0067, -59.4631, -88.9057], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.3353, -65.6219, -84.4354, -77.1554,     -inf,     -inf,
        -61.9332, -55.7571, -93.2206], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.1682, -71.7131, -85.1009, -82.0876,     -inf,     -inf,
        -59.0911,     -inf, -93.3027], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.7017, -72.9151, -79.2055, -80.5153,     -inf,     -inf,
            -inf,     -inf, -86.6741], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5406, -64.0712, -71.0981,     -inf,     -inf,
            -inf,     -inf, -72.0436], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.4496,     -inf, -66.6705,     -inf,     -inf,
            -inf,     -inf, -65.9982], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -73.0892,     -inf, -70.7929,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -56.4861,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 985: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.0342, -63.8815, -71.2279, -70.1576, -61.2718, -52.4177,
        -65.8421, -66.9978, -79.8233], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8534, -63.7114, -80.1621, -73.9004, -52.9579,     -inf,
        -63.0067, -59.4631, -88.9057], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.3353, -65.6219, -84.4354, -77.1554,     -inf,     -inf,
        -61.9332, -55.7571, -93.2206], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.1682, -71.7131, -85.1009, -82.0876,     -inf,     -inf,
        -59.0911,     -inf, -93.3027], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.7017, -72.9151, -79.2055, -80.5153,     -inf,     -inf,
            -inf,     -inf, -86.6741], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -69.5406, -64.0712, -71.0981,     -inf,     -inf,
            -inf,     -inf, -72.0436], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.4496,     -inf, -66.6705,     -inf,     -inf,
            -inf,     -inf, -65.9982], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -72.3024,     -inf, -70.9884,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -55.6221,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 986: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1735, -63.0578, -71.1818, -70.1752, -60.7851, -52.6014,
        -66.3489, -67.4604, -79.4391], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0152, -62.8834, -80.1443, -73.9143, -52.4419,     -inf,
        -63.4800, -59.8981, -88.5463], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5060, -64.7939, -84.4148, -77.1674,     -inf,     -inf,
        -62.4174, -56.1950, -92.8622], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.3289, -70.9203, -85.0743, -82.1376,     -inf,     -inf,
        -59.5661,     -inf, -92.9259], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.8489, -72.1346, -79.1579, -80.5808,     -inf,     -inf,
            -inf,     -inf, -86.2774], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.7545, -64.0899, -71.2402,     -inf,     -inf,
            -inf,     -inf, -71.6846], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -65.6273,     -inf, -66.8167,     -inf,     -inf,
            -inf,     -inf, -65.6438], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.6686,     -inf,     -inf,
            -inf,     -inf, -84.8602], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -73.6797], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 987: Reward=-209.55, route=[0, 6, 5, 8, 7, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.1735, -63.0578, -71.1818, -70.1752, -60.7851, -52.6014,
        -66.3489, -67.4604, -79.4391], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -71.0152, -62.8834, -80.1443, -73.9143, -52.4419,     -inf,
        -63.4800, -59.8981, -88.5463], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.5060, -64.7939, -84.4148, -77.1674,     -inf,     -inf,
        -62.4174, -56.1950, -92.8622], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.3289, -70.9203, -85.0743, -82.1376,     -inf,     -inf,
        -59.5661,     -inf, -92.9259], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.8489, -72.1346, -79.1579, -80.5808,     -inf,     -inf,
            -inf,     -inf, -86.2774], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -68.7545, -64.0899, -71.2402,     -inf,     -inf,
            -inf,     -inf, -71.6846], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -65.6273,     -inf, -66.8167,     -inf,     -inf,
            -inf,     -inf, -65.6438], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.6686,     -inf,     -inf,
            -inf,     -inf, -84.8602], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -73.6797], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 988: Reward=-209.55, route=[0, 6, 5, 8, 7, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.0649, -62.2478, -70.7748, -70.0476, -60.6156, -52.8640,
        -66.8520, -67.8964, -78.4851], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9522, -62.0792, -79.7901, -73.8077, -52.2427,     -inf,
        -63.9245, -60.2849, -87.6429], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.4927, -63.9921, -84.1521, -77.0943,     -inf,     -inf,
        -62.8186, -56.4979, -92.0414], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.3032, -70.1578, -84.8043, -82.1027,     -inf,     -inf,
        -59.9583,     -inf, -92.0826], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.7567, -71.3907, -78.7844, -80.5379,     -inf,     -inf,
            -inf,     -inf, -85.3213], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.9711, -63.7461, -71.2418,     -inf,     -inf,
            -inf,     -inf, -70.7365], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -64.7983,     -inf, -66.8150,     -inf,     -inf,
            -inf,     -inf, -64.6843], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.5089,     -inf, -71.0331,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -54.7690,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 989: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.0649, -62.2478, -70.7748, -70.0476, -60.6156, -52.8640,
        -66.8520, -67.8964, -78.4851], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9522, -62.0792, -79.7901, -73.8077, -52.2427,     -inf,
        -63.9245, -60.2849, -87.6429], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.4927, -63.9921, -84.1521, -77.0943,     -inf,     -inf,
        -62.8186, -56.4979, -92.0414], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.3032, -70.1578, -84.8043, -82.1027,     -inf,     -inf,
        -59.9583,     -inf, -92.0826], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.7567, -71.3907, -78.7844, -80.5379,     -inf,     -inf,
            -inf,     -inf, -85.3213], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -67.9711, -63.7461, -71.2418,     -inf,     -inf,
            -inf,     -inf, -70.7365], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -64.7983,     -inf, -66.8150,     -inf,     -inf,
            -inf,     -inf, -64.6843], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -71.5089,     -inf, -71.0331,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True  True  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -54.7690,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 990: Reward=-176.12, route=[0, 6, 5, 8, 7, 1, 3, 9, 4, 2] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -67.0649, -62.2478, -70.7748, -70.0476, -60.6156, -52.8640,
        -66.8520, -67.8964, -78.4851], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.9522, -62.0792, -79.7901, -73.8077, -52.2427,     -inf,
        -63.9245, -60.2849, -87.6429], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.4737, -62.8184, -83.9641, -76.9425,     -inf,     -inf,
        -63.3017, -57.2260, -91.3747], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.2706, -69.0233, -84.6089, -81.9903,     -inf,     -inf,
        -60.4311,     -inf, -91.3925], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.6581, -70.2676, -78.4827, -80.4104,     -inf,     -inf,
            -inf,     -inf, -84.5184], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.7877, -63.5189, -71.1830,     -inf,     -inf,
            -inf,     -inf, -69.9957], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -63.5546,     -inf, -66.7452,     -inf,     -inf,
            -inf,     -inf, -63.9408], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.2545,     -inf,     -inf,
            -inf,     -inf, -83.0937], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -72.1881], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 991: Reward=-209.55, route=[0, 6, 5, 8, 7, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.9640, -61.0462, -70.4339, -69.8244, -60.4677, -53.0863,
        -67.4413, -68.7400, -77.6973], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8905, -60.8924, -79.4989, -73.6080, -52.0706,     -inf,
        -64.4640, -61.0934, -86.8968], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.4737, -62.8184, -83.9641, -76.9425,     -inf,     -inf,
        -63.3017, -57.2260, -91.3747], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.2706, -69.0233, -84.6089, -81.9903,     -inf,     -inf,
        -60.4311,     -inf, -91.3925], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.6581, -70.2676, -78.4827, -80.4104,     -inf,     -inf,
            -inf,     -inf, -84.5184], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.7877, -63.5189, -71.1830,     -inf,     -inf,
            -inf,     -inf, -69.9957], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -63.5546,     -inf, -66.7452,     -inf,     -inf,
            -inf,     -inf, -63.9408], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  0. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.2545,     -inf,     -inf,
            -inf,     -inf, -83.0937], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.
  1.  0. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True  True  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf,     -inf,     -inf,     -inf,
            -inf,     -inf, -72.1881], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 992: Reward=-209.55, route=[0, 6, 5, 8, 7, 1, 3, 2, 4, 9] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.9640, -61.0462, -70.4339, -69.8244, -60.4677, -53.0863,
        -67.4413, -68.7400, -77.6973], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.8905, -60.8924, -79.4989, -73.6080, -52.0706,     -inf,
        -64.4640, -61.0934, -86.8968], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.4737, -62.8184, -83.9641, -76.9425,     -inf,     -inf,
        -63.3017, -57.2260, -91.3747], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -72.2706, -69.0233, -84.6089, -81.9903,     -inf,     -inf,
        -60.4311,     -inf, -91.3925], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.1940, -69.6827, -77.8945, -80.4262,     -inf,     -inf,
            -inf,     -inf, -83.2916], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.1581, -63.0154, -71.2934,     -inf,     -inf,
            -inf,     -inf, -68.8398], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -62.8754,     -inf, -66.8502,     -inf,     -inf,
            -inf,     -inf, -62.7765], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.6570,     -inf, -71.1596,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -65.8447,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 993: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.4941, -60.3725, -69.7863, -69.7272, -60.8656, -53.3585,
        -67.6785, -69.8550, -76.4780], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4737, -60.2284, -78.9191, -73.5433, -52.4398,     -inf,
        -64.6290, -62.1602, -85.7323], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.1639, -62.1515, -83.6048, -76.9539,     -inf,     -inf,
        -63.3405, -58.0948, -90.4098], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.9427, -68.4023, -84.2416, -82.0428,     -inf,     -inf,
        -60.4496,     -inf, -90.4021], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.1940, -69.6827, -77.8945, -80.4262,     -inf,     -inf,
            -inf,     -inf, -83.2916], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.1581, -63.0154, -71.2934,     -inf,     -inf,
            -inf,     -inf, -68.8398], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -62.8754,     -inf, -66.8502,     -inf,     -inf,
            -inf,     -inf, -62.7765], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.6570,     -inf, -71.1596,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -65.8447,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 994: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.4941, -60.3725, -69.7863, -69.7272, -60.8656, -53.3585,
        -67.6785, -69.8550, -76.4780], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.4737, -60.2284, -78.9191, -73.5433, -52.4398,     -inf,
        -64.6290, -62.1602, -85.7323], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -72.1639, -62.1515, -83.6048, -76.9539,     -inf,     -inf,
        -63.3405, -58.0948, -90.4098], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.9427, -68.4023, -84.2416, -82.0428,     -inf,     -inf,
        -60.4496,     -inf, -90.4021], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -69.1940, -69.6827, -77.8945, -80.4262,     -inf,     -inf,
            -inf,     -inf, -83.2916], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.1581, -63.0154, -71.2934,     -inf,     -inf,
            -inf,     -inf, -68.8398], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -62.5793,     -inf, -67.0996,     -inf,     -inf,
            -inf,     -inf, -61.8548], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.4118,     -inf, -71.4598,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -65.8285,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 995: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.0857, -60.0626, -69.0915, -69.7805, -61.1503, -53.5893,
        -67.9382, -70.8318, -75.5024], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.1111, -59.9241, -78.2793, -73.6207, -52.6988,     -inf,
        -64.8281, -63.0965, -84.8052], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.8920, -61.8447, -83.1384, -77.0892,     -inf,     -inf,
        -63.4423, -58.8704, -89.6479], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.6528, -68.1472, -83.7649, -82.2216,     -inf,     -inf,
        -60.5311,     -inf, -89.6173], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.7898, -69.4625, -77.2363, -80.5801,     -inf,     -inf,
            -inf,     -inf, -82.3103], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -65.9047, -62.4517, -71.5460,     -inf,     -inf,
            -inf,     -inf, -67.9232], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -62.5793,     -inf, -67.0996,     -inf,     -inf,
            -inf,     -inf, -61.8548], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.4118,     -inf, -71.4598,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -65.8285,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 996: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -66.0857, -60.0626, -69.0915, -69.7805, -61.1503, -53.5893,
        -67.9382, -70.8318, -75.5024], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -70.1111, -59.9241, -78.2793, -73.6207, -52.6988,     -inf,
        -64.8281, -63.0965, -84.8052], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.8920, -61.8447, -83.1384, -77.0892,     -inf,     -inf,
        -63.4423, -58.8704, -89.6479], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.6528, -68.1472, -83.7649, -82.2216,     -inf,     -inf,
        -60.5311,     -inf, -89.6173], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.7898, -69.4625, -77.2363, -80.5801,     -inf,     -inf,
            -inf,     -inf, -82.3103], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -65.9047, -62.4517, -71.5460,     -inf,     -inf,
            -inf,     -inf, -67.9232], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -62.5793,     -inf, -67.0996,     -inf,     -inf,
            -inf,     -inf, -61.8548], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.4118,     -inf, -71.4598,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.0903,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 997: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.7015, -60.2053, -68.6577, -70.1226, -61.3474, -53.5377,
        -67.8839, -71.3487, -74.6428], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.7405, -60.0644, -77.8680, -73.9553, -52.8759,     -inf,
        -64.7577, -63.6034, -83.9644], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5815, -61.9761, -82.8040, -77.4407,     -inf,     -inf,
        -63.3402, -59.2968, -88.8997], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.3217, -68.3362, -83.4192, -82.6184,     -inf,     -inf,
        -60.4069,     -inf, -88.8453], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.3887, -69.6812, -76.7806, -80.9712,     -inf,     -inf,
            -inf,     -inf, -81.4223], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.1149, -62.0836, -72.0299,     -inf,     -inf,
            -inf,     -inf, -67.0806], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -62.7568,     -inf, -67.5834,     -inf,     -inf,
            -inf,     -inf, -61.0128], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.6503,     -inf, -71.9971,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.0903,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 998: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

mask = [ True False False False False False False False False False]
greedy_action q_values = tensor([    -inf, -65.7015, -60.2053, -68.6577, -70.1226, -61.3474, -53.5377,
        -67.8839, -71.3487, -74.6428], grad_fn=<SliceBackward0>)
action = 6
next_state = [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.
  0.  0. 25. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False False  True False False False]
greedy_action q_values = tensor([    -inf, -69.7405, -60.0644, -77.8680, -73.9553, -52.8759,     -inf,
        -64.7577, -63.6034, -83.9644], grad_fn=<SliceBackward0>)
action = 5
next_state = [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  0.  0. 15. 30. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False False False]
greedy_action q_values = tensor([    -inf, -71.5815, -61.9761, -82.8040, -77.4407,     -inf,     -inf,
        -63.3402, -59.2968, -88.8997], grad_fn=<SliceBackward0>)
action = 8
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  1.  1.  0.
  1.  0. 10. 43. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True False  True False]
greedy_action q_values = tensor([    -inf, -71.3217, -68.3362, -83.4192, -82.6184,     -inf,     -inf,
        -60.4069,     -inf, -88.8453], grad_fn=<SliceBackward0>)
action = 7
next_state = [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.
  1.  0. 20. 50. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True False False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf, -68.3887, -69.6812, -76.7806, -80.9712,     -inf,     -inf,
            -inf,     -inf, -81.4223], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  1.  1.
  1.  0. 41. 49. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False False False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -66.1149, -62.0836, -72.0299,     -inf,     -inf,
            -inf,     -inf, -67.0806], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  0. 55. 45. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True False]
greedy_action q_values = tensor([    -inf,     -inf, -62.7568,     -inf, -67.5834,     -inf,     -inf,
            -inf,     -inf, -61.0128], grad_fn=<SliceBackward0>)
action = 9
next_state = [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  1.  0.  1.  1.  1.
  1.  1. 55. 60. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True False  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf, -69.6503,     -inf, -71.9971,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.
  1.  1. 35. 17. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


mask = [ True  True  True  True False  True  True  True  True  True]
greedy_action q_values = tensor([    -inf,     -inf,     -inf,     -inf, -66.0903,     -inf,     -inf,
            -inf,     -inf,     -inf], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.
  1.  1. 55. 20. 35. 35. 35. 35. 41. 49. 35. 17. 55. 45. 55. 20. 15. 30.
 25. 30. 20. 50. 10. 43. 55. 60.]


Episode 999: Reward=-190.55, route=[0, 6, 5, 8, 7, 1, 3, 9, 2, 4] 

==================

