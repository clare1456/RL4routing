mask = [ True False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
greedy_action q_values = tensor([-inf, -inf, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  1.  1.  1.  1. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 0: Reward=-115.37, route=[0, 1, 2, 4, 3] 

==================

mask = [ True False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  1.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
greedy_action q_values = tensor([-inf, -inf, -inf, -inf, nan], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 1: Reward=-132.2, route=[0, 1, 2, 3, 4] 

==================

mask = [ True False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  1.  0.  0.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  0.  1. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False  True]
greedy_action q_values = tensor([-inf, -inf, -inf, nan, -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  1.  1.  1.  1. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 2: Reward=-124.43, route=[0, 1, 4, 2, 3] 

==================

mask = [ True False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  0.  1.  0.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  1.  1.  1. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True  True  True]
greedy_action q_values = tensor([-inf, nan, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  1.  1.  1.  1. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 3: Reward=-93.02, route=[0, 2, 4, 3, 1] 

==================

mask = [ True False False False False]
greedy_action q_values = tensor([-inf, nan, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True False]
greedy_action q_values = tensor([-inf, -inf, nan, -inf, nan], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  1.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
greedy_action q_values = tensor([-inf, -inf, -inf, -inf, nan], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 4: Reward=-109.42, route=[0, 1, 3, 2, 4] 

==================

mask = [ True False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  0.  1.  0.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True False  True]
greedy_action q_values = tensor([-inf, nan, -inf, nan, -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  1.  0.  1. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  1.  1.  1.  1. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 5: Reward=-107.35, route=[0, 2, 4, 1, 3] 

==================

mask = [ True False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  1.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False  True]
greedy_action q_values = tensor([-inf, -inf, -inf, nan, -inf], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  1.  1.  1.  1. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 6: Reward=-130.12, route=[0, 2, 1, 4, 3] 

==================

mask = [ True False False False False]
greedy_action q_values = tensor([-inf, nan, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True False]
greedy_action q_values = tensor([-inf, -inf, nan, -inf, nan], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  1.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
greedy_action q_values = tensor([-inf, -inf, -inf, -inf, nan], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 7: Reward=-109.42, route=[0, 1, 3, 2, 4] 

==================

mask = [ True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True False]
greedy_action q_values = tensor([-inf, nan, nan, -inf, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  1.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  1.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 8: Reward=-114.7, route=[0, 3, 1, 2, 4] 

==================

mask = [ True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  1.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  1.  0.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True  True]
greedy_action q_values = tensor([-inf, -inf, nan, -inf, -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  1.  1.  1.  1. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 9: Reward=-107.35, route=[0, 3, 1, 4, 2] 

==================

mask = [ True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  1.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True  True False]
greedy_action q_values = tensor([-inf, nan, -inf, -inf, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  1.  1.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
greedy_action q_values = tensor([-inf, -inf, -inf, -inf, nan], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 10: Reward=-146.53, route=[0, 3, 2, 1, 4] 

==================

mask = [ True False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True False]
greedy_action q_values = tensor([-inf, -inf, nan, -inf, nan], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  1.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 11: Reward=-109.42, route=[0, 1, 3, 2, 4] 

==================

mask = [ True False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  1.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  1.  1.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 12: Reward=-124.17, route=[0, 2, 3, 1, 4] 

==================

mask = [ True False False False False]
greedy_action q_values = tensor([-inf, nan, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
greedy_action q_values = tensor([-inf, -inf, -inf, nan, nan], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  1.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 13: Reward=-132.2, route=[0, 1, 2, 3, 4] 

==================

mask = [ True False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True False False]
greedy_action q_values = tensor([-inf, nan, -inf, nan, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  1.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  1.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
greedy_action q_values = tensor([-inf, -inf, -inf, -inf, nan], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 14: Reward=-115.12, route=[0, 2, 1, 3, 4] 

==================

mask = [ True False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
greedy_action q_values = tensor([-inf, -inf, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
greedy_action q_values = tensor([-inf, -inf, -inf, nan, nan], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  1.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 15: Reward=-132.2, route=[0, 1, 2, 3, 4] 

==================

mask = [ True False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
greedy_action q_values = tensor([-inf, -inf, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
greedy_action q_values = tensor([-inf, -inf, -inf, nan, nan], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  1.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 16: Reward=-132.2, route=[0, 1, 2, 3, 4] 

==================

mask = [ True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  0.  0.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  1.  1. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True  True]
greedy_action q_values = tensor([-inf, -inf, nan, -inf, -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  1.  1.  1.  1. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 17: Reward=-130.12, route=[0, 3, 4, 1, 2] 

==================

mask = [ True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True False]
greedy_action q_values = tensor([-inf, nan, nan, -inf, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  1.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  1.  0.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True  True]
greedy_action q_values = tensor([-inf, -inf, nan, -inf, -inf], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  1.  1.  1.  1. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 18: Reward=-107.35, route=[0, 3, 1, 4, 2] 

==================

mask = [ True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  1.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True  True False]
greedy_action q_values = tensor([-inf, nan, -inf, -inf, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  1.  1.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 19: Reward=-146.53, route=[0, 3, 2, 1, 4] 

==================

mask = [ True False False False False]
greedy_action q_values = tensor([-inf, nan, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True False]
greedy_action q_values = tensor([-inf, -inf, nan, -inf, nan], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  1.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 20: Reward=-109.42, route=[0, 1, 3, 2, 4] 

==================

mask = [ True False False False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  0.  0.  0.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  0.  1.  1. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True  True]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  1.  1. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  1.  1.  1.  1. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 21: Reward=-115.12, route=[0, 4, 3, 1, 2] 

==================

mask = [ True False False False False]
greedy_action q_values = tensor([-inf, nan, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
greedy_action q_values = tensor([-inf, -inf, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
greedy_action q_values = tensor([-inf, -inf, -inf, nan, nan], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  1.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
greedy_action q_values = tensor([-inf, -inf, -inf, -inf, nan], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 22: Reward=-132.2, route=[0, 1, 2, 3, 4] 

==================

mask = [ True False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  1.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  1.  1.  0.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False  True]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  0.  1.  1.  1.  1. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 23: Reward=-130.12, route=[0, 2, 1, 4, 3] 

==================

mask = [ True False False False False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  1.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  1.  1.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 24: Reward=-124.17, route=[0, 2, 3, 1, 4] 

==================

mask = [ True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  1.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  1.  0.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  0.  1.  1.  1.  1. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 25: Reward=-107.35, route=[0, 3, 1, 4, 2] 

==================

mask = [ True False False False False]
greedy_action q_values = tensor([-inf, nan, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
greedy_action q_values = tensor([-inf, -inf, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  1.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
greedy_action q_values = tensor([-inf, -inf, -inf, -inf, nan], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 26: Reward=-132.2, route=[0, 1, 2, 3, 4] 

==================

mask = [ True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  0.  0.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  1.  1. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True  True  True]
greedy_action q_values = tensor([-inf, nan, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  1.  1.  1.  1. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 27: Reward=-115.37, route=[0, 3, 4, 2, 1] 

==================

mask = [ True False False False False]
greedy_action q_values = tensor([-inf, nan, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
greedy_action q_values = tensor([-inf, -inf, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  1.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 28: Reward=-132.2, route=[0, 1, 2, 3, 4] 

==================

mask = [ True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  1.  0.  0.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True  True]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  1.  1. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True  True  True]
greedy_action q_values = tensor([-inf, nan, -inf, -inf, -inf], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  0.  1.  1.  1.  1. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 29: Reward=-115.37, route=[0, 3, 4, 2, 1] 

==================

mask = [ True False False False False]
random_action
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  0.  0.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False False  True False]
random_action
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  0.  1.  1.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True False  True  True False]
greedy_action q_values = tensor([-inf, nan, -inf, -inf, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  1.  1.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
random_action
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 30: Reward=-146.53, route=[0, 3, 2, 1, 4] 

==================

mask = [ True False False False False]
random_action
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
greedy_action q_values = tensor([-inf, -inf, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 2
next_state = [ 0.  0.  1.  0.  0.  1.  1.  1.  0.  0. 35. 17. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True False False]
greedy_action q_values = tensor([-inf, -inf, -inf, nan, nan], grad_fn=<SliceBackward0>)
action = 3
next_state = [ 0.  0.  0.  1.  0.  1.  1.  1.  1.  0. 55. 45. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True  True  True False]
greedy_action q_values = tensor([-inf, -inf, -inf, -inf, nan], grad_fn=<SliceBackward0>)
action = 4
next_state = [ 0.  0.  0.  0.  1.  0.  1.  1.  1.  1. 55. 20. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


Episode 31: Reward=-132.2, route=[0, 1, 2, 3, 4] 

==================

mask = [ True False False False False]
greedy_action q_values = tensor([-inf, nan, nan, nan, nan], grad_fn=<SliceBackward0>)
action = 1
next_state = [ 0.  1.  0.  0.  0.  1.  1.  0.  0.  0. 41. 49. 35. 35. 35. 35. 41. 49.
 35. 17. 55. 45. 55. 20.]


mask = [ True  True False False False]
random_action
action = 3
